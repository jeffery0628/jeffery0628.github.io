<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/snoppy.jpeg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/snoppy.jpeg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/snoppy.jpeg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jeffery0628.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":true,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
<meta property="og:type" content="website">
<meta property="og:title" content="ç«ç§2å·">
<meta property="og:url" content="https://jeffery0628.github.io/index.html">
<meta property="og:site_name" content="ç«ç§2å·">
<meta property="og:description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Li Zhen">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://jeffery0628.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>ç«ç§2å·</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ç«ç§2å·</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">ç«ç§è®¡åˆ’</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>å…³äº</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£</a>

  </li>
        <li class="menu-item menu-item-books">

    <a href="/books/" rel="section"><i class="fa fa-book fa-fw"></i>è¯»ä¹¦</a>

  </li>
        <li class="menu-item menu-item-movies">

    <a href="/movies/" rel="section"><i class="fa fa-video fa-fw"></i>ç”µå½±</a>

  </li>
        <li class="menu-item menu-item-games">

    <a href="/games/" rel="section"><i class="fa fa-gamepad fa-fw"></i>æ¸¸æˆ</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>æœç´¢
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="æœç´¢..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>



</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/03/20/%E8%BF%87%E5%8E%BB%E3%80%81%E7%8E%B0%E5%9C%A8%E3%80%81%E6%9C%AA%E6%9D%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/20/%E8%BF%87%E5%8E%BB%E3%80%81%E7%8E%B0%E5%9C%A8%E3%80%81%E6%9C%AA%E6%9D%A5/" class="post-title-link" itemprop="url">è¿‡å»ã€ç°åœ¨ã€æœªæ¥</a>
        </h2>

        <div class="post-meta">
          
            <i class="fa fa-thumb-tack"></i>
            <font color=7D26CD>ç½®é¡¶</font>
            <span class="post-meta-divider">|</span>
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-08 15:24:38" itemprop="dateModified" datetime="2020-05-08T15:24:38+08:00">2020-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%94%9F%E6%B4%BB/" itemprop="url" rel="index"><span itemprop="name">ç”Ÿæ´»</span></a>
                </span>
            </span>

          
            <span id="/2020/03/20/%E8%BF%87%E5%8E%BB%E3%80%81%E7%8E%B0%E5%9C%A8%E3%80%81%E6%9C%AA%E6%9D%A5/" class="post-meta-item leancloud_visitors" data-flag-title="è¿‡å»ã€ç°åœ¨ã€æœªæ¥" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/03/20/%E8%BF%87%E5%8E%BB%E3%80%81%E7%8E%B0%E5%9C%A8%E3%80%81%E6%9C%AA%E6%9D%A5/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/03/20/%E8%BF%87%E5%8E%BB%E3%80%81%E7%8E%B0%E5%9C%A8%E3%80%81%E6%9C%AA%E6%9D%A5/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>154</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>1 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>å¼€è¿™ç¯‡ blog post æœ‰ä¸¤ä¸ªç›®çš„ï¼š</p>
<ol>
<li>å›é¦–è¿‡å»ï¼ŒæŠŠæ¡ç°åœ¨ï¼Œä¸è´Ÿæœªæ¥ã€‚å½“è¹‰è·ä¸å‰çš„æ—¶å€™ï¼Œå¯ä»¥æé†’è‡ªå·±æƒ³è¦ä¸€ä¸ªä»€ä¹ˆæ ·çš„æœªæ¥ï¼Œä»€ä¹ˆåº”è¯¥åšï¼Œä»€ä¹ˆä¸åº”è¯¥åšã€‚</li>
<li>å®¢è§‚çš„è®°å½•è‡ªå·±çš„æˆé•¿ã€‚</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/03/20/%E8%BF%87%E5%8E%BB%E3%80%81%E7%8E%B0%E5%9C%A8%E3%80%81%E6%9C%AA%E6%9D%A5/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/05/11/transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/11/transformer/" class="post-title-link" itemprop="url">Transformer</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-11 13:06:55" itemprop="dateModified" datetime="2020-05-11T13:06:55+08:00">2020-05-11</time>
              </span>

          
            <span id="/2020/05/11/transformer/" class="post-meta-item leancloud_visitors" data-flag-title="Transformer" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/05/11/transformer/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/05/11/transformer/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>24k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>21 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><img src="/2020/05/11/transformer/transformer.jpeg" alt></p>
<h1 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h1><p>è‡ª2017å¹´æå‡ºä»¥æ¥ï¼ŒTransformeråœ¨ä¼—å¤šè‡ªç„¶è¯­è¨€å¤„ç†é—®é¢˜ä¸­å–å¾—äº†éå¸¸å¥½çš„æ•ˆæœã€‚å®ƒä¸ä½†è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œè€Œä¸”æ›´é€‚åˆå»ºæ¨¡é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œå› æ­¤å¤§æœ‰å–ä»£å¾ªç¯æˆ–å·ç§¯ç¥ç»ç½‘ç»œï¼Œä¸€ç»Ÿè‡ªç„¶è¯­è¨€å¤„ç†çš„æ·±åº¦æ¨¡å‹æ±Ÿæ¹–ä¹‹åŠ¿ã€‚æœ¬æ–‡ç»“åˆ<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">ã€ŠAttention is all you needã€‹</a>è®ºæ–‡ä¸Harvardçš„ä»£ç <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">ã€ŠAnnotated Transformerã€‹</a>æ·±å…¥ç†è§£transformeræ¨¡å‹ã€‚ </p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/05/11/transformer/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/05/11/transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/11/transformer/" class="post-title-link" itemprop="url">Transformer</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-11 13:09:57" itemprop="dateModified" datetime="2020-05-11T13:09:57+08:00">2020-05-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%80%E6%9C%AF-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">æŠ€æœ¯/è‡ªç„¶è¯­è¨€å¤„ç†</span></a>
                </span>
            </span>

          
            <span id="/2020/05/11/transformer/" class="post-meta-item leancloud_visitors" data-flag-title="Transformer" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/05/11/transformer/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/05/11/transformer/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>24k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>21 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <a id="more"></a>
<p><img src="/2020/05/11/transformer/transformer.jpeg" alt></p>
<h1 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h1><p>è‡ª2017å¹´æå‡ºä»¥æ¥ï¼ŒTransformeråœ¨ä¼—å¤šè‡ªç„¶è¯­è¨€å¤„ç†é—®é¢˜ä¸­å–å¾—äº†éå¸¸å¥½çš„æ•ˆæœã€‚å®ƒä¸ä½†è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œè€Œä¸”æ›´é€‚åˆå»ºæ¨¡é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œå› æ­¤å¤§æœ‰å–ä»£å¾ªç¯æˆ–å·ç§¯ç¥ç»ç½‘ç»œï¼Œä¸€ç»Ÿè‡ªç„¶è¯­è¨€å¤„ç†çš„æ·±åº¦æ¨¡å‹æ±Ÿæ¹–ä¹‹åŠ¿ã€‚æœ¬æ–‡ç»“åˆ<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">ã€ŠAttention is all you needã€‹</a>è®ºæ–‡ä¸Harvardçš„ä»£ç <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">ã€ŠAnnotated Transformerã€‹</a>æ·±å…¥ç†è§£transformeræ¨¡å‹ã€‚ </p>
<!--more-->
<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p>Transformerçš„æ•´ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨Encoderå’ŒDecoderä¸­éƒ½ä½¿ç”¨äº†Self-attention, Point-wiseå’Œå…¨è¿æ¥å±‚ã€‚Encoderå’Œdecoderçš„å¤§è‡´ç»“æ„åˆ†åˆ«å¦‚ä¸‹å›¾çš„å·¦åŠéƒ¨åˆ†å’Œå³åŠéƒ¨åˆ†æ‰€ç¤ºã€‚</p>
<p><img src="/2020/05/11/transformer/over_all.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">(src_vocab, tgt_vocab, N=<span class="number">6</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               d_model=<span class="number">512</span>, d_ff=<span class="number">2048</span>, h=<span class="number">8</span>, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Helper: Construct a model from hyperparameters.</span></span><br><span class="line"><span class="string">    src_vocab: è¾“å…¥è¯æ±‡è¡¨å¤§å°</span></span><br><span class="line"><span class="string">    tgt_vocab:è¾“å‡ºè¯æ±‡è¡¨å¤§å°</span></span><br><span class="line"><span class="string">    Nï¼šå †å ä¸ªæ•°</span></span><br><span class="line"><span class="string">    d_model:embedding_size</span></span><br><span class="line"><span class="string">    d_ff: çº¿å½¢å±‚è¾“å‡ºç»´åº¦</span></span><br><span class="line"><span class="string">    h:multi-headä¸­ head çš„ä¸ªæ•°</span></span><br><span class="line"><span class="string">    dropoutï¼š</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    c = copy.deepcopy</span><br><span class="line">    attn = MultiHeadedAttention(h, d_model)</span><br><span class="line">    ff = PositionwiseFeedForward(d_model, d_ff, dropout)</span><br><span class="line">    position = PositionalEncoding(d_model, dropout)</span><br><span class="line">    model = EncoderDecoder(</span><br><span class="line">        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N), <span class="comment"># encoder</span></span><br><span class="line">        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N), <span class="comment"># decoder</span></span><br><span class="line">        nn.Sequential(Embeddings(d_model, src_vocab), c(position)), <span class="comment"># src_embed</span></span><br><span class="line">        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)), <span class="comment"># tgt_embed</span></span><br><span class="line">        Generator(d_model, tgt_vocab) <span class="comment"># generator</span></span><br><span class="line">    		)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># This was important from their code. </span></span><br><span class="line">    <span class="comment"># Initialize parameters with Glorot / fan_avg.</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line">            nn.init.xavier_uniform(p)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><p>transformerçš„è¾“å…¥æ˜¯<strong>Word Embedding + Position Embedding</strong>ã€‚</p>
<h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><p>Word embeddingåœ¨pytorchä¸­é€šå¸¸ç”¨ nn.Embedding å®ç°ï¼Œå…¶æƒé‡çŸ©é˜µé€šå¸¸æœ‰ä¸¤ç§é€‰æ‹©ï¼š</p>
<ol>
<li>ä½¿ç”¨ Pre-trainedçš„<strong>Embeddingså¹¶freeze</strong>ï¼Œè¿™ç§æƒ…å†µä¸‹å®é™…å°±æ˜¯ä¸€ä¸ª Lookup Tableã€‚</li>
<li>å¯¹å…¶è¿›è¡Œéšæœºåˆå§‹åŒ–(å½“ç„¶ä¹Ÿå¯ä»¥é€‰æ‹© Pre-trained çš„ç»“æœ)ï¼Œä½†<strong>è®¾ä¸º Trainable</strong>ã€‚è¿™æ ·åœ¨ training è¿‡ç¨‹ä¸­ä¸æ–­åœ°å¯¹ Embeddings è¿›è¡Œæ”¹è¿›ã€‚</li>
</ol>
<p>transformeré€‰æ‹©åè€…ï¼Œä»£ç å®ç°å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><figcaption><span>word_embedding</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Embeddings</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">        super(Embeddings, self).__init__()</span><br><span class="line">        self.lut = nn.Embedding(vocab, d_model) <span class="comment"># vocab è¯æ±‡è¡¨å¤§å°</span></span><br><span class="line">        self.d_model = d_model  <span class="comment">#è¡¨ç¤ºembeddingçš„ç»´åº¦</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.lut(x) * math.sqrt(self.d_model)</span><br></pre></td></tr></table></figure>
<h3 id="Positional-Embedding"><a href="#Positional-Embedding" class="headerlink" title="Positional Embedding"></a>Positional Embedding</h3><p>åœ¨RNNä¸­ï¼Œå¯¹å¥å­çš„å¤„ç†æ˜¯ä¸€ä¸ªä¸ªwordæŒ‰é¡ºåºè¾“å…¥çš„ã€‚ä½†åœ¨ Transformer ä¸­ï¼Œè¾“å…¥å¥å­çš„æ‰€æœ‰wordæ˜¯åŒæ—¶å¤„ç†çš„ï¼Œæ²¡æœ‰è€ƒè™‘è¯çš„æ’åºå’Œä½ç½®ä¿¡æ¯ã€‚å› æ­¤ï¼ŒTransformer çš„ä½œè€…æå‡ºäº†åŠ å…¥ <code>positional encoding</code>çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚<code>positional encoding</code>ä½¿å¾— Transformer å¯ä»¥è¡¡é‡ word ä½ç½®æœ‰å…³çš„ä¿¡æ¯ã€‚</p>
<p><strong>å¦‚ä½•å®ç°å…·æœ‰ä½ç½®ä¿¡æ¯çš„encodingï¼Ÿ</strong></p>
<p>ä½œè€…æä¾›äº†ä¸¤ç§æ€è·¯ï¼š</p>
<ul>
<li>é€šè¿‡è®­ç»ƒå­¦ä¹  positional encoding å‘é‡ï¼›</li>
<li>ä½¿ç”¨å…¬å¼æ¥è®¡ç®— positional encodingå‘é‡ã€‚</li>
</ul>
<p>è¯•éªŒåå‘ç°ä¸¤ç§é€‰æ‹©çš„ç»“æœæ˜¯ç›¸ä¼¼çš„ï¼Œæ‰€ä»¥é‡‡ç”¨äº†ç¬¬2ç§æ–¹æ³•ï¼Œä¼˜ç‚¹æ˜¯ä¸éœ€è¦è®­ç»ƒå‚æ•°ï¼Œè€Œä¸”å³ä½¿<strong>åœ¨è®­ç»ƒé›†ä¸­æ²¡æœ‰å‡ºç°è¿‡çš„å¥å­é•¿åº¦ä¸Šä¹Ÿèƒ½ç”¨</strong>ã€‚Positional Encodingçš„å…¬å¼å¦‚ä¸‹ï¼š</p>
<script type="math/tex; mode=display">
\begin{aligned}
P E_{(p o s, 2 i)} &=\sin \left(p o s / 10000^{2 i / d_{\text {model }}}\right) \\
P E_{(p o s, 2 i+1)} &=\cos \left(p o s / 10000^{2 i / d_{\text {model }}}\right.
\end{aligned}</script><p>å…¶ä¸­ï¼Œ$pos$æŒ‡çš„æ˜¯è¿™ä¸ª word åœ¨è¿™ä¸ªå¥å­ä¸­çš„ä½ç½®ï¼›$2i$æŒ‡çš„æ˜¯ embedding è¯å‘é‡çš„å¶æ•°ç»´åº¦ï¼Œ$2i+1$æŒ‡çš„æ˜¯embedding è¯å‘é‡çš„å¥‡æ•°ç»´åº¦ã€‚å…·ä½“å®ç°å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><figcaption><span>PositionalEncoding</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement the PE function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, dropout, max_len=<span class="number">5000</span>)</span>:</span></span><br><span class="line">        super(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>) <span class="comment"># [max_len, 1]</span></span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) * -(math.log(<span class="number">10000.0</span>) / d_model)) <span class="comment"># ?</span></span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term) <span class="comment"># å¶æ•°åˆ—</span></span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term) <span class="comment"># å¥‡æ•°åˆ—</span></span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)         <span class="comment"># [1, max_len, d_model]</span></span><br><span class="line">        self.register_buffer(<span class="string">'pe'</span>, pe) <span class="comment"># ä¸Šè¿°ä»£ç åªéœ€è®¡ç®—ä¸€æ¬¡ï¼Œç„¶åæ”¾åˆ°å¯„å­˜å™¨é‡Œï¼Œéšç”¨éšå–ã€‚</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)], </span><br><span class="line">                         requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x) <span class="comment"># æ®è¯´dropout=0.1</span></span><br></pre></td></tr></table></figure>
<p><code>x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)</code> è¿™è¡Œä»£ç è¡¨ç¤ºï¼›è¾“å…¥æ¨¡å‹çš„æ•´ä¸ªEmbeddingæ˜¯Word Embeddingä¸Positional Embeddingç›´æ¥ç›¸åŠ ä¹‹åçš„ç»“æœã€‚</p>
<p>ä¸ºä»€ä¹ˆä¸Šé¢çš„ä¸¤ä¸ªå…¬å¼èƒ½ä½“ç°å•è¯çš„ç›¸å¯¹ä½ç½®ä¿¡æ¯å‘¢ï¼Ÿ</p>
<p>ä¸‹é¢ä¸€æ®µä»£ç å–è¯å‘é‡çš„4ä¸ªç»´åº¦ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åœ¨ä½ç½®ç¼–ç ä¸‹æ–¹ï¼Œå°†åŸºäºä½ç½®æ·»åŠ æ­£å¼¦æ³¢ã€‚å¯¹äºæ¯ä¸ªç»´åº¦ï¼Œæ³¢çš„é¢‘ç‡å’Œåç§»éƒ½ä¸åŒã€‚</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">pe = PositionalEncoding(<span class="number">20</span>, <span class="number">0</span>)</span><br><span class="line">y = pe.forward(Variable(torch.zeros(<span class="number">1</span>, <span class="number">100</span>, <span class="number">20</span>))) <span class="comment"># [bs=1,seq_len=100,embed_size=20]</span></span><br><span class="line">plt.plot(np.arange(<span class="number">100</span>), y[<span class="number">0</span>, :, <span class="number">4</span>:<span class="number">8</span>].data.numpy())</span><br><span class="line">plt.legend([<span class="string">"dim %d"</span> %p <span class="keyword">for</span> p <span class="keyword">in</span> [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]])</span><br></pre></td></tr></table></figure>
<p><img src="/2020/05/11/transformer/position_embedding.png" alt></p>
<p>å¯ä»¥çœ‹åˆ°æŸä¸ªåºåˆ—ä¸­ä¸åŒä½ç½®çš„å•è¯ï¼Œåœ¨æŸä¸€ç»´åº¦ä¸Šçš„ä½ç½®ç¼–ç æ•°å€¼ä¸ä¸€æ ·ï¼Œå³åŒä¸€åºåˆ—çš„ä¸åŒå•è¯åœ¨å•ä¸ªçº¬åº¦ç¬¦åˆæŸä¸ªæ­£å¼¦æˆ–è€…ä½™å¼¦ï¼Œå¯è®¤ä¸ºä»–ä»¬çš„å…·æœ‰ç›¸å¯¹å…³ç³»ã€‚</p>
<h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p>Encoderéƒ¨åˆ†æ˜¯ç”±ä¸ªå±‚ç›¸åŒå°Encoder Layerä¸²è”è€Œæˆã€‚å°Encoder Layerå¯ä»¥ç®€åŒ–ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š</p>
<ol>
<li>Multi-Head Self Attention</li>
<li>Feed-Forward Network</li>
</ol>
<p><code>Multi-Head Self Attention</code> å’Œ<code>Feed-Forward Network</code>ä¹‹åéƒ½æ¥äº†ä¸€å±‚<code>Add</code> å’Œ<code>Norm</code></p>
<p>ç¤ºæ„å›¾å¦‚ä¸‹:</p>
<p><img src="/2020/05/11/transformer/encoder_layer.png" alt></p>
<h3 id="Muti-Head-Attention"><a href="#Muti-Head-Attention" class="headerlink" title="Muti-Head-Attention"></a>Muti-Head-Attention</h3><p>Multi-Head Self Attention å®é™…ä¸Šæ˜¯<strong>ç”±hä¸ªSelf Attention å±‚å¹¶è¡Œç»„æˆï¼ŒåŸæ–‡ä¸­h=8</strong>ã€‚</p>
<h4 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h4><p>self-attentionçš„è¾“å…¥æ˜¯åºåˆ—è¯å‘é‡<code>x</code>ã€‚<code>x</code>ç»è¿‡ä¸€ä¸ªçº¿æ€§å˜æ¢å¾—åˆ°<code>query(Q)</code>, <code>x</code>ç»è¿‡ç¬¬äºŒä¸ªçº¿æ€§å˜æ¢å¾—åˆ°<code>key(K)</code>,<code>x</code>ç»è¿‡ç¬¬ä¸‰ä¸ªçº¿æ€§å˜æ¢å¾—åˆ°<code>value(V)</code>ã€‚ä¹Ÿå°±æ˜¯ï¼š</p>
<ul>
<li>Q = linear_q(x)</li>
<li>K = linear_k(x)</li>
<li>V = linear_v(x)</li>
</ul>
<p>å³ï¼š</p>
<p><img src="/2020/05/11/transformer/qkv.png" alt></p>
<p>linear_k, linear_q, linear_væ˜¯ç›¸äº’ç‹¬ç«‹ã€æƒé‡$ğ‘Š^ğ‘„,ğ‘Š^ğ¾,W^V$)æ˜¯ä¸åŒçš„ï¼Œé€šè¿‡è®­ç»ƒå¯å¾—åˆ°ã€‚å¾—åˆ°query(Q)ï¼Œkey(K)ï¼Œvalue(V)ä¹‹åæŒ‰ç…§ä¸‹é¢çš„å…¬å¼è®¡ç®—attention(Q, K, V)ï¼š</p>
<script type="math/tex; mode=display">
\text {Attention}(Q, K, V)=\text {Softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V</script><p><img src="/2020/05/11/transformer/attention.png" alt></p>
<p>è¿™é‡Œ<code>Z</code>å°±æ˜¯<code>attention(Q, K, V)</code>ï¼Œ$ğ‘‘_ğ‘˜=\frac{ğ‘‘_{ğ‘šğ‘œğ‘‘ğ‘’ğ‘™}}{â„}=\frac{512}{8}=64$ã€‚</p>
<ol>
<li><p>ä¸ºä»€ä¹ˆè¦ç”¨$\sqrt{d_k}$ å¯¹ $ğ‘„ğ¾^ğ‘‡$è¿›è¡Œç¼©æ”¾å‘¢ï¼Ÿ</p>
<p>$d_k$å®é™…ä¸Šæ˜¯<code>Q/K/V</code>çš„æœ€åä¸€ä¸ªç»´åº¦ï¼Œå½“$d_k$è¶Šå¤§ï¼Œ$QK^T$å°±è¶Šå¤§ï¼Œå¯èƒ½ä¼šå°†softmaxå‡½æ•°æ¨å…¥æ¢¯åº¦æå°çš„åŒºåŸŸã€‚</p>
</li>
<li><p>softmaxä¹‹åå€¼éƒ½ä»‹äº0åˆ°1ä¹‹é—´ï¼Œå¯ä»¥ç†è§£æˆå¾—åˆ°äº† attention weightsã€‚ç„¶ååŸºäºè¿™ä¸ª attention weights å¯¹ V æ±‚ weighted sum å€¼ Attention(Q, K, V)ã€‚ </p>
</li>
</ol>
<p>Multi-Head-Attention å°±æ˜¯å°†<code>embedding</code>ä¹‹åçš„XæŒ‰ç»´åº¦$ğ‘‘_{ğ‘šğ‘œğ‘‘ğ‘’ğ‘™}=512$ åˆ‡å‰²æˆ$â„=8$ä¸ªï¼Œåˆ†åˆ«åšself-attentionä¹‹åå†åˆå¹¶åœ¨ä¸€èµ·ã€‚</p>
<p><img src="/2020/05/11/transformer/attention_1.png" alt></p>
<figure class="highlight python"><figcaption><span>Attention</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span><span class="params">(query, key, value, mask=None, dropout=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Compute 'Scaled Dot Product Attention</span></span><br><span class="line"><span class="string">    qkv :[batch, h, seq_len, embed_size/h(d_k)]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    d_k = query.size(<span class="number">-1</span>)</span><br><span class="line">    scores = torch.matmul(query, key.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) / math.sqrt(d_k)</span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, <span class="number">-1e9</span>)  <span class="comment"># mask </span></span><br><span class="line">    p_attn = F.softmax(scores, dim = <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p_attn = dropout(p_attn)     <span class="comment"># dropout=0.1</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></table></figure>
<p><img src="/2020/05/11/transformer/multi_head.png" alt></p>
<figure class="highlight python"><figcaption><span>MultiHeadedAttention</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadedAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, h, d_model, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="string">"Take in model size and number of heads."</span></span><br><span class="line">        super(MultiHeadedAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> d_model % h == <span class="number">0</span></span><br><span class="line">        <span class="comment"># We assume d_v always equals d_k</span></span><br><span class="line">        self.d_k = d_model // h</span><br><span class="line">        self.h = h</span><br><span class="line">        self.linears = clones(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line">        self.attn = <span class="literal">None</span></span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, mask=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        å®ç°MultiHeadedAttentionã€‚</span></span><br><span class="line"><span class="string">           è¾“å…¥çš„qï¼Œkï¼Œvæ˜¯å½¢çŠ¶ [batch, seq_len, embed_size(d_model)]ã€‚</span></span><br><span class="line"><span class="string">           è¾“å‡ºçš„x çš„å½¢çŠ¶åŒä¸Šã€‚</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Same mask applied to all h heads.</span></span><br><span class="line">            mask = mask.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        nbatches = query.size(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1) Do all the linear projections in batch from d_model =&gt; h x d_k </span></span><br><span class="line">        <span class="comment">#    [batch, seq_len, embed_size] -&gt;[batch, h, seq_len, embed_size/h]</span></span><br><span class="line">        query, key, value = [l(x).view(nbatches, <span class="number">-1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>) <span class="keyword">for</span> l, x <span class="keyword">in</span> zip(self.linears, (query, key, value))]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2) Apply attention on all the projected vectors in batch.</span></span><br><span class="line">        <span class="comment">#    è®¡ç®—æ³¨æ„åŠ›attn å¾—åˆ°attn*v ä¸attn </span></span><br><span class="line">        <span class="comment">#    qkv :[batch, h, seq_len, embed_size/h] --&gt;</span></span><br><span class="line">        <span class="comment">#              x:[batch, h, seq_len, embed_size/h], attn[batch, h, seq_len, seq_len]</span></span><br><span class="line">        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3) "Concat" using a view and apply a final linear.</span></span><br><span class="line">        <span class="comment">#     ä¸Šä¸€æ­¥çš„ç»“æœåˆå¹¶åœ¨ä¸€èµ·è¿˜åŸæˆåŸå§‹è¾“å…¥åºåˆ—çš„å½¢çŠ¶</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(nbatches, <span class="number">-1</span>, self.h * self.d_k)</span><br><span class="line">        <span class="keyword">return</span> self.linears[<span class="number">-1</span>](x)  <span class="comment"># æœ€åå†è¿‡ä¸€ä¸ªçº¿æ€§å±‚</span></span><br></pre></td></tr></table></figure>
<h4 id="Self-Attentionçš„ä¼˜ç‚¹"><a href="#Self-Attentionçš„ä¼˜ç‚¹" class="headerlink" title="Self-Attentionçš„ä¼˜ç‚¹"></a>Self-Attentionçš„ä¼˜ç‚¹</h4><ol>
<li>å› ä¸ºæ¯ä¸ªè¯éƒ½å’Œå‘¨å›´æ‰€æœ‰è¯åšattentionï¼Œæ‰€ä»¥ä»»æ„ä¸¤ä¸ªä½ç½®éƒ½ç›¸å½“äºæœ‰ç›´è¿çº¿è·¯ï¼Œå¯æ•è·é•¿è·ç¦»ä¾èµ–ã€‚</li>
<li>Attentionçš„å¯è§£é‡Šæ€§æ›´å¥½ï¼Œæ ¹æ®Attention scoreå¯ä»¥çŸ¥é“ä¸€ä¸ªè¯å’Œå“ªäº›è¯çš„å…³ç³»æ¯”è¾ƒå¤§ã€‚</li>
<li>æ˜“äºå¹¶è¡ŒåŒ–ï¼Œå½“å‰å±‚çš„Attentionè®¡ç®—åªå’Œå‰ä¸€å±‚çš„å€¼æœ‰å…³ï¼Œæ‰€ä»¥ä¸€å±‚çš„æ‰€æœ‰èŠ‚ç‚¹å¯å¹¶è¡Œæ‰§è¡Œself-attentionæ“ä½œã€‚è®¡ç®—æ•ˆç‡é«˜ï¼Œä¸€æ¬¡Self-Attentionåªéœ€è¦ä¸¤æ¬¡çŸ©é˜µè¿ç®—ï¼Œé€Ÿåº¦å¾ˆå¿«ã€‚</li>
</ol>
<h3 id="Add-amp-Norm"><a href="#Add-amp-Norm" class="headerlink" title="Add &amp; Norm"></a>Add &amp; Norm</h3><p><code>x</code> åºåˆ—ç»è¿‡<code>Multi-Head-Self-Attention</code> ä¹‹åå®é™…ç»è¿‡ä¸€ä¸ª<code>Add+Norm</code>å±‚ï¼Œå†è¿›å…¥<code>feed-forward network(FFN)</code>ï¼Œåœ¨<code>FFN</code>ä¹‹ååˆç»è¿‡ä¸€ä¸ª<code>norm</code>å†è¾“å…¥ä¸‹ä¸€ä¸ªencoder layerã€‚å‡ ä¹æ¯ä¸ªsub layerä¹‹åéƒ½ä¼šç»è¿‡ä¸€ä¸ªå½’ä¸€åŒ–ï¼Œç„¶åå†åŠ åœ¨åŸæ¥çš„è¾“å…¥ä¸Šã€‚</p>
<figure class="highlight python"><figcaption><span>Norm</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerNorm</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Construct a layernorm module (See citation for details)."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, eps=<span class="number">1e-6</span>)</span>:</span></span><br><span class="line">        super(LayerNorm, self).__init__()</span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features)) <span class="comment"># ?</span></span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(features)) <span class="comment"># ?</span></span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        mean = x.mean(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>Add</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SublayerConnection</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A residual connection followed by a layer norm.</span></span><br><span class="line"><span class="string">    Note for code simplicity the norm is first as opposed to last.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, dropout)</span>:</span></span><br><span class="line">        super(SublayerConnection, self).__init__()</span><br><span class="line">        self.norm = LayerNorm(size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, sublayer)</span>:</span></span><br><span class="line">        <span class="string">"Apply residual connection to any sublayer with the same size."</span></span><br><span class="line">        <span class="comment"># sublayer &lt;-- encoder layer</span></span><br><span class="line">        <span class="keyword">return</span> x + self.dropout(sublayer(self.norm(x)))</span><br></pre></td></tr></table></figure>
<h3 id="Feed-Forward-Network"><a href="#Feed-Forward-Network" class="headerlink" title="Feed-Forward Network"></a>Feed-Forward Network</h3><p>Feed-Forward Networkå¯ä»¥ç»†åˆ†ä¸ºæœ‰ä¸¤å±‚ï¼Œç¬¬ä¸€å±‚æ˜¯ä¸€ä¸ªçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œç¬¬äºŒå±‚æ˜¯æ¿€æ´»å‡½æ•°æ˜¯ReLUã€‚å¯ä»¥è¡¨ç¤ºä¸ºï¼š</p>
<script type="math/tex; mode=display">
F F N=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}</script><figure class="highlight python"><figcaption><span>PositionwiseFeedForward</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""Implements FFN equation.</span></span><br><span class="line"><span class="string">    positionwiseä½“ç°åœ¨å“ªé‡Œï¼Ÿï¼Ÿ</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_ff, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">      <span class="string">"""</span></span><br><span class="line"><span class="string">      d_model: embedding_size</span></span><br><span class="line"><span class="string">      d_ff: çº¿å½¢å±‚è¾“å‡ºç»´åº¦</span></span><br><span class="line"><span class="string">      """</span></span><br><span class="line">        super(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        self.w_1 = nn.Linear(d_model, d_ff)</span><br><span class="line">        self.w_2 = nn.Linear(d_ff, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.w_2(self.dropout(F.relu(self.w_1(x))))</span><br></pre></td></tr></table></figure>
<h3 id="ç»„åˆå‡ºEncoder"><a href="#ç»„åˆå‡ºEncoder" class="headerlink" title="ç»„åˆå‡ºEncoder"></a>ç»„åˆå‡ºEncoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clones</span><span class="params">(module, N)</span>:</span></span><br><span class="line">    <span class="string">"Produce N identical layers."</span></span><br><span class="line">    <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> range(N)])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Core encoder is a stack of N layers"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N)  <span class="comment"># sub layer</span></span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span></span><br><span class="line">        <span class="string">"Pass the input (and mask) through each layer in turn."</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<h3 id="å°ç»“"><a href="#å°ç»“" class="headerlink" title="å°ç»“"></a>å°ç»“</h3><p>æ€»çš„æ¥è¯´Encoder æ˜¯ç”±ä¸Šè¿°å°encoder layer 6ä¸ªä¸²è¡Œå åŠ ç»„æˆã€‚encoder sub layerä¸»è¦åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š</p>
<ul>
<li>SubLayer-1 åš Multi-Headed Attention</li>
<li>SubLayer-2 åš Feed Forward Neural Network</li>
</ul>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>Decoderä¸Encoderæœ‰æ‰€ä¸åŒï¼ŒEncoderä¸Decoderçš„å…³ç³»å¯ä»¥ç”¨ä¸‹å›¾æè¿°ï¼š</p>
<p><img src="/2020/05/11/transformer/decoder.png" alt></p>
<figure class="highlight python"><figcaption><span>Decoder</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Generic N layer decoder with masking."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span> </span><br><span class="line">      	<span class="comment"># memory Encoderæœ€åçš„è¾“å‡ºã€‚ </span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, memory, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<p>Decoder å­ç»“æ„ï¼ˆsub layerï¼‰ï¼š</p>
<p><img src="/2020/05/11/transformer/decoder_layer.png" alt></p>
<p>Decoder ä¹Ÿæ˜¯N=6å±‚å †å çš„ç»“æ„ã€‚è¢«åˆ†ä¸º3ä¸ª SubLayerï¼ŒEncoderä¸Decoderæœ‰ä¸‰å¤§ä¸»è¦çš„ä¸åŒï¼š</p>
<ol>
<li>Decoder SubLayer-1 ä½¿ç”¨çš„æ˜¯ â€œMaskedâ€ Multi-Headed Attention æœºåˆ¶ï¼Œé˜²æ­¢ä¸ºäº†æ¨¡å‹çœ‹åˆ°è¦é¢„æµ‹çš„æ•°æ®ï¼Œé˜²æ­¢æ³„éœ²ã€‚</li>
<li>SubLayer-2 æ˜¯ä¸€ä¸ª Encoder-Decoder Multi-head Attentionã€‚</li>
<li>LinearLayer å’Œ SoftmaxLayer ä½œç”¨äº SubLayer-3 çš„è¾“å‡ºåé¢ï¼Œæ¥é¢„æµ‹å¯¹åº”çš„ word çš„ probabilities ã€‚</li>
</ol>
<h3 id="Mask-Multi-Head-Attention"><a href="#Mask-Multi-Head-Attention" class="headerlink" title="Mask-Multi-Head-Attention"></a>Mask-Multi-Head-Attention</h3><p>Mask çš„ç›®çš„æ˜¯é˜²æ­¢ Decoder â€œseeing the futureâ€ï¼Œé˜²æ­¢æå‰çŸ¥é“é¢„æµ‹çš„å†…å®¹ï¼ˆensures that the predictions for position $i$ can depend only on the known outputs at positions less than $i$.ï¼‰,è¿™ä¹Ÿè¯´æ˜Transformeråªæ˜¯åœ¨Encoderé˜¶æ®µå¯ä»¥å¹¶è¡ŒåŒ–ï¼ŒDecoderé˜¶æ®µä¾ç„¶è¦ä¸€ä¸ªä¸ªè¯é¡ºåºç¿»è¯‘ï¼Œä¾ç„¶æ˜¯<strong>ä¸²è¡Œ</strong>çš„ã€‚è¿™é‡Œmaskæ˜¯ä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µï¼Œå¯¹è§’çº¿ä»¥åŠå¯¹è§’çº¿å·¦ä¸‹éƒ½æ˜¯1ï¼Œå…¶ä½™éƒ½æ˜¯0ã€‚</p>
<figure class="highlight python"><figcaption><span>subsequent_mask</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subsequent_mask</span><span class="params">(size)</span>:</span></span><br><span class="line">    <span class="string">""""Mask out subsequent positions.</span></span><br><span class="line"><span class="string">    maskåç»­çš„ä½ç½®ï¼Œè¿”å›[size, size]å°ºå¯¸ä¸‹ä¸‰è§’Tensor</span></span><br><span class="line"><span class="string">    å¯¹è§’çº¿åŠå…¶å·¦ä¸‹è§’å…¨æ˜¯1ï¼Œå³ä¸Šè§’å…¨æ˜¯0</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    attn_shape = (<span class="number">1</span>, size, size)</span><br><span class="line">    <span class="comment"># np.triu()  Upper triangle of an array: è¿”å›çŸ©é˜µä¸Šä¸‰è§’</span></span><br><span class="line">    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(subsequent_mask) == <span class="number">0</span> <span class="comment"># ç­‰äº0ï¼Œè¿”å›çš„æ˜¯çŸ©é˜µçš„ä¸‹ä¸‰è§’</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">plt.imshow(subsequent_mask(<span class="number">20</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>ç»“æœå¦‚ä¸‹ï¼š</p>
<p><img src="/2020/05/11/transformer/subsequent_mask.png" alt></p>
<p>subsequent_mask è¿”å›ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]], dtype=torch.uint8)</span><br></pre></td></tr></table></figure>
<p>å½“maskä¸ä¸ºç©ºçš„æ—¶å€™ï¼Œattentionè®¡ç®—éœ€è¦å°†xåšä¸€ä¸ªæ“ä½œï¼šscores = scores.masked_fill(mask == 0, -1e9)ã€‚å³å°†mask==0çš„æ›¿æ¢ä¸º-1e9,å…¶ä½™ä¸å˜ã€‚</p>
<h3 id="Encoder-Decoder-Multi-head-Attention"><a href="#Encoder-Decoder-Multi-head-Attention" class="headerlink" title="Encoder-Decoder Multi-head Attention"></a>Encoder-Decoder Multi-head Attention</h3><p>è¿™éƒ¨åˆ†å’ŒMulti-head Attentionçš„åŒºåˆ«æ˜¯è¯¥å±‚çš„è¾“å…¥æ¥è‡ªencoderå’Œä¸Šä¸€æ¬¡decoderçš„ç»“æœã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Decoder is made of self-attn, src-attn, and feed forward (defined below)"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, src_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(DecoderLayer, self).__init__()</span><br><span class="line">        self.size = size</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.src_attn = src_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">3</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="string">"Follow Figure 1 (right) for connections."</span></span><br><span class="line">      	<span class="comment"># å°†decoderçš„ä¸‰ä¸ªSublayerä¸²è”èµ·æ¥</span></span><br><span class="line">        m = memory <span class="comment"># ä¸ºencoder æœ€åçš„è¾“å‡º</span></span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask))</span><br><span class="line">        x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask))</span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure>
<h3 id="Linear-and-Softmax-to-Produce-Output-Probabilities"><a href="#Linear-and-Softmax-to-Produce-Output-Probabilities" class="headerlink" title="Linear and Softmax to Produce Output Probabilities"></a>Linear and Softmax to Produce Output Probabilities</h3><p>Decoderçš„æœ€åä¸€ä¸ªéƒ¨åˆ†æ˜¯è¿‡ä¸€ä¸ªlinear layerå°†decoderçš„è¾“å‡ºæ‰©å±•åˆ°ä¸vocabulary sizeä¸€æ ·çš„ç»´åº¦ä¸Šã€‚ç»è¿‡softmax åï¼Œé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ä¸€ä¸ªwordä½œä¸ºé¢„æµ‹ç»“æœã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„ç½‘ç»œï¼Œåœ¨åšé¢„æµ‹æ—¶ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ol>
<li>ç»™ decoder è¾“å…¥ encoder å¯¹æ•´ä¸ªå¥å­ embedding çš„ç»“æœå’Œä¸€ä¸ªç‰¹æ®Šçš„å¼€å§‹ç¬¦å· &lt;/s&gt;ã€‚decoder å°†äº§ç”Ÿé¢„æµ‹ï¼Œåœ¨ä¾‹å­ä¸­åº”è¯¥æ˜¯ <code>I</code>ã€‚</li>
<li>ç»™ decoder è¾“å…¥ encoder çš„ embedding ç»“æœå’Œ â€œ&lt;/s&gt; Iâ€ï¼Œåœ¨è¿™ä¸€æ­¥ decoder åº”è¯¥äº§ç”Ÿé¢„æµ‹ <code>am</code>ã€‚</li>
<li>ç»™ decoder è¾“å…¥ encoder çš„ embedding ç»“æœå’Œ â€œ&lt;/s&gt; I amâ€ï¼Œåœ¨è¿™ä¸€æ­¥ decoder åº”è¯¥äº§ç”Ÿé¢„æµ‹ <code>a</code>ã€‚</li>
<li>ç»™ decoder è¾“å…¥ encoder çš„ embedding ç»“æœå’Œ â€œ&lt;/s&gt; I am aâ€ï¼Œåœ¨è¿™ä¸€æ­¥ decoder åº”è¯¥äº§ç”Ÿé¢„æµ‹ <code>student</code>ã€‚</li>
<li>ç»™ decoder è¾“å…¥ encoder çš„ embedding ç»“æœå’Œ â€œ&lt;/s&gt;I am a studentâ€, decoderåº”è¯¥ç”Ÿæˆå¥å­ç»“å°¾çš„æ ‡è®°ï¼Œdecoder åº”è¯¥è¾“å‡º <code>&lt;/eos&gt;</code>ã€‚</li>
<li>ç„¶å decoder ç”Ÿæˆäº† &lt;/eos&gt;ï¼Œç¿»è¯‘å®Œæˆã€‚</li>
</ol>
<p>è¿™éƒ¨åˆ†çš„ä»£ç å®ç°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Define standard linear + softmax generation step."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">    		<span class="string">"""</span></span><br><span class="line"><span class="string">    		d_model:decoder è¾“å‡ºçš„embedding size</span></span><br><span class="line"><span class="string">    		vocabï¼šç›®æ ‡çš„è¯æ±‡è¡¨å¤§å°</span></span><br><span class="line"><span class="string">    		"""</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line">        self.proj = nn.Linear(d_model, vocab)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(self.proj(x), dim=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="EncoderDecoder"><a href="#EncoderDecoder" class="headerlink" title="EncoderDecoder"></a>EncoderDecoder</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A standard Encoder-Decoder architecture. Base for this and many </span></span><br><span class="line"><span class="string">    other models.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder, src_embed, tgt_embed, generator)</span>:</span></span><br><span class="line">        super(EncoderDecoder, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        self.src_embed = src_embed <span class="comment"># embedding</span></span><br><span class="line">        self.tgt_embed = tgt_embed <span class="comment"># embedding</span></span><br><span class="line">        self.generator = generator <span class="comment"># ç”¨äºç”Ÿæˆç¿»è¯‘ç›®æ ‡ï¼ˆLinear + softmax --&gt; probï¼‰</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src, tgt, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="string">"Take in and process masked src and target sequences."</span></span><br><span class="line">        <span class="keyword">return</span> self.decode(self.encode(src, src_mask), src_mask,</span><br><span class="line">                            tgt, tgt_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, src, src_mask)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.encoder(self.src_embed(src), src_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, memory, src_mask, tgt, tgt_mask)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)</span><br></pre></td></tr></table></figure>
<h2 id="Full-Model"><a href="#Full-Model" class="headerlink" title="Full Model"></a>Full Model</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">(src_vocab, tgt_vocab, N=<span class="number">6</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               d_model=<span class="number">512</span>, d_ff=<span class="number">2048</span>, h=<span class="number">8</span>, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">    <span class="string">"Helper: Construct a model from hyperparameters."</span></span><br><span class="line">    c = copy.deepcopy</span><br><span class="line">    attn = MultiHeadedAttention(h, d_model)</span><br><span class="line">    ff = PositionwiseFeedForward(d_model, d_ff, dropout) <span class="comment"># linear(relu(linear(x)))</span></span><br><span class="line">    position = PositionalEncoding(d_model, dropout)</span><br><span class="line">    model = EncoderDecoder(</span><br><span class="line">        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),</span><br><span class="line">        Decoder(DecoderLayer(d_model, c(attn), c(attn), </span><br><span class="line">                             c(ff), dropout), N),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),</span><br><span class="line">        Generator(d_model, tgt_vocab))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># This was important from their code. </span></span><br><span class="line">    <span class="comment"># Initialize parameters with Glorot / fan_avg.</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line">            nn.init.xavier_uniform(p)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><p>è¿™éƒ¨åˆ†ä¸»è¦æ ¹æ®è‡ªå·±çš„ç†è§£å¯¹ä»£ç åŠ æ³¨é‡Š</p>
<h2 id="Batches-and-Masking"><a href="#Batches-and-Masking" class="headerlink" title="Batches and Masking"></a>Batches and Masking</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch</span>:</span></span><br><span class="line">    <span class="string">"Object for holding a batch of data with mask during training."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, src, trg=None, pad=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.src = src</span><br><span class="line">        self.src_mask = (src != pad).unsqueeze(<span class="number">-2</span>) <span class="comment"># å¯¹è¶…å‡ºå¥å­é•¿åº¦éƒ¨åˆ†mask</span></span><br><span class="line">        <span class="keyword">if</span> trg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.trg = trg[:, :<span class="number">-1</span>]</span><br><span class="line">            self.trg_y = trg[:, <span class="number">1</span>:]</span><br><span class="line">            self.trg_mask = self.make_std_mask(self.trg, pad) <span class="comment"># mask to hide padding and future words</span></span><br><span class="line">            self.ntokens = (self.trg_y != pad).data.sum()</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_std_mask</span><span class="params">(tgt, pad)</span>:</span></span><br><span class="line">        <span class="string">"Create a mask to hide padding and future words."</span></span><br><span class="line">        tgt_mask = (tgt != pad).unsqueeze(<span class="number">-2</span>)</span><br><span class="line">        tgt_mask = tgt_mask &amp; Variable(</span><br><span class="line">            subsequent_mask(tgt.size(<span class="number">-1</span>)).type_as(tgt_mask.data))</span><br><span class="line">        <span class="keyword">return</span> tgt_mask</span><br></pre></td></tr></table></figure>
<h2 id="Training-Loop"><a href="#Training-Loop" class="headerlink" title="Training Loop"></a>Training Loop</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_epoch</span><span class="params">(data_iter, model, loss_compute)</span>:</span></span><br><span class="line">    <span class="string">"Standard Training and Logging Function"</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    total_tokens = <span class="number">0</span></span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    tokens = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(data_iter):</span><br><span class="line">        out = model.forward(batch.src, batch.trg, </span><br><span class="line">                            batch.src_mask, batch.trg_mask)</span><br><span class="line">        loss = loss_compute(out, batch.trg_y, batch.ntokens)</span><br><span class="line">        total_loss += loss</span><br><span class="line">        total_tokens += batch.ntokens</span><br><span class="line">        tokens += batch.ntokens</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">1</span>:</span><br><span class="line">            elapsed = time.time() - start</span><br><span class="line">            print(<span class="string">"Epoch Step: %d Loss: %f Tokens per Sec: %f"</span> %</span><br><span class="line">                    (i, loss / batch.ntokens, tokens / elapsed))</span><br><span class="line">            start = time.time()</span><br><span class="line">            tokens = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> total_loss / total_tokens</span><br></pre></td></tr></table></figure>
<h2 id="Training-Data"><a href="#Training-Data" class="headerlink" title="Training Data"></a>Training Data</h2><p>ä½¿ç”¨æ ‡å‡†WMT 2014è‹±è¯­-å¾·è¯­æ•°æ®é›†è¿›è¡Œäº†è®­ç»ƒï¼Œè¯¥æ•°æ®é›†åŒ…å«å¤§çº¦450ä¸‡ä¸ªå¥å­å¯¹ã€‚ ä½¿ç”¨å­—èŠ‚å¯¹çš„ç¼–ç æ–¹æ³•å¯¹å¥å­è¿›è¡Œç¼–ç ï¼Œè¯¥ç¼–ç å…·æœ‰å¤§çº¦37000ä¸ªè¯çš„å…±äº«æº-ç›®æ ‡è¯æ±‡è¡¨ã€‚ å¯¹äºè‹±è¯­-æ³•è¯­ï¼Œä½¿ç”¨äº†WMT 2014 è‹±è¯­-æ³•è¯­æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”±36Mä¸ªå¥å­ç»„æˆï¼Œå¹¶å°†è¯åˆ†æˆ32000ä¸ªè¯ç‰‡(Word-piece)çš„è¯æ±‡è¡¨ã€‚å¥å­å¯¹æŒ‰ç…§è¿‘ä¼¼çš„åºåˆ—é•¿åº¦è¿›è¡Œæ‰¹å¤„ç†ã€‚æ¯ä¸ªè®­ç»ƒæ‰¹åŒ…å«ä¸€ç»„å¥å­å¯¹ï¼ŒåŒ…å«å¤§çº¦25000ä¸ªæºè¯å’Œ25000ä¸ªç›®æ ‡è¯ã€‚</p>
<p>ä½¿ç”¨torch textæ¥åˆ›å»ºbatchã€‚åœ¨torchtextçš„ä¸€ä¸ªå‡½æ•°ä¸­åˆ›å»ºbatchï¼Œç¡®ä¿å¡«å……åˆ°æœ€å¤§batchè®­ç»ƒé•¿åº¦çš„å¤§å°ä¸è¶…è¿‡é˜ˆå€¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_size_fn</span><span class="params">(new, count, sofar)</span>:</span></span><br><span class="line">    <span class="string">"Keep augmenting batch and calculate total number of tokens + padding."</span></span><br><span class="line">    <span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">1</span>: <span class="comment"># ï¼Ÿï¼Ÿ</span></span><br><span class="line">        max_src_in_batch = <span class="number">0</span></span><br><span class="line">        max_tgt_in_batch = <span class="number">0</span></span><br><span class="line">    max_src_in_batch = max(max_src_in_batch,  len(new.src))</span><br><span class="line">    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + <span class="number">2</span>)</span><br><span class="line">    src_elements = count * max_src_in_batch</span><br><span class="line">    tgt_elements = count * max_tgt_in_batch</span><br><span class="line">    <span class="keyword">return</span> max(src_elements, tgt_elements)</span><br></pre></td></tr></table></figure>
<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><p>é€‰æ‹©Adamä½œä¸ºä¼˜åŒ–å™¨ï¼Œå…¶å‚æ•°ä¸º$\beta_1 = 0.9, \beta_2=0.98,\epsilon=10^{-9}$ã€‚æ ¹æ®$lrate = d_{model}^{- \frac{1}{2}} * min(step_num^{- \frac{1}{2}},step_num \cdot warmup_steps^{-1.5})$ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¹å˜äº†å­¦ä¹ ç‡ã€‚åœ¨<code>warm_up</code>ä¸­éšæ­¥æ•°çº¿æ€§åœ°å¢åŠ å­¦ä¹ é€Ÿç‡ï¼Œéšåä¸æ­¥æ•°çš„åå¹³æ–¹æ ¹æˆæ¯”ä¾‹åœ°å‡å°å®ƒã€‚é¢„çƒ­<code>warmup_steps</code>ä¸º4000ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoamOpt</span>:</span></span><br><span class="line">    <span class="string">"Optim wrapper that implements rate."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model_size, factor, warmup, optimizer)</span>:</span></span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self._step = <span class="number">0</span></span><br><span class="line">        self.warmup = warmup</span><br><span class="line">        self.factor = factor</span><br><span class="line">        self.model_size = model_size</span><br><span class="line">        self._rate = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"Update parameters and rate"</span></span><br><span class="line">        self._step += <span class="number">1</span></span><br><span class="line">        rate = self.rate()</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.optimizer.param_groups:</span><br><span class="line">            p[<span class="string">'lr'</span>] = rate</span><br><span class="line">        self._rate = rate</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rate</span><span class="params">(self, step = None)</span>:</span></span><br><span class="line">        <span class="string">"Implement `lrate` above"</span></span><br><span class="line">        <span class="keyword">if</span> step <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            step = self._step</span><br><span class="line">        <span class="comment"># å¯¹åº”ä¸Šé¢å…¬å¼</span></span><br><span class="line">        <span class="keyword">return</span> self.factor * (self.model_size ** (<span class="number">-0.5</span>) * min(step ** (<span class="number">-0.5</span>), step * self.warmup ** (<span class="number">-1.5</span>)))</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_std_opt</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">2</span>, <span class="number">4000</span>,torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">opts = [NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>), </span><br><span class="line">        NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">8000</span>, <span class="literal">None</span>),</span><br><span class="line">        NoamOpt(<span class="number">256</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>)]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">20000</span>), [[opt.rate(i) <span class="keyword">for</span> opt <span class="keyword">in</span> opts] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">20000</span>)])</span><br><span class="line">plt.legend([<span class="string">"512:4000"</span>, <span class="string">"512:8000"</span>, <span class="string">"256:4000"</span>])</span><br></pre></td></tr></table></figure>
<p><img src="/2020/05/11/transformer/warm_up.png" alt="screenshot"></p>
<p>ä¹Ÿå°±æ˜¯è¯´ï¼š</p>
<ol>
<li>åœ¨embedding sizeç›¸åŒçš„æƒ…å†µä¸‹ï¼Œwarm upæ­¥æ•°è¶Šå°‘ï¼Œå‰æœŸçš„å­¦ä¹ ç‡æ›²çº¿è¶Šé™¡å³­ï¼Œå­¦çš„è¶Šå¿«ã€‚</li>
<li>åœ¨warm upæ­¥æ•°ç›¸åŒçš„æ—¶å€™ï¼Œembedding size è¶Šå°ï¼Œå‰æœŸçš„å­¦ä¹ ç‡æ›²çº¿è¶Šé™¡å³­ï¼Œå­¦çš„è¶Šå¿«ã€‚</li>
</ol>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><h3 id="Label-Smoothing"><a href="#Label-Smoothing" class="headerlink" title="Label Smoothing"></a>Label Smoothing</h3><h4 id="èƒŒæ™¯ä»‹ç»"><a href="#èƒŒæ™¯ä»‹ç»" class="headerlink" title="èƒŒæ™¯ä»‹ç»"></a>èƒŒæ™¯ä»‹ç»</h4><p>åœ¨å¤šåˆ†ç±»è®­ç»ƒä»»åŠ¡ä¸­ï¼Œè¾“å…¥ç»è¿‡ç¥çº§ç½‘ç»œçš„è®¡ç®—ï¼Œä¼šå¾—åˆ°å½“å‰è¾“å…¥å¯¹åº”äºå„ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ï¼Œè¿™äº›åˆ†æ•°ä¼šè¢«softmaxè¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œæœ€ç»ˆå¾—åˆ°å½“å‰è¾“å…¥å±äºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚</p>
<script type="math/tex; mode=display">
q_{i}=\frac{\exp \left(z_{i}\right)}{\sum_{j=1}^{K} \exp \left(z_{j}\right)}</script><p>ä¹‹ååœ¨ä½¿ç”¨äº¤å‰ç†µå‡½æ•°æ¥è®¡ç®—æŸå¤±å€¼ï¼š</p>
<script type="math/tex; mode=display">
\begin{aligned}
&L o s s=-\sum_{i=1}^{K} p_{i} \log q_{i}\\
&p_{i}=\left\{\begin{array}{l}
1, \text { if }(i=y) \\
0, i f(i \neq y)
\end{array}\right.
\end{aligned}</script><p>å…¶ä¸­ï¼Œiè¡¨ç¤ºå¤šç±»ä¸­çš„æŸä¸€ç±»ã€‚</p>
<p>æœ€ç»ˆåœ¨è®­ç»ƒç½‘ç»œæ—¶ï¼Œæœ€å°åŒ–é¢„æµ‹æ¦‚ç‡å’Œæ ‡ç­¾çœŸå®æ¦‚ç‡çš„äº¤å‰ç†µï¼Œä»è€Œå¾—åˆ°æœ€ä¼˜çš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä¸ºäº†è¾¾åˆ°æœ€å¥½çš„æ‹Ÿåˆæ•ˆæœï¼Œæœ€ä¼˜çš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒä¸ºï¼š</p>
<script type="math/tex; mode=display">
Z_{i}=\left\{\begin{array}{l}
+\infty, i f(i=y) \\
0, i f(i \neq y)
\end{array}\right.</script><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œç½‘ç»œä¼šé©±ä½¿è‡ªèº«å¾€æ­£ç¡®æ ‡ç­¾å’Œé”™è¯¯æ ‡ç­¾å·®å€¼å¤§çš„æ–¹å‘å­¦ä¹ ï¼Œåœ¨è®­ç»ƒæ•°æ®ä¸è¶³ä»¥è¡¨å¾æ‰€ä»¥çš„æ ·æœ¬ç‰¹å¾çš„æƒ…å†µä¸‹ï¼Œå°±<strong>ä¼šå¯¼è‡´ç½‘ç»œè¿‡æ‹Ÿåˆ</strong>ã€‚</p>
<h4 id="label-smoothingåŸç†"><a href="#label-smoothingåŸç†" class="headerlink" title="label smoothingåŸç†"></a>label smoothingåŸç†</h4><p>label smoothingçš„æå‡ºå°±æ˜¯ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæ˜¯ä¸€ç§æ­£åˆ™åŒ–çš„ç­–ç•¥ã€‚å…¶é€šè¿‡â€è½¯åŒ–â€ä¼ ç»Ÿçš„one-hotç±»å‹æ ‡ç­¾ï¼Œä½¿å¾—åœ¨è®¡ç®—æŸå¤±å€¼æ—¶èƒ½å¤Ÿæœ‰æ•ˆæŠ‘åˆ¶è¿‡æ‹Ÿåˆç°è±¡ã€‚label smoothingç›¸å½“äºå‡å°‘çœŸå®æ ·æœ¬æ ‡ç­¾çš„ç±»åˆ«åœ¨è®¡ç®—æŸå¤±å‡½æ•°æ—¶çš„æƒé‡ï¼Œæœ€ç»ˆèµ·åˆ°æŠ‘åˆ¶è¿‡æ‹Ÿåˆçš„æ•ˆæœã€‚</p>
<p>1.label smoothingå°†çœŸå®æ¦‚ç‡åˆ†å¸ƒä½œå¦‚ä¸‹æ”¹å˜ï¼š</p>
<script type="math/tex; mode=display">
P_{i}=\left\{\begin{array}{l}
1, i f(i=y) \\
0, i f(i \neq y)
\end{array} \Longrightarrow  P_{i}=\left\{\begin{array}{l}
(1-\varepsilon), i f(i=y) \\
\frac{\varepsilon}{K-1}, i f(i \neq y)
\end{array}\right.\right.</script><p>å…¶å®æ›´æ–°åçš„åˆ†å¸ƒå°±ç›¸å½“äºå¾€çœŸå®åˆ†å¸ƒä¸­åŠ å…¥äº†å™ªå£°ï¼Œä¸ºäº†ä¾¿äºè®¡ç®—ï¼Œè¯¥å™ªå£°æœä»ç®€å•çš„å‡åŒ€åˆ†å¸ƒã€‚</p>
<p>2.ä¸ä¹‹å¯¹åº”ï¼Œlabel smoothingå°†äº¤å‰ç†µæŸå¤±å‡½æ•°ä½œå¦‚ä¸‹æ”¹å˜ï¼š</p>
<script type="math/tex; mode=display">
L o s s=-\sum_{i=1}^{K} p_{i} \log q_{i} \Longrightarrow \operatorname{Loss}_{i}=\left\{\begin{array}{l}
(1-\varepsilon)^{*} \operatorname{Loss}, \text {if}(i=y) \\
\varepsilon^{*} \operatorname{Loss}, \text {if}(i \neq y)
\end{array}\right.</script><p>3.ä¸ä¹‹å¯¹åº”ï¼Œlabel smoothingå°†æœ€ä¼˜çš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒä½œå¦‚ä¸‹æ”¹å˜ï¼š</p>
<script type="math/tex; mode=display">
Z_{i}=\left\{\begin{array}{l}
+\infty, i f(i=y) \\
0, i f(i \neq y)
\end{array} \Longrightarrow Z_{i}=\left\{\begin{array}{l}
\log \frac{(k-1)(1-\varepsilon)}{\varepsilon+\alpha}, i f(i=y) \\
\alpha, i f(i \neq y)
\end{array}\right.\right.</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement label smoothing."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, padding_idx, smoothing=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        super(LabelSmoothing, self).__init__()</span><br><span class="line">        self.criterion = nn.KLDivLoss(size_average=<span class="literal">False</span>)</span><br><span class="line">        self.padding_idx = padding_idx</span><br><span class="line">        self.confidence = <span class="number">1.0</span> - smoothing</span><br><span class="line">        self.smoothing = smoothing</span><br><span class="line">        self.size = size</span><br><span class="line">        self.true_dist = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, target)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> x.size(<span class="number">1</span>) == self.size</span><br><span class="line">        true_dist = x.data.clone()</span><br><span class="line">        true_dist.fill_(self.smoothing / (self.size - <span class="number">2</span>)) <span class="comment"># ?</span></span><br><span class="line">        true_dist.scatter_(<span class="number">1</span>, target.data.unsqueeze(<span class="number">1</span>), self.confidence)</span><br><span class="line">        true_dist[:, self.padding_idx] = <span class="number">0</span></span><br><span class="line">        mask = torch.nonzero(target.data == self.padding_idx)</span><br><span class="line">        <span class="keyword">if</span> mask.dim() &gt; <span class="number">0</span>:</span><br><span class="line">            true_dist.index_fill_(<span class="number">0</span>, mask.squeeze(), <span class="number">0.0</span>)</span><br><span class="line">        self.true_dist = true_dist</span><br><span class="line">        <span class="keyword">return</span> self.criterion(x, Variable(true_dist, requires_grad=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>
<p>åœ¨è®­ç»ƒæœŸé—´ï¼Œé‡‡ç”¨äº†å€¼ $\epsilon_{ls}=0.1$çš„æ ‡ç­¾å¹³æ»‘ã€‚ è¿™ç§åšæ³•æé«˜äº†å›°æƒ‘åº¦ï¼Œå› ä¸ºæ¨¡å‹å˜å¾—æ›´åŠ ä¸ç¡®å®šï¼Œä½†æé«˜äº†å‡†ç¡®æ€§å’ŒBLEUåˆ†æ•°ã€‚ä½¿ç”¨KL div losså®ç°æ ‡ç­¾å¹³æ»‘ã€‚ ç›¸æ¯”ä½¿ç”¨ç‹¬çƒ­ç›®æ ‡åˆ†å¸ƒï¼Œå…¶åŒ…å«æ­£ç¡®å•è¯çš„ç½®ä¿¡åº¦å’Œæ•´ä¸ªè¯æ±‡è¡¨ä¸­åˆ†å¸ƒçš„å…¶ä½™å¹³æ»‘é¡¹ã€‚å¯ä»¥çœ‹åˆ°æ ‡ç­¾å¹³æ»‘çš„ç¤ºä¾‹:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of label smoothing.</span></span><br><span class="line"><span class="comment"># embed_size = 5, padding_idx=0,smoothing=0.4</span></span><br><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.4</span>)</span><br><span class="line">predict = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">                             [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>], </span><br><span class="line">                             [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>]])</span><br><span class="line">v = crit(Variable(predict.log()), </span><br><span class="line">         Variable(torch.LongTensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the target distributions expected by the system.</span></span><br><span class="line">plt.imshow(crit.true_dist)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/05/11/transformer/label_smooth.png" alt="screenshot"></p>
<p>Emmm,ä¸Šå›¾æ²¡çœ‹æ‡‚ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(x)</span>:</span></span><br><span class="line">    d = x + <span class="number">3</span> * <span class="number">1</span></span><br><span class="line">    predict = torch.FloatTensor([[<span class="number">0</span>, x / d, <span class="number">1</span> / d, <span class="number">1</span> / d, <span class="number">1</span> / d],</span><br><span class="line">                                 ])</span><br><span class="line">    <span class="comment">#print(predict)</span></span><br><span class="line">    <span class="keyword">return</span> crit(Variable(predict.log()),</span><br><span class="line">                 Variable(torch.LongTensor([<span class="number">1</span>]))).data[<span class="number">0</span>]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">100</span>), [loss(x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">100</span>)])</span><br></pre></td></tr></table></figure>
<p>å¦‚æœå¯¹ç»™å®šçš„é€‰æ‹©éå¸¸æœ‰ä¿¡å¿ƒï¼Œæ ‡ç­¾å¹³æ»‘å®é™…ä¸Šä¼šå¼€å§‹æƒ©ç½šæ¨¡å‹ã€‚???æ€ä¹ˆçœ‹å‡ºæ¥çš„ï¼Ÿæˆ‘æ²¡çœ‹æ‡‚ï¼</p>
<p><img src="/2020/05/11/transformer/penate.png" alt="screenshot"></p>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><h3 id="Copy-Task"><a href="#Copy-Task" class="headerlink" title="Copy Task"></a>Copy Task</h3><h4 id="Synthetic-Data"><a href="#Synthetic-Data" class="headerlink" title="Synthetic Data"></a>Synthetic Data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_gen</span><span class="params">(V, batch, nbatches)</span>:</span></span><br><span class="line">    <span class="string">"Generate random data for a src-tgt copy task."</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nbatches):</span><br><span class="line">        data = torch.from_numpy(np.random.randint(<span class="number">1</span>, V, size=(batch, <span class="number">10</span>)))</span><br><span class="line">        data[:, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        src = Variable(data, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        tgt = Variable(data, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">yield</span> Batch(src, tgt, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Loss-Computation"><a href="#Loss-Computation" class="headerlink" title="Loss Computation"></a>Loss Computation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLossCompute</span>:</span></span><br><span class="line">    <span class="string">"A simple loss compute and train function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion, opt=None)</span>:</span></span><br><span class="line">        self.generator = generator</span><br><span class="line">        self.criterion = criterion</span><br><span class="line">        self.opt = opt</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, y, norm)</span>:</span></span><br><span class="line">        x = self.generator(x)</span><br><span class="line">        loss = self.criterion(x.contiguous().view(<span class="number">-1</span>, x.size(<span class="number">-1</span>)), </span><br><span class="line">                              y.contiguous().view(<span class="number">-1</span>)) / norm</span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.opt.step()</span><br><span class="line">            self.opt.optimizer.zero_grad()</span><br><span class="line">        <span class="keyword">return</span> loss.data[<span class="number">0</span>] * norm</span><br></pre></td></tr></table></figure>
<h4 id="Greedy-Decoding"><a href="#Greedy-Decoding" class="headerlink" title="Greedy Decoding"></a>Greedy Decoding</h4><p>è´ªå¿ƒè§£ç ã€‚ã€‚ã€‚å¤§ä½¬ä»¬çœŸä¼šèµ·åå­—ï¼ï¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train the simple copy task.</span></span><br><span class="line">V = <span class="number">11</span></span><br><span class="line">criterion = LabelSmoothing(size=V, padding_idx=<span class="number">0</span>, smoothing=<span class="number">0.0</span>)</span><br><span class="line">model = make_model(V, V, N=<span class="number">2</span>)</span><br><span class="line">model_opt = NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">400</span>,</span><br><span class="line">        torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">20</span>), model, </span><br><span class="line">              SimpleLossCompute(model.generator, criterion, model_opt))</span><br><span class="line">    model.eval()</span><br><span class="line">    print(run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">5</span>), model, </span><br><span class="line">                    SimpleLossCompute(model.generator, criterion, <span class="literal">None</span>)))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedy_decode</span><span class="params">(model, src, src_mask, max_len, start_symbol)</span>:</span></span><br><span class="line">    memory = model.encode(src, src_mask)</span><br><span class="line">    ys = torch.ones(<span class="number">1</span>, <span class="number">1</span>).fill_(start_symbol).type_as(src.data)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_len<span class="number">-1</span>):</span><br><span class="line">        out = model.decode(memory, src_mask, </span><br><span class="line">                           Variable(ys), </span><br><span class="line">                           Variable(subsequent_mask(ys.size(<span class="number">1</span>))</span><br><span class="line">                                    .type_as(src.data)))</span><br><span class="line">        prob = model.generator(out[:, <span class="number">-1</span>])</span><br><span class="line">        _, next_word = torch.max(prob, dim = <span class="number">1</span>)</span><br><span class="line">        next_word = next_word.data[<span class="number">0</span>]</span><br><span class="line">        ys = torch.cat([ys, </span><br><span class="line">                        torch.ones(<span class="number">1</span>, <span class="number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> ys</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line">src = Variable(torch.LongTensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]]) )</span><br><span class="line">src_mask = Variable(torch.ones(<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>) )</span><br><span class="line">print(greedy_decode(model, src, src_mask, max_len=<span class="number">10</span>, start_symbol=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><figcaption><span>result</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span></span><br><span class="line">[torch.LongTensor of size <span class="number">1</span>x10]</span><br></pre></td></tr></table></figure>
<p>ç¿»è¯‘çš„ä¾‹å­æ¶‰åŠGPUå¹¶è¡Œæ¯”è¾ƒå¤æ‚ï¼Œä¸åšä»‹ç»ã€‚</p>
<h1 id="Attention-Visualization"><a href="#Attention-Visualization" class="headerlink" title="Attention Visualization"></a>Attention Visualization</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">tgt_sent = trans.split()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span><span class="params">(data, x, y, ax)</span>:</span></span><br><span class="line">    seaborn.heatmap(data, </span><br><span class="line">                    xticklabels=x, square=<span class="literal">True</span>, yticklabels=y, vmin=<span class="number">0.0</span>, vmax=<span class="number">1.0</span>, </span><br><span class="line">                    cbar=<span class="literal">False</span>, ax=ax)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>):</span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>,<span class="number">4</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    print(<span class="string">"Encoder Layer"</span>, layer+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">        draw(model.encoder.layers[layer].self_attn.attn[<span class="number">0</span>, h].data, sent, sent <span class="keyword">if</span> h ==<span class="number">0</span> <span class="keyword">else</span> [], ax=axs[h])</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>):</span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>,<span class="number">4</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    print(<span class="string">"Decoder Self Layer"</span>, layer+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">        draw(model.decoder.layers[layer].self_attn.attn[<span class="number">0</span>, h].data[:len(tgt_sent), :len(tgt_sent)], tgt_sent, tgt_sent <span class="keyword">if</span> h ==<span class="number">0</span> <span class="keyword">else</span> [], ax=axs[h])</span><br><span class="line">    plt.show()</span><br><span class="line">    print(<span class="string">"Decoder Src Layer"</span>, layer+<span class="number">1</span>)</span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>,<span class="number">4</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">        draw(model.decoder.layers[layer].self_attn.attn[<span class="number">0</span>, h].data[:len(tgt_sent), :len(sent)],sent, tgt_sent <span class="keyword">if</span> h ==<span class="number">0</span> <span class="keyword">else</span> [], ax=axs[h])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="Encoder-visualization"><a href="#Encoder-visualization" class="headerlink" title="Encoder visualization"></a>Encoder visualization</h2><div class="note info">
            <p>Encoder Layer 2</p>
          </div>
<p><img src="/2020/05/11/transformer/encoder_layer_2.png" alt="screenshot"></p>
<div class="note info">
            <p>Encoder Layer 2</p>
          </div>
<p><img src="/2020/05/11/transformer/encoder_layer_4.png" alt="screenshot"></p>
<div class="note info">
            <p>Encoder Layer 6ï¼Œè¿™ä¸€å±‚è¯´æ˜äº†å•¥ï¼Ÿï¼Ÿ</p>
          </div>
<p><img src="/2020/05/11/transformer/image-20200511115252714.png" alt="image-20200511115252714"></p>
<p>åŒä¸€è¡Œï¼Œæ¯”è¾ƒä¸åŒçš„head,å¯ä»¥çœ‹å‡ºï¼Œä¸åŒçš„headï¼Œattentionåˆ°çš„å†…å®¹æ˜¯å„ä¸ç›¸åŒçš„ã€‚</p>
<p>ä¸åŒè¡Œæ¯”è¾ƒçš„ç»“è®ºï¼Ÿ</p>
<h2 id="Decoder-visualization"><a href="#Decoder-visualization" class="headerlink" title="Decoder visualization"></a>Decoder visualization</h2><div class="note info">
            <p>decoder Self Layer 2 :<s>ä¼šattentionåˆ°æ‰€æœ‰å•è¯ï¼Œå•è¯å¤§å¤šä¼šattentionåˆ°è‡ªå·±ã€‚</s></p>
          </div>
<p><img src="/2020/05/11/transformer/image-20200511120009561.png" alt="image-20200511120009561"></p>
<div class="note info">
            <p>decoder Src Layer 2</p>
          </div>
<p><img src="/2020/05/11/transformer/image-20200511120705604.png" alt="image-20200511120705604"></p>
<div class="note info">
            <p>decoder Self Layer 4</p>
          </div>
<p><img src="/2020/05/11/transformer/image-20200511120927309.png" alt="image-20200511120927309"></p>
<div class="note info">
            <p>decoder Src Layer 4</p>
          </div>
<p><img src="/2020/05/11/transformer/image-20200511120946538.png" alt="image-20200511120946538"></p>
<div class="note info">
            <p>decoder Self Layer 6</p>
          </div>
<p><img src="/2020/05/11/transformer/image-20200511121002344.png" alt="image-20200511121002344"></p>
<div class="note info">
            <p>decoder Src Layer 6</p>
          </div>
<p><img src="/2020/05/11/transformer/image-20200511121021648.png" alt="image-20200511121021648"></p>
<p>åŒä¸€è¡Œ ï¼Ÿ</p>
<p>ä¸åŒè¡Œï¼Ÿ</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><h2 id="tricks"><a href="#tricks" class="headerlink" title="tricks"></a>tricks</h2><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹æ²¡æœ‰æ”¶æ•›å¾—å¾ˆå¥½æ—¶ï¼ŒDecoderé¢„æµ‹äº§ç”Ÿçš„è¯å¾ˆå¯èƒ½ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚è¿™ä¸ªæ—¶å€™å¦‚æœå†æŠŠé”™è¯¯çš„æ•°æ®å†è¾“ç»™Decoderï¼Œå°±ä¼šè¶Šè·‘è¶Šåã€‚è¿™ä¸ªæ—¶å€™æ€ä¹ˆåŠï¼Ÿ</p>
<ul>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥ä½¿ç”¨ â€œteacher forcingâ€ã€‚å› ä¸ºæˆ‘ä»¬çŸ¥é“åº”è¯¥é¢„æµ‹çš„wordæ˜¯ä»€ä¹ˆï¼Œé‚£ä¹ˆå¯ä»¥ç»™Decoderå–‚ä¸€ä¸ªæ­£ç¡®çš„ç»“æœä½œä¸ºè¾“å…¥ã€‚</li>
<li>é™¤äº†é€‰æ‹©æœ€é«˜æ¦‚ç‡çš„è¯ (greedy search)ï¼Œè¿˜å¯ä»¥é€‰æ‹©æ˜¯æ¯”å¦‚ â€œBeam Searchâ€ï¼Œå¯ä»¥ä¿ç•™topKä¸ªé¢„æµ‹çš„wordã€‚ Beam Search æ–¹æ³•ä¸å†æ˜¯åªå¾—åˆ°ä¸€ä¸ªè¾“å‡ºæ”¾åˆ°ä¸‹ä¸€æ­¥å»è®­ç»ƒäº†ï¼Œæˆ‘ä»¬å¯ä»¥è®¾å®šä¸€ä¸ªå€¼ï¼Œæ‹¿å¤šä¸ªå€¼æ”¾åˆ°ä¸‹ä¸€æ­¥å»è®­ç»ƒï¼Œè¿™æ¡è·¯å¾„çš„æ¦‚ç‡ç­‰äºæ¯ä¸€æ­¥è¾“å‡ºçš„æ¦‚ç‡çš„ä¹˜ç§¯ã€‚</li>
</ul>
<h2 id="Transformerçš„ä¼˜ç¼ºç‚¹"><a href="#Transformerçš„ä¼˜ç¼ºç‚¹" class="headerlink" title="Transformerçš„ä¼˜ç¼ºç‚¹"></a>Transformerçš„ä¼˜ç¼ºç‚¹</h2><h3 id="ä¼˜ç‚¹"><a href="#ä¼˜ç‚¹" class="headerlink" title="ä¼˜ç‚¹"></a>ä¼˜ç‚¹</h3><ol>
<li>æ¯å±‚è®¡ç®—å¤æ‚åº¦æ¯”RNNè¦ä½ã€‚</li>
<li>å¯ä»¥è¿›è¡Œ<strong>å¹¶è¡Œè®¡ç®—</strong>ã€‚</li>
<li>ä»è®¡ç®—ä¸€ä¸ªåºåˆ—é•¿åº¦ä¸ºnçš„ä¿¡æ¯è¦ç»è¿‡çš„è·¯å¾„é•¿åº¦æ¥çœ‹, CNNéœ€è¦å¢åŠ å·ç§¯å±‚æ•°æ¥æ‰©å¤§è§†é‡ï¼ŒRNNéœ€è¦ä»1åˆ°né€ä¸ªè¿›è¡Œè®¡ç®—ï¼Œè€ŒSelf-attentionåªéœ€è¦ä¸€æ­¥çŸ©é˜µè®¡ç®—å°±å¯ä»¥ã€‚Self-Attentionå¯ä»¥æ¯”RNNæ›´å¥½åœ°è§£å†³é•¿æ—¶ä¾èµ–é—®é¢˜ã€‚å½“ç„¶å¦‚æœè®¡ç®—é‡å¤ªå¤§ï¼Œæ¯”å¦‚åºåˆ—é•¿åº¦Nå¤§äºåºåˆ—ç»´åº¦Dè¿™ç§æƒ…å†µï¼Œä¹Ÿå¯ä»¥ç”¨çª—å£é™åˆ¶Self-Attentionçš„è®¡ç®—æ•°é‡ã€‚ï¼Ÿï¼Ÿï¼Ÿ</li>
<li>ä»ä½œè€…åœ¨é™„å½•ä¸­ç»™å‡ºçš„æ —å­å¯ä»¥çœ‹å‡ºï¼ŒSelf-Attentionæ¨¡å‹æ›´å¯è§£é‡Šï¼ŒAttentionç»“æœçš„åˆ†å¸ƒè¡¨æ˜äº†è¯¥æ¨¡å‹å­¦ä¹ åˆ°äº†ä¸€äº›è¯­æ³•å’Œè¯­ä¹‰ä¿¡æ¯ã€‚</li>
</ol>
<h3 id="ç¼ºç‚¹"><a href="#ç¼ºç‚¹" class="headerlink" title="ç¼ºç‚¹"></a>ç¼ºç‚¹</h3><ol>
<li>å®è·µä¸Šï¼šæœ‰äº›RNNè½»æ˜“å¯ä»¥è§£å†³çš„é—®é¢˜transformeræ²¡åšåˆ°ï¼Œæ¯”å¦‚<strong>å¤åˆ¶string</strong>ï¼Œæˆ–è€…æ¨ç†æ—¶ç¢°åˆ°çš„sequenceé•¿åº¦æ¯”è®­ç»ƒæ—¶æ›´é•¿ï¼ˆå› ä¸º<strong>ç¢°åˆ°äº†æ²¡è§è¿‡çš„position embedding</strong>ï¼‰ã€‚</li>
<li>ç†è®ºä¸Šï¼štransformersä¸æ˜¯computationally universal(å›¾çµå®Œå¤‡)ï¼Œè¿™ç§éRNNå¼çš„æ¨¡å‹æ˜¯éå›¾çµå®Œå¤‡çš„çš„ï¼Œ<strong>æ— æ³•å•ç‹¬å®ŒæˆNLPä¸­æ¨ç†ã€å†³ç­–ç­‰è®¡ç®—é—®é¢˜</strong>ï¼ˆåŒ…æ‹¬ä½¿ç”¨transformerçš„bertæ¨¡å‹ç­‰ç­‰ï¼‰ã€‚ï¼Ÿï¼Ÿï¼Ÿ</li>
</ol>
<h1 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h1><ol>
<li><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">The Annotated Transformer</a></li>
<li><a href="https://www.cnblogs.com/zingp/p/11696111.html" target="_blank" rel="noopener">æ·±å…¥ç†è§£TransformeråŠå…¶æºç </a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/05/08/%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/08/%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">å¹³æ»‘æ–¹æ³•</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-08 19:23:48" itemprop="dateModified" datetime="2020-05-08T19:23:48+08:00">2020-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">è‡ªç„¶è¯­è¨€å¤„ç†</span></a>
                </span>
            </span>

          
            <span id="/2020/05/08/%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95/" class="post-meta-item leancloud_visitors" data-flag-title="å¹³æ»‘æ–¹æ³•" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/05/08/%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/05/08/%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>4k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>4 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h3><p>åœ¨ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ä¸­ï¼Œä¹Ÿå°±æ˜¯ p(e)åœ¨ event space E ä¸‹çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ¨¡å‹å¾ˆå¯èƒ½ä¼šç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡(MLE)ï¼š</p>
<script type="math/tex; mode=display">
P_{M L E}=\frac{c(x)}{\sum_{e} c(e)}</script><p>ç„¶è€Œï¼Œç”±äºå¹¶æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œå¾ˆå¤šäº‹ä»¶ $x$ å¹¶æ²¡æœ‰åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°ï¼Œä¹Ÿå°±æ˜¯ $c(x)=0$ï¼Œ$P_{MLE}=0$è¿™æ˜¯æœ‰é—®é¢˜çš„ï¼Œæ²¡æœ‰åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°çš„æ•°æ®ï¼Œå¹¶ä¸ä»£è¡¨ä¸ä¼šåœ¨æµ‹è¯•æ•°æ®ä¸­å‡ºç°ï¼Œå¦‚æœæ²¡æœ‰è€ƒè™‘åˆ°æ•°æ®ç¨€ç–æ€§ï¼Œæ¨¡å‹å°±æ˜¾å¾—å¤ªç®€å•äº†ã€‚</p>
<p>Data sparsity æ˜¯ smoothing çš„æœ€å¤§åŸå› ã€‚Chen &amp; Goodman åœ¨1998 å¹´æåˆ°è¿‡ï¼Œå‡ ä¹æ‰€æœ‰æ•°æ®ç¨€ç–çš„åœºæ™¯ä¸‹ï¼Œsmoothing éƒ½å¯ä»¥å¸®åŠ©æé«˜ performanceï¼Œè€Œæ•°æ®ç¨€ç–æ€§å‡ ä¹æ˜¯æ‰€æœ‰ç»Ÿè®¡æ¨¡å‹éƒ½ä¼šé‡åˆ°çš„é—®é¢˜ã€‚è€Œå¦‚æœä½ æœ‰è¶³å¤Ÿå¤šçš„è®­ç»ƒæ•°æ®ï¼Œæ‰€æœ‰çš„ parameters éƒ½å¯ä»¥åœ¨æ²¡æœ‰ smoothing çš„æƒ…å†µä¸‹è¢«å‡†ç¡®çš„ä¼°è®¡ï¼Œé‚£ä¹ˆä½ æ€»æ˜¯å¯ä»¥æ‰©å±•æ¨¡å‹ï¼Œå¦‚åŸæ¥æ˜¯ bigramï¼Œæ²¡æœ‰æ•°æ®ç¨€ç–ï¼Œå®Œå…¨å¯ä»¥æ‰©å±•åˆ° trigram æ¥æé«˜ performanceï¼Œå¦‚æœè¿˜æ²¡æœ‰å‡ºç°ç¨€ç–ï¼Œå°±å†å¾€é«˜å±‚æ¨ï¼Œå½“ parameters è¶Šæ¥è¶Šå¤šçš„æ—¶å€™ï¼Œæ•°æ®ç¨€ç–å†æ¬¡æˆä¸ºäº†é—®é¢˜ï¼Œè¿™æ—¶å€™ï¼Œç”¨åˆé€‚çš„å¹³æ»‘æ–¹æ³•å¯ä»¥å¾—åˆ°æ›´å‡†ç¡®çš„æ¨¡å‹ã€‚å®é™…ä¸Šï¼Œæ— è®ºæœ‰å¤šå°‘çš„æ•°æ®ï¼Œå¹³æ»‘å‡ ä¹æ€»æ˜¯å¯ä»¥ä»¥å¾ˆå°çš„ä»£ä»·æ¥æé«˜ performanceã€‚</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/05/08/%E5%B9%B3%E6%BB%91%E6%96%B9%E6%B3%95/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/04/28/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/28/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">åˆ†è¯ç®—æ³•</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-07 17:52:43" itemprop="dateModified" datetime="2020-05-07T17:52:43+08:00">2020-05-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€</span></a>
                </span>
            </span>

          
            <span id="/2020/04/28/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/" class="post-meta-item leancloud_visitors" data-flag-title="åˆ†è¯ç®—æ³•" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/04/28/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/28/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>44k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>40 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="åˆ†è¯ç®€ä»‹"><a href="#åˆ†è¯ç®€ä»‹" class="headerlink" title="åˆ†è¯ç®€ä»‹"></a>åˆ†è¯ç®€ä»‹</h3><p>ä¸­æ–‡åˆ†è¯ç®—æ³•æ˜¯æŒ‡å°†ä¸€ä¸ªæ±‰å­—åºåˆ—åˆ‡åˆ†æˆä¸€ä¸ªä¸€ä¸ªå•ç‹¬çš„è¯ï¼Œä¸è‹±æ–‡ä»¥ç©ºæ ¼ä½œä¸ºå¤©ç„¶çš„åˆ†éš”ç¬¦ä¸åŒï¼Œä¸­æ–‡å­—ç¬¦åœ¨è¯­ä¹‰è¯†åˆ«æ—¶ï¼Œéœ€è¦æŠŠæ•°ä¸ªå­—ç¬¦ç»„åˆæˆè¯ï¼Œæ‰èƒ½è¡¨è¾¾å‡ºçœŸæ­£çš„å«ä¹‰ã€‚åˆ†è¯ç®—æ³•é€šå¸¸åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€æœç´¢å¼•æ“ã€æ™ºèƒ½æ¨èç­‰é¢†åŸŸã€‚</p>
<p>åˆ†è¯ç®—æ³•æ ¹æ®å…¶æ ¸å¿ƒæ€æƒ³ä¸»è¦åˆ†ä¸ºä¸¤ç§ï¼Œç¬¬ä¸€ç§æ˜¯åŸºäºè¯å…¸çš„åˆ†è¯ï¼Œå…ˆæŠŠå¥å­æŒ‰ç…§å­—å…¸åˆ‡åˆ†æˆè¯ï¼Œå†å¯»æ‰¾è¯çš„æœ€ä½³ç»„åˆæ–¹å¼ï¼›ç¬¬äºŒç§æ˜¯åŸºäºå­—çš„åˆ†è¯ï¼Œå³ç”±å­—æ„è¯ï¼Œå…ˆæŠŠå¥å­åˆ†æˆä¸€ä¸ªä¸ªå­—ï¼Œå†å°†å­—ç»„åˆæˆè¯ï¼Œå¯»æ‰¾æœ€ä¼˜çš„åˆ‡åˆ†ç­–ç•¥ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥è½¬åŒ–æˆåºåˆ—æ ‡æ³¨é—®é¢˜ã€‚</p>
<p>å…¶åˆ†ç±»å¤§è‡´å¯åˆ†ä¸ºï¼š</p>
<ol>
<li><p>åŸºäºåŒ¹é…è§„åˆ™çš„æ–¹æ³•</p>
<ul>
<li>æ­£å‘æœ€å¤§åŒ¹é…æ³•(forward maximum matching method, FMM)</li>
<li>é€†å‘æœ€å¤§åŒ¹é…æ³•(backward maximum matching method, BMM)</li>
<li>æœ€çŸ­è·¯å¾„åˆ†è¯ç®—æ³•</li>
</ul>
</li>
<li><p>åŸºäºç»Ÿè®¡ä»¥åŠæœºå™¨å­¦ä¹ çš„åˆ†è¯æ–¹æ³•</p>
<ul>
<li>åŸºäºN-gramè¯­è¨€æ¨¡å‹çš„åˆ†è¯æ–¹æ³•</li>
<li>åŸºäºHMMçš„åˆ†è¯æ–¹æ³•</li>
<li>åŸºäºCRFçš„åˆ†è¯æ–¹æ³•</li>
<li>åŸºäºè¯æ„ŸçŸ¥æœºçš„åˆ†è¯æ–¹æ³•</li>
<li>åŸºäºæ·±åº¦å­¦ä¹ çš„ç«¯åˆ°ç«¯çš„åˆ†è¯æ–¹æ³•</li>
</ul>
</li>
</ol>
<p>åŸºäºè§„åˆ™åŒ¹é…çš„åˆ†è¯é€šå¸¸ä¼šåŠ å…¥ä¸€äº›å¯å‘å¼è§„åˆ™ï¼Œæ¯”å¦‚â€œæ­£å‘/åå‘æœ€å¤§åŒ¹é…â€ï¼Œâ€œé•¿è¯ä¼˜å…ˆâ€ç­‰ã€‚</p>
<p>åŸºäºç»Ÿè®¡ä»¥åŠæœºå™¨å­¦ä¹ çš„åˆ†è¯æ–¹æ³•ï¼Œå®ƒä»¬åŸºäºäººå·¥æ ‡æ³¨çš„è¯æ€§å’Œç»Ÿè®¡ç‰¹å¾ï¼Œå¯¹ä¸­æ–‡è¿›è¡Œå»ºæ¨¡ï¼Œå³æ ¹æ®è§‚æµ‹åˆ°çš„æ•°æ®(æ ‡æ³¨å¥½çš„è¯­æ–™)å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œè®­ç»ƒï¼Œåœ¨åˆ†è¯é˜¶æ®µå†é€šè¿‡æ¨¡å‹è®¡ç®—å„ç§åˆ†è¯å‡ºç°çš„æ¦‚ç‡ï¼Œå°†æ¦‚ç‡æœ€å¤§çš„åˆ†è¯ç»“æœä½œä¸ºæœ€ç»ˆç»“æœã€‚è¿™ç±»åˆ†è¯ç®—æ³•èƒ½å¾ˆå¥½å¤„ç†æ­§ä¹‰å’Œæœªç™»å½•è¯é—®é¢˜ï¼Œæ•ˆæœæ¯”åŸºäºè§„åˆ™åŒ¹é…çš„æ–¹æ³•æ•ˆæœå¥½ï¼Œä½†æ˜¯éœ€è¦å¤§é‡çš„äººå·¥æ ‡æ³¨æ•°æ®ï¼Œä»¥åŠè¾ƒæ…¢çš„åˆ†è¯é€Ÿåº¦ã€‚</p>
<p><a href="https://github.com/jeffery0628/chinese_word_seg" target="_blank" rel="noopener">ä»£ç åŠæ•°æ®</a></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/04/28/%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/04/24/%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/24/%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/" class="post-title-link" itemprop="url">æ–‡æœ¬çº é”™</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-08 16:37:07" itemprop="dateModified" datetime="2020-05-08T16:37:07+08:00">2020-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€</span></a>
                </span>
            </span>

          
            <span id="/2020/04/24/%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/" class="post-meta-item leancloud_visitors" data-flag-title="æ–‡æœ¬çº é”™" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/04/24/%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/24/%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>3k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>3 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h3><h4 id="å¸¸è§é”™è¯¯ç±»å‹"><a href="#å¸¸è§é”™è¯¯ç±»å‹" class="headerlink" title="å¸¸è§é”™è¯¯ç±»å‹"></a>å¸¸è§é”™è¯¯ç±»å‹</h4><ol>
<li>è°éŸ³å­—è¯ï¼Œå¦‚ é…å‰¯çœ¼ç›-é…å‰¯çœ¼é•œ</li>
<li>æ··æ·†éŸ³å­—è¯ï¼Œå¦‚ æµæµªç»‡å¥³-ç‰›éƒç»‡å¥³</li>
<li>å­—è¯é¡ºåºé¢ å€’ï¼Œå¦‚ ä¼è¿ªè‰¾ä¼¦-è‰¾ä¼¦ä¼è¿ª</li>
<li>å­—è¯è¡¥å…¨ï¼Œå¦‚ çˆ±æœ‰å¤©æ„-å‡å¦‚çˆ±æœ‰å¤©æ„</li>
<li>å½¢ä¼¼å­—é”™è¯¯ï¼Œå¦‚ é«˜æ¢-é«˜ç²±</li>
<li>ä¸­æ–‡æ‹¼éŸ³å…¨æ‹¼ï¼Œå¦‚ xingfu-å¹¸ç¦</li>
<li>ä¸­æ–‡æ‹¼éŸ³ç¼©å†™ï¼Œå¦‚ sz-æ·±åœ³</li>
<li>è¯­æ³•é”™è¯¯ï¼Œå¦‚ æƒ³è±¡éš¾ä»¥-éš¾ä»¥æƒ³è±¡</li>
</ol>
<p>é’ˆå¯¹ä¸åŒä¸šåŠ¡åœºæ™¯ï¼Œè¿™äº›é—®é¢˜å¹¶ä¸ä¸€å®šå…¨éƒ¨å­˜åœ¨ï¼Œæ¯”å¦‚è¾“å…¥æ³•ä¸­éœ€è¦å¤„ç†å‰å››ç§ï¼Œæœç´¢å¼•æ“éœ€è¦å¤„ç†æ‰€æœ‰ç±»å‹ï¼Œè¯­éŸ³è¯†åˆ«åæ–‡æœ¬çº é”™åªéœ€è¦å¤„ç†å‰ä¸¤ç§ï¼Œ å…¶ä¸­â€™å½¢ä¼¼å­—é”™è¯¯â€™ä¸»è¦é’ˆå¯¹äº”ç¬”æˆ–è€…ç¬”ç”»æ‰‹å†™è¾“å…¥ç­‰ã€‚</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/04/24/%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/04/21/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/21/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/" class="post-title-link" itemprop="url">å…³é”®è¯æŠ½å–</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-04-24 23:25:40" itemprop="dateModified" datetime="2020-04-24T23:25:40+08:00">2020-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€</span></a>
                </span>
            </span>

          
            <span id="/2020/04/21/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/" class="post-meta-item leancloud_visitors" data-flag-title="å…³é”®è¯æŠ½å–" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/04/21/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/21/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>15k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>14 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="TF-IDF-æå–å…³é”®è¯"><a href="#TF-IDF-æå–å…³é”®è¯" class="headerlink" title="TF-IDF æå–å…³é”®è¯"></a>TF-IDF æå–å…³é”®è¯</h2><h3 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h3><p>TF-IDF(Term Frequency-Inverse Document Frequency, è¯é¢‘-é€†æ–‡ä»¶é¢‘ç‡).TF-IDFæ˜¯ä¸€ç§ç»Ÿè®¡æ–¹æ³•ï¼Œç”¨ä»¥è¯„ä¼°ä¸€å­—è¯å¯¹äºä¸€ä¸ªæ–‡ä»¶é›†æˆ–ä¸€ä»½æ–‡ä»¶åœ¨ä¸€ä¸ªè¯­æ–™åº“ä¸­çš„é‡è¦ç¨‹åº¦ã€‚å­—è¯çš„é‡è¦æ€§éšç€å®ƒåœ¨æ–‡ä»¶ä¸­å‡ºç°çš„æ¬¡æ•°æˆæ­£æ¯”å¢åŠ ï¼Œä½†åŒæ—¶ä¼šéšç€å®ƒåœ¨è¯­æ–™åº“ä¸­å‡ºç°çš„é¢‘ç‡æˆåæ¯”ä¸‹é™ã€‚æ¢å¥è¯è¯´å°±æ˜¯ï¼š<strong>ä¸€ä¸ªè¯è¯­åœ¨ä¸€ç¯‡æ–‡ç« ä¸­å‡ºç°æ¬¡æ•°è¶Šå¤š, åŒæ—¶åœ¨æ‰€æœ‰æ–‡æ¡£ä¸­å‡ºç°æ¬¡æ•°è¶Šå°‘, è¶Šèƒ½å¤Ÿä»£è¡¨è¯¥æ–‡ç« ã€‚</strong></p>
<blockquote>
<p>TF-IDF ç®—æ³•ä¸»è¦é€‚ç”¨äºè‹±æ–‡ï¼Œä¸­æ–‡é¦–å…ˆè¦åˆ†è¯ï¼Œåˆ†è¯åè¦è§£å†³å¤šè¯ä¸€ä¹‰ï¼Œä»¥åŠä¸€è¯å¤šä¹‰é—®é¢˜ï¼Œè¿™ä¸¤ä¸ªé—®é¢˜é€šè¿‡ç®€å•çš„tf-idfæ–¹æ³•ä¸èƒ½å¾ˆå¥½çš„è§£å†³ã€‚äºæ˜¯å°±æœ‰äº†åæ¥çš„è¯åµŒå…¥æ–¹æ³•ï¼Œç”¨å‘é‡æ¥è¡¨å¾ä¸€ä¸ªè¯ã€‚</p>
</blockquote>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/04/21/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/04/13/bert%E7%B3%BB%E5%88%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/13/bert%E7%B3%BB%E5%88%97/" class="post-title-link" itemprop="url">bertç³»åˆ—</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-05-08 20:31:50" itemprop="dateModified" datetime="2020-05-08T20:31:50+08:00">2020-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">æ·±åº¦å­¦ä¹ </span></a>
                </span>
            </span>

          
            <span id="/2020/04/13/bert%E7%B3%BB%E5%88%97/" class="post-meta-item leancloud_visitors" data-flag-title="bertç³»åˆ—" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/04/13/bert%E7%B3%BB%E5%88%97/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/13/bert%E7%B3%BB%E5%88%97/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>4.8k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>4 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="BERT-åŠå…¶åç»­æ¨¡å‹"><a href="#BERT-åŠå…¶åç»­æ¨¡å‹" class="headerlink" title="BERT åŠå…¶åç»­æ¨¡å‹"></a>BERT åŠå…¶åç»­æ¨¡å‹</h2><p>äº†è§£è¿™äº›åç»­çš„æ¨¡å‹ï¼Œæ–¹ä¾¿åœ¨åç»­çš„ç ”ç©¶å’Œåº”ç”¨ä¸­æ¥æ›´å¥½çš„é€‰æ‹©æ¨¡å‹ã€‚</p>
<h3 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h3><p>BERTæ¨¡å‹çš„ä¸»è¦åˆ›æ–°ç‚¹éƒ½åœ¨pre-trainæ–¹æ³•ä¸Šï¼Œå³ç”¨äº†Masked LMå’ŒNext Sentence Predictionä¸¤ç§æ–¹æ³•åˆ†åˆ«æ•æ‰è¯è¯­å’Œå¥å­çº§åˆ«çš„representationã€‚</p>
<p><img src="/2020/04/13/bert%E7%B3%BB%E5%88%97/bert.jpg" alt="avatar"></p>
<p>å¯¹æ¯”OpenAI GPT(Generative pre-trained transformer)ï¼ŒBERTæ˜¯åŒå‘çš„Transformer blockè¿æ¥ï¼›å°±åƒå•å‘rnnå’ŒåŒå‘rnnçš„åŒºåˆ«ï¼Œç›´è§‰ä¸Šæ¥è®²æ•ˆæœä¼šå¥½ä¸€äº›ã€‚</p>
<p>å¯¹æ¯”ELMoï¼Œè™½ç„¶éƒ½æ˜¯â€œåŒå‘â€ï¼Œä½†ç›®æ ‡å‡½æ•°å…¶å®æ˜¯ä¸åŒçš„ã€‚ELMoæ˜¯åˆ†åˆ«ä»¥ $P(w_i|w_1,\cdots,w_{i-1})$ å’Œ$P(w_i|w_{i+1},\cdots,w_n)$ä½œä¸ºç›®æ ‡å‡½æ•°ï¼Œç‹¬ç«‹è®­ç»ƒå¤„ä¸¤ä¸ªrepresentationç„¶åæ‹¼æ¥ï¼Œè€ŒBERTåˆ™æ˜¯ä»¥$P(w_i|w_1,\cdots,w_{i-1},w_{i+1}\cdots,w_n)$  ä½œä¸ºç›®æ ‡å‡½æ•°è®­ç»ƒLMã€‚</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/04/13/bert%E7%B3%BB%E5%88%97/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/04/11/%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/11/%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">æ–‡æœ¬å¤šæ ‡ç­¾åˆ†ç±»</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-04-11 23:26:44" itemprop="dateModified" datetime="2020-04-11T23:26:44+08:00">2020-04-11</time>
              </span>

          
            <span id="/2020/04/11/%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/" class="post-meta-item leancloud_visitors" data-flag-title="æ–‡æœ¬å¤šæ ‡ç­¾åˆ†ç±»" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/04/11/%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/11/%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>1.7k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>2 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>å¯¹äºäº‹ä»¶æŠ½å–ä¸­å•å¥å¤šäº‹ä»¶çš„é—®é¢˜ï¼Œæ‰“ç®—ç”¨æ–‡æœ¬å¤šæ ‡ç­¾åˆ†ç±»æ¥è¿›è¡Œè§£å†³ã€‚</p>
<h3 id="éš¾ç‚¹"><a href="#éš¾ç‚¹" class="headerlink" title="éš¾ç‚¹"></a>éš¾ç‚¹</h3><ol>
<li>ç±»æ ‡æ•°é‡ä¸ç¡®å®šï¼Œæœ‰äº›æ ·æœ¬å¯èƒ½åªæœ‰ä¸€ä¸ªç±»æ ‡ï¼Œæœ‰äº›æ ·æœ¬çš„ç±»æ ‡å¯èƒ½é«˜è¾¾å‡ åç”šè‡³ä¸Šç™¾ä¸ªã€‚â€‚</li>
<li>ç±»æ ‡ä¹‹é—´ç›¸äº’ä¾èµ–ï¼Œä¾‹å¦‚åŒ…å«è“å¤©ç±»æ ‡çš„æ ·æœ¬å¾ˆå¤§æ¦‚ç‡ä¸ŠåŒ…å«ç™½äº‘ï¼Œå¦‚ä½•è§£å†³ç±»æ ‡ä¹‹é—´çš„ä¾èµ–æ€§é—®é¢˜ä¹Ÿæ˜¯ä¸€å¤§éš¾ç‚¹ã€‚</li>
<li>å¤šæ ‡ç­¾çš„è®­ç»ƒé›†æ¯”è¾ƒéš¾ä»¥è·å–ã€‚</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/04/11/%E6%96%87%E6%9C%AC%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/04/11/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%80%9F%E6%9F%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç«ç§2å·">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/11/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%80%9F%E6%9F%A5/" class="post-title-link" itemprop="url">pythonæ•°æ®ç§‘å­¦é€ŸæŸ¥</a>
        </h2>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-04-11 23:27:44" itemprop="dateModified" datetime="2020-04-11T23:27:44+08:00">2020-04-11</time>
              </span>

          
            <span id="/2020/04/11/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%80%9F%E6%9F%A5/" class="post-meta-item leancloud_visitors" data-flag-title="pythonæ•°æ®ç§‘å­¦é€ŸæŸ¥" title="é˜…è¯»æ¬¡æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valineï¼š</span>
    
    <a title="valine" href="/2020/04/11/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%80%9F%E6%9F%A5/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/11/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%80%9F%E6%9F%A5/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>60k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>54 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="é€ŸæŸ¥è¡¨"><a href="#é€ŸæŸ¥è¡¨" class="headerlink" title="é€ŸæŸ¥è¡¨"></a>é€ŸæŸ¥è¡¨</h2><h3 id="python-åŸºç¡€"><a href="#python-åŸºç¡€" class="headerlink" title="python åŸºç¡€"></a>python åŸºç¡€</h3><p><img src="/2020/04/11/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%80%9F%E6%9F%A5/python.png" alt="avatar"></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2020/04/11/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%80%9F%E6%9F%A5/#more" rel="contents">
                é˜…è¯»å…¨æ–‡ &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="ä¸‹ä¸€é¡µ"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <a href='/'>
    <img class="site-author-image" itemprop="image" alt="Li Zhen"
      src="/images/snoppy.jpeg">
  </a>
  <p class="site-author-name" itemprop="name">Li Zhen</p>
  <div class="site-description" itemprop="description">ä½†è¡Œå¥½äº‹ï¼Œè«é—®å‰ç¨‹ï¼</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">åˆ†ç±»</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="hhttps://github.com/jeffery0628" title="GitHub â†’ hhttps:&#x2F;&#x2F;github.com&#x2F;jeffery0628" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jeffery.lee.0628@gmail.com" title="é‚®ç®± â†’ mailto:jeffery.lee.0628@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>é‚®ç®±</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">
  
  &copy; 2018 â€“ 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li Zhen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">ç«™ç‚¹æ€»å­—æ•°ï¼š</span>
    <span title="ç«™ç‚¹æ€»å­—æ•°">386k</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="site-uv">
      æˆ‘çš„ç¬¬ <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> ä½æœ‹å‹ï¼Œ
    </span>
    <span class="site-pv">
      å†ç» <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> æ¬¡å›çœ¸æ‰ä¸ä½ ç›¸é‡
    </span>
</div>






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"bu0jcrISneKfTwssc7P792xE-gzGzoHsz","app_key":"3y7nYJuTGp6zIHSfRBQlMQnB","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  

  <canvas id="evanyou"></canvas>
  <style>
    #evanyou {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
    }
  </style>
  <script src="/js/evan-you.js"></script>




  <canvas id="evanyou"></canvas>
  <style>
    #evanyou {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
    }
  </style>
  <script src="/js/evan-you.js"></script>



  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>


 

<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
<script>
  function timer() {
    var ages = moment.preciseDiff(moment(),moment(20180101,"YYYYMMDD"));
    ages = ages.replace(/years?/, "å¹´");
    ages = ages.replace(/months?/, "æœˆ");
    ages = ages.replace(/days?/, "å¤©");
    ages = ages.replace(/hours?/, "å°æ—¶");
    ages = ages.replace(/minutes?/, "åˆ†");
    ages = ages.replace(/seconds?/, "ç§’");
    ages = ages.replace(/\d+/g, '<span style="color:#1890ff">$&</span>');
    div.innerHTML = `æˆ‘å·²åœ¨æ­¤ç­‰å€™ä½  ${ages}`;
  }
  var div = document.createElement("div");
  //æ’å…¥åˆ°copyrightä¹‹å
  var copyright = document.querySelector(".copyright");
  document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
  timer();
  setInterval("timer()",1000)
</script>


<script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>

<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'wocKAhd8E1IRPHNgYbfFVsKf-gzGzoHsz',
      appKey     : '0SDY7WADR3m02c4hBcUv3T0B',
      placeholder: "ç•™ä¸‹ä½ çš„å°è„šå°å§ï¼",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '8' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
