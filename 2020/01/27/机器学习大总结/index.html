<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/snoppy.jpeg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/snoppy.jpeg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/snoppy.jpeg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jeffery0628.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":true,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="机器学习大总结知识点进程和线程进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同.进程就是包换上下文切换的程序执行时间总和 &#x3D; CPU加载上下文+CPU执行+CPU保存上下文.线程是共享了进程的上下文环境的更为细小的CPU时间段。 判别式模型和生成式模型: 判别式模型直接学习决策函数$f(X)$或条件概率分布$P(Y|X)$作为预测的模型.往往准确率更高,并且可以简化学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习大总结">
<meta property="og:url" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="火种2号">
<meta property="og:description" content="机器学习大总结知识点进程和线程进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同.进程就是包换上下文切换的程序执行时间总和 &#x3D; CPU加载上下文+CPU执行+CPU保存上下文.线程是共享了进程的上下文环境的更为细小的CPU时间段。 判别式模型和生成式模型: 判别式模型直接学习决策函数$f(X)$或条件概率分布$P(Y|X)$作为预测的模型.往往准确率更高,并且可以简化学习">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/newton.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/sklearn.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/kd_tree.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/search_kd.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/search_kd_2.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/logistic.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/support_vector.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/support_soft.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/0_1loss.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/1.png">
<meta property="og:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/label_bias.png">
<meta property="article:published_time" content="2020-01-27T00:05:35.000Z">
<meta property="article:modified_time" content="2020-05-08T09:23:49.904Z">
<meta property="article:author" content="Li Zhen">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="统计学习方法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/newton.png">

<link rel="canonical" href="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习大总结 | 火种2号</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">火种2号</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">火种计划</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-books">

    <a href="/books/" rel="section"><i class="fa fa-book fa-fw"></i>读书</a>

  </li>
        <li class="menu-item menu-item-movies">

    <a href="/movies/" rel="section"><i class="fa fa-video fa-fw"></i>电影</a>

  </li>
        <li class="menu-item menu-item-games">

    <a href="/games/" rel="section"><i class="fa fa-gamepad fa-fw"></i>游戏</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>



</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jeffery0628.github.io/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoppy.jpeg">
      <meta itemprop="name" content="Li Zhen">
      <meta itemprop="description" content="但行好事，莫问前程！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="火种2号">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习大总结
        </h1>

        <div class="post-meta">
          
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-05-08 17:23:49" itemprop="dateModified" datetime="2020-05-08T17:23:49+08:00">2020-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
            <span id="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/" class="post-meta-item leancloud_visitors" data-flag-title="机器学习大总结" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>26k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="机器学习大总结"><a href="#机器学习大总结" class="headerlink" title="机器学习大总结"></a>机器学习大总结</h2><h3 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h3><h4 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a><strong>进程和线程</strong></h4><p>进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同.进程就是包换上下文切换的程序执行时间总和 = CPU加载上下文+CPU执行+CPU保存上下文.线程是共享了进程的上下文环境的更为细小的CPU时间段。</p>
<h4 id="判别式模型和生成式模型"><a href="#判别式模型和生成式模型" class="headerlink" title="判别式模型和生成式模型:"></a><strong>判别式模型和生成式模型</strong>:</h4><ol>
<li>判别式模型直接学习决策函数$f(X)$或条件概率分布$P(Y|X)$作为预测的模型.往往准确率更高,并且可以简化学习问题.<ol>
<li>k近邻法、感知机、决策树、最大熵模型、Logistic回归、线性判别分析(LDA)、支持向量机(SVM)、Boosting、CRF、线性回归、神经网络</li>
</ol>
</li>
<li>生成式模型由数据学习<strong>联合概率分布P(X,Y)</strong>,然后由P(Y|X)=P(X,Y)/P(X)求出条件概率分布作为预测的模型,即生成模型.当存在隐变量时只能用生成方法学习.<ol>
<li>混合高斯模型和其他混合模型、隐马尔可夫模型(HMM)、朴素贝叶斯、依赖贝叶斯(AODE)、LDA文档主题生成模型</li>
</ol>
</li>
</ol>
<a id="more"></a>
<h4 id="概率质量函数-概率密度函数-累积分布函数"><a href="#概率质量函数-概率密度函数-累积分布函数" class="headerlink" title="概率质量函数,概率密度函数,累积分布函数:"></a><strong>概率质量函数,概率密度函数,累积分布函数</strong>:</h4><ol>
<li>概率质量函数 (probability mass function，PMF)是离散随机变量在各特定取值上的概率。</li>
<li>概率密度函数（probability density function，PDF)是对 连续随机变量 定义的，本身不是概率，只有对连续随机变量的取值进行积分后才是概率。</li>
<li><p>累积分布函数（cumulative distribution function，CDF)能完整描述一个实数随机变量X的概率分布，是概率密度函数的积分。对於所有实数x ，与pdf相对。</p>
<h4 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a><strong>极大似然估计</strong></h4></li>
</ol>
<p>已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。</p>
<h4 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h4><p>二乘的英文是least square,找一个（组）估计值,使得实际值与估计值之差的平方加总之后的值最小$Q=\min \sum_{i}^{n}\left(y_{i e}-y_{i}\right)^{2}$.求解方式是对参数求偏导,令偏导为0即可.样本量小时速度快.</p>
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a><strong>梯度下降法</strong></h4><p>负梯度方向是函数值下降最快的方向,每次更新值都等于原值加学习率(<strong>步长</strong>)乘损失函数的<strong>梯度</strong>.每次都试一个步长看会不会下降一定的程度,如果没有的话就按比例减小步长.不断应用参数更新公式直到收敛,可以得到局部最小值.初始值的不同组合可以得到不同局部最小值.在最优点时会有震荡.</p>
<ol>
<li><p><strong>批量梯度下降(BGD)</strong>:每次都使用所有的m个样本来更新,容易找到全局最优解,但是m较大时速度较慢。$\theta_{j}^{\prime}=\theta_{j}+\frac{1}{m} \sum_{i=1}^{m}\left(y^{i}-h_{\theta}\left(x^{i}\right)\right) x_{j}^{i}$</p>
</li>
<li><p><strong>随机梯度下降(SGD)</strong>：每次只使用一个样本来更新,训练速度快,但是噪音较多,不容易找到全局最优解,以损失很小的一部分精确度和增加一定数量的迭代次数为代价,换取了总体的优化效率的提升.注意控制步长缩小,减少震荡.</p>
</li>
</ol>
<script type="math/tex; mode=display">
\theta_{j}=\theta_{j}+\left(y^{i}-h_{\theta}\left(x^{i}\right)\right) x_{j}^{i}</script><ol>
<li><strong>小批量梯度下降(MBGD)</strong>:每次使用一部分样本来更新.</li>
</ol>
<h4 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a><strong>牛顿法</strong></h4><p>牛顿法是<strong>二次收敛</strong>,因此收敛速度快.从几何上看是每次用一个二次曲面来拟合当前所处位置的局部曲面,而梯度下降法是用一个平面来拟合.</p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/newton.png" alt="avatar"></p>
<ol>
<li><strong>黑塞矩阵</strong>是由目标函数f(x)在点X处的二阶偏导数组成的n*n阶对称矩阵。</li>
<li><strong>牛顿法</strong>:将f(x)在x(k)附近进行<strong>二阶泰勒展开</strong>:$f(x)=f\left(x^{(k)}\right)+g_{k}^{\top}\left(x-x^{(k)}\right)+\frac{1}{2}\left(x-x^{(k)}\right)^{\mathrm{T}} H\left(x^{(k)}\right)\left(x-x^{(k)}\right)$。其中$g_k$是$f(x)$的梯度向量在$x^{(k)}$的值,$H(x^{(k)})$是$f(x)$的黑塞矩阵在点$x^k$的值.牛顿法利用极小点的必要条件$f(x)$处的梯度为0,每次迭代中从点$x^{(k)}$开始,假设$\nabla f\left(x^{(k+1)}\right)=0$，对二阶泰勒展开求偏导有 $\nabla f(x)=g_{k}+H_{k}\left(x-x^{(k)}\right)$，代入得到$g_{k}+H_{k}\left(x^{(k+1)}-x^{(k)}\right)=0$,即$\quad x^{(k+1)}=x^{(k)}-H_{k}^{-1} g_{k}$,以此为迭代公式就是牛顿法.</li>
</ol>
<h4 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h4><p>用一个<strong>n阶正定矩阵Gk</strong>=G(x(k))来<strong>近似代替</strong>黑塞矩阵的<strong>逆矩阵</strong>就是拟牛顿法的基本思想.在牛顿法中黑塞矩阵满足的条件如下:$g_{k+1}-g_{k}=H_{k}\left(x^{(k+1)}-x^{(k)}\right)$,令$ {y_{k}}=g_{k+1}-g_{k}, \quad \delta_{k}=x^{(k+1)}-x^{(k)}$，则有  $ H_{k}^{-1} y_{k}=\delta_{k}$,称为拟牛顿条件.</p>
<ol>
<li><strong>DFP算法</strong>:假设每一步$G_{k+1}=G_{k}+P_{k}+Q_{k}$，为使$G_{k+1}$满足拟牛顿条件,可使$P_k$和$Q_k$满足$P_{k} y_{k}=\delta_{k}, Q_{k} y_{k}=-G_{k} y_{k}$,例如取$P_{k}=\frac{\delta_{k} \delta_{k}^{\tau}}{\delta_{k}^{\top} y_{k}} \quad Q_{k}=-\frac{G_{k} y_{k} y_{k}^{\top} G_{k}}{y_{k}^{\top} G_{k} y_{k}}$，就得到迭代公式$G_{k+1}=G_{k}+\frac{\delta_{k} \delta_{k}^{\top}}{\delta_{k}^{\tau} y_{k}}-\frac{G_{k} y_{k} y_{k}^{\top} G_{k}}{y_{k}^{T} G_{k} y_{k}}$</li>
<li><strong>BFGS算法</strong>: 最流行的拟牛顿算法.它用$B_k$逼近黑塞矩阵,此时相应的拟牛顿条件是$B_{k+1} \delta_{k}=y_{k}$,假设每一步$B_{k+1}=B_{k}+P_{k}+Q_{k}$，则 $P_k$ 和 $Q_k$ 满足$P_{k} \delta_{k}=y_{k}, \quad Q_{k} \delta_{k}=-B_{k} \delta_{k}$，类似得到迭代公式$B_{k+1}=B_{k}+\frac{y_{k} y_{k}^{\top}}{y_{k}^{\top} \delta_{k}}-\frac{B_{k} \delta_{k} \delta_{k}^{\mathrm{T}} B_{k}}{\delta_{k}^{\top} B_{k} \delta_{k}}$</li>
</ol>
<h4 id="先验概率和后验概率"><a href="#先验概率和后验概率" class="headerlink" title="先验概率和后验概率"></a><strong>先验概率和后验概率</strong></h4><ol>
<li>先验概率就是事情发生前的预测概率.</li>
<li>后验概率是一种条件概率，它限定了事件为隐变量取值，而条件为观测结果。一般的条件概率，条件和事件可以是任意的.</li>
<li>贝叶斯公式$P(y|x) = ( P(x|y) * P(y) ) / P(x)$中,$P(y|x)$是后验概率,$P(x|y)$是条件概率,$P(y)$是先验概率.</li>
</ol>
<h4 id="偏差-方差-噪声"><a href="#偏差-方差-噪声" class="headerlink" title="偏差,方差,噪声"></a><strong>偏差,方差,噪声</strong></h4><ol>
<li>偏差:度量了学习算法的期望预测和真实结果偏离程度</li>
<li>方差:度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响</li>
<li>噪声:可以认为是数据自身的波动性，表达了目前任何学习算法所能达到泛化误差的下限</li>
<li><p><strong>泛化误差</strong>可以分解为偏差、方差与噪声之和</p>
<h4 id="对偶原理"><a href="#对偶原理" class="headerlink" title="对偶原理"></a><strong>对偶原理</strong></h4></li>
</ol>
<p>一个优化问题可以从主问题和对偶问题两个方面考虑.在推导对偶问题时,通过将拉格朗日函数对$x$求导并使导数为0来获得对偶函数.对偶函数给出了主问题最优解的下界,因此对偶问题一般是凸问题,那么只需求解对偶函数的最优解就可以了.</p>
<h4 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a><strong>KKT条件</strong></h4><p>通常我们要求解的最优化条件有如下三种:</p>
<ol>
<li>无约束优化问题:通常使用求导,使导数为零,求解候选最优值</li>
<li>有等式约束的优化问题:通常使用拉格朗日乘子法,即把等式约束用拉格朗日乘子和优化问题合并为一个式子,通过对各个变量求导使其为零,求解候选最优值.拉格朗日乘数法其实是KKT条件在等式约束优化问题的简化版.</li>
<li>有不等式约束的优化问题:通常使用KKT条件.即把不等式约束,等式约束和优化问题合并为一个式子.假设有多个等式约束$h(x)$和不等式约束$g(x)$,$L(\boldsymbol{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})=f(\boldsymbol{x})+\sum_{i=1}^{m} \lambda_{i} h_{i}(\boldsymbol{x})+\sum_{i=1}^{n} \mu_{j} g_{j}(\boldsymbol{x})$,则不等式约束引入的KKT条件如下:<br>$\left\{\begin{array}{l}g_{j}(\boldsymbol{x}) \leqslant 0 \\ mu_{j} \geqslant 0  \\mu_{j} g_{j}(\boldsymbol{x})=0\end{array}\right.$ ,实质是最优解在$g(x)&lt;0$区域内时,约束条件不起作用,等价于对$μ$置零然后对原函数的偏导数置零;当$g(x)=0$时与情况2相近.结合两种情况,那么只需要使$L$对$x$求导为零,使$h(x)$为零,使$μg(x)$为零三式即可求解候选最优值.</li>
</ol>
<h4 id="降维方法"><a href="#降维方法" class="headerlink" title="降维方法"></a><strong>降维方法</strong></h4><ol>
<li>主成分分析(PCA):降维,不断选择与已有坐标轴正交且方差最大的坐标轴.</li>
<li>奇异值分解(SVD):矩阵分解,降维,推荐系统. </li>
<li>线性判别分析(LDA)</li>
</ol>
<h4 id="集成方法"><a href="#集成方法" class="headerlink" title="集成方法"></a>集成方法</h4><h5 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h5><p>装袋法的核心思想是构建多个相互独立的评估器，然后对其预测进行平均或多数表决原则来决定集成评估器的结果。</p>
<ol>
<li>评估器：相互独立，同时运行</li>
<li>抽样：有放回抽样</li>
<li>如何决定集成的结果：平均或者少数服从多数</li>
<li>目标：降低方差</li>
<li>基学习器过拟合：能够一定程度上解决基学习器过拟合的问题</li>
<li>基学习器学习能力弱：不是很有帮助</li>
<li>代表算法：随机森林<h5 id="boosting"><a href="#boosting" class="headerlink" title="boosting"></a>boosting</h5>提升方法中，基评估器是相关的，是按顺序一一构建的。其核心思想是结合弱评估器的力量一次次对难以评估的样本进行预测，从而构成一个强评估器。提升法的代表模型有Adaboost和梯度提升树。</li>
<li>评估器：相互关联，按顺序依次构建，后建的模型在先建模型预测失败的样本上有更多的权重</li>
<li>抽样：有放回的采样，但会确认数据的权重，每次抽样都会给预测失败的样本更多的权重</li>
<li>如何决定集成的结果：加权平均，在训练集上表现好的模型会有更大的权重</li>
<li>目标：降低偏差，提高模型整体的精确度</li>
<li>基学习器过拟合：加剧过拟合问题</li>
<li>基学习器学习能力弱：提升模型表现</li>
<li>代表算法：GBDT,Adaboost<h5 id="stacking"><a href="#stacking" class="headerlink" title="stacking"></a>stacking</h5>Stacking模型是指将多种分类器组合在一起来取得更好表现的一种集成学习模型。一般情况下，Stacking模型分为两层。第一层中我们训练多个不同的模型，然后再以第一层训练的各个模型的输出作为输入来训练第二层的模型，以得到一个最终的输出。</li>
</ol>
<h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a><strong>性能度量</strong></h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center">预测值</th>
<th style="text-align:center">预测值</th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">真实值</td>
<td style="text-align:center">1</td>
<td style="text-align:center">11</td>
<td style="text-align:center">10</td>
<td style="text-align:center">Recall = $\frac{11}{11+10}$</td>
</tr>
<tr>
<td style="text-align:center">真实值</td>
<td style="text-align:center">0</td>
<td style="text-align:center">01</td>
<td style="text-align:center">00</td>
<td style="text-align:center">FPR = $\frac{01}{01+00}$</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">Precision=$\frac{11}{11+01}$</td>
<td style="text-align:center"></td>
<td style="text-align:center">Acc = $\frac{11+00}{11+10+01+00}$</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li><strong>准确度</strong>,最常用,但在数据集不平衡的情况下不好</li>
<li><strong>Precision(精确度/查准率)</strong>:$P=TP/(TP+FP)$</li>
<li><strong>Recall(召回率/查全率)</strong>:$R=TP/(TP+FN)$</li>
<li><strong>Fβ度量</strong>:$F_{\beta}=\frac{\left(1+\beta^{2}\right) r p}{\beta^{2} * p+r}$,当β=1时退化为F1度量,是精确率和召回率的调和均值.</li>
<li><strong>TPR(真正例率)</strong>:$TPR=TP/(TP+FN)$</li>
<li><strong>FPR(假正例率)</strong>:$FPR=FP/(TN+FP)$</li>
<li><strong>PR曲线</strong>:纵轴为Precision,横轴为Recall,一般使用平衡点(BEP,即Precsion=Recall的点)作为衡量标准.</li>
<li><strong>ROC(接受者操作特征)曲线</strong>:（<strong>每判断正确一个少数类，就有多少个多数类会被判断错误。</strong>）纵轴为TRP,横轴为FPR,在绘图时将分类阈值依次设为每个样例的预测值,再连接各点.ROC曲线围住的面积称为AOC,AOC越大则学习器性能越好.</li>
</ol>
<h4 id="损失函数和风险函数"><a href="#损失函数和风险函数" class="headerlink" title="损失函数和风险函数"></a><strong>损失函数和风险函数</strong></h4><ol>
<li>损失函数度量模型一次预测的好坏.常用的损失函数有:0-1损失函数,平方损失函数,绝对损失函数,对数似然损失函数.</li>
<li>损失函数的期望是理论上模型关于联合分布P(X,Y)的平均意义下的损失,称为风险函数,也叫<strong>期望风险</strong>.但是联合分布是未知的,期望风险不能直接计算.</li>
<li>当样本容量N趋于无穷时经验风险趋于期望风险,但现实中训练样本数目有限.</li>
</ol>
<h4 id="经验风险最小化和结构风险最小化"><a href="#经验风险最小化和结构风险最小化" class="headerlink" title="经验风险最小化和结构风险最小化"></a><strong>经验风险最小化和结构风险最小化</strong></h4><ol>
<li>模型关于训练数据集的平均损失称为经验风险.经验风险最小化的策略就是最小化经验风险.当样本数量足够大时学习效果较好.比如当模型是条件概率分布,损失函数是对数损失函数时,经验风险最小化就等价于极大似然估计.但是当样本容量很小时会出现过拟合.</li>
<li>结构风险最小化等于正则化.结构风险在经验风险上加上表示模型复杂度的正则化项.比如当模型是条件概率分布,损失函数是对数损失函数,模型复杂度由模型的先验概率表示时,结构风险最小化就等价于最大后验概率估计.</li>
</ol>
<h4 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a><strong>过拟合</strong></h4><p>指学习时选择的模型所包含的参数过多,以致于对已知数据预测得很好,但对未知数据预测很差的现象.模型选择旨在避免过拟合并提高模型的预测能力.</p>
<h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a><strong>正则化</strong></h4><p>模型选择的典型方法.正则化项一般是模型复杂度的单调递增函数,比如模型参数向量的范数.</p>
<h4 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a><strong>交叉验证</strong></h4><p>是另一常用的模型选择方法,可分为简单交叉验证,K折交叉验证,留一交叉验证等.</p>
<h4 id="sklearn"><a href="#sklearn" class="headerlink" title="sklearn"></a>sklearn</h4><p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/sklearn.png" alt="avatar"></p>
<h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h3><p>感知机是<strong>二类分类</strong>的线性模型,属于判别模型.感知机学习旨在求出将训练数据进行线性划分的分离超平面.是神经网络和支持向量机的基础.</p>
<h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p>$f(x)=sign(wx + b)$,$w$叫作权值向量,$b$叫做偏置,$sign$是符号函数.</p>
<h4 id="感知机的几何解释"><a href="#感知机的几何解释" class="headerlink" title="感知机的几何解释"></a><strong>感知机的几何解释</strong></h4><p>$wx+b$对应于特征空间中的一个分离超平面S,其中$w$是$S$的法向量,$b$是$S$的截距.$S$将特征空间划分为两个部分,位于两个部分的点分别被分为正负两类.</p>
<h4 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h4><p>假设训练数据集是线性可分的,感知机的损失函数是误分类点到超平面$S$的总距离.因为误分类点到超平面$S$的距离是$\frac{1}{|w|}\left|w \cdot x_{0}+b\right|$,且对于误分类的数据来说,总有$-y_i(wx_i+b)&gt;0$成立,因此不考虑$\frac{1}{|w|}$,就得到感知机的损失函数:</p>
<p>$L(w, b)=-\sum_{x \in M} y_{i}\left(w \cdot x_{i}+b\right)$,其中M是误分类点的集合.感知机学习的策略就是选取使损失函数最小的模型参数.</p>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>感知机的最优化方法采用<strong>随机梯度下降法</strong>.首先任意选取一个超平面$w_0,b_0$,然后不断地极小化目标函数.在极小化过程中一次随机选取一个误分类点更新$w,b$,直到损失函数为0.$w \leftarrow w+\eta y_{i} x_{i}$ ， $b \leftarrow b+\eta y_{i}$，其中$η$表示步长.该算法的直观解释是:当一个点被误分类,就调整$w,b$使分离超平面向该误分类点接近.感知机的解可以不同.</p>
<h4 id="对偶形式"><a href="#对偶形式" class="headerlink" title="对偶形式"></a><strong>对偶形式</strong></h4><p>假设原始形式中的$w_0$和$b_0$均为0,设逐步修改$w$和$b$共n次,令$a=nη$,最后学习到的$w,b$可以表示为$w =\sum_{i=1}^{N} \alpha_{i} y_{i} x_{i}$,$b =\sum_{i=1}^{N}{\alpha_{i} y_{i}}$ ,那么对偶算法就变为设初始$a$和$b$均为0,每次选取数据更新$a$和$b$直至没有误分类点为止.对偶形式的意义在于可以将训练集中实例间的内积计算出来,存在Gram矩阵中,可以大大加快训练速度.</p>
<h3 id="k近邻法"><a href="#k近邻法" class="headerlink" title="k近邻法"></a>k近邻法</h3><p>k近邻法根据其<strong>k个最近邻</strong>的训练实例的类别,通过多数表决等方式进行预测.当k=1时称为最近邻算法.</p>
<h4 id="三个基本要素"><a href="#三个基本要素" class="headerlink" title="三个基本要素:"></a>三个基本要素:</h4><ol>
<li>k值的选择</li>
<li>距离度量</li>
<li>分类决策规则</li>
</ol>
<h4 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h4><p>当训练集,距离度量,k值以及分类决策规则确定后,特征空间已经根据这些要素被划分为一些子空间,且子空间里每个点所属的类也已被确定.</p>
<h4 id="策略-1"><a href="#策略-1" class="headerlink" title="策略"></a><strong>策略</strong></h4><ol>
<li><strong>距离</strong>:特征空间中两个实例点的距离是相似程度的反映,k近邻算法一般使用欧氏距离,也可以使用更一般的Lp距离或Minkowski距离.</li>
<li><strong>k值</strong>:k值较小时,整体模型变得复杂,容易发生过拟合.k值较大时,整体模型变得简单.在应用中k一般取较小的值,通过交叉验证法选取最优的k.</li>
<li><p><strong>分类决策规则</strong>:k近邻中的分类决策规则往往是多数表决,多数表决规则等价于经验风险最小化.</p>
<h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4></li>
</ol>
<p>根据给定的距离度量,在训练集中找出与x最邻近的k个点,根据分类规则决定x的类别y.</p>
<p><strong>kd树</strong></p>
<ol>
<li><p>kd树就是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构.kd树更适用于<strong>训练实例数远大于空间维数</strong>时的k近邻搜索.</p>
</li>
<li><p><strong>构造</strong>:可以通过如下<strong>递归</strong>实现:在超矩形区域上选择一个<strong>坐标轴</strong>和此坐标轴上的一个<strong>切分点</strong>,确定一个超平面,该超平面将当前超矩形区域切分为两个子区域.在子区域上重复切分直到子区域内没有实例时终止.通常依次选择坐标轴和选定坐标轴上的<strong>中位数点</strong>为切分点,这样可以得到平衡kd树.</p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/kd_tree.png" alt="avatar"></p>
</li>
</ol>
<h4 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a><strong>搜索</strong></h4><p>从根节点出发,若目标点x当前维的坐标小于切分点的坐标则移动到左子结点,否则移动到右子结点,直到子结点为叶结点为止.以此叶结点为”当前最近点”,<strong>递归</strong>地向上回退,在每个结点:(a)如果该结点比当前最近点距离目标点更近,则以该结点为”当前最近点”(b)”当前最近点”一定存在于该结点一个子结点对应的区域,检查该结点的另一子结点对应的区域是否与以目标点为球心,以目标点与”当前最近点”间的距离为半径的超球体相交.如果相交,移动到另一个子结点,如果不相交,向上回退.持续这个过程直到回退到根结点,最后的”当前最近点”即为最近邻点.</p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/search_kd.png" alt="avatar"></p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/search_kd_2.png" alt="avatar"></p>
<h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><p>朴素贝叶斯是基于<strong>贝叶斯定理</strong>和<strong>特征条件独立假设</strong>的分类方法.首先学习输入/输出的联合概率分布,然后基于此模型,对给定的输入x,利用贝叶斯定理求出后验概率最大的输出y.属于生成模型.</p>
<h4 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a><strong>模型</strong></h4><ol>
<li>首先学习先验概率分布$p(c_k),k=1,2,3,4,…,k$</li>
<li>然后学习条件概率分布,$P\left(X=x | Y=c_{k}\right)=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right)$.如果估计实际,需要指数级的计算,所以朴素贝叶斯法对条件概率分布作了条件独立性的假设,上式变成$\prod_{j=1}^{n} P\left(X^{(n)}=x^{(n)} | Y=c_{k}\right)$</li>
<li>在分类时,通过学习到的模型计算后验概率分布,由贝叶斯定理得到$P\left(Y=c_{k} | X=x\right)=\frac{P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}{\sum_{k} P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}$</li>
<li>将条件独立性假设得到的等式代入,并且注意到分母都是相同的,所以得到朴素贝叶斯分类器:$y=\arg \max _{a_{k}} P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(l)}=x^{(l)} | Y=c_{k}\right)$</li>
</ol>
<p>朴素贝叶斯将实例分到后验概率最大的类中,这等价于期望风险最小化.</p>
<h4 id="算法-2"><a href="#算法-2" class="headerlink" title="算法"></a><strong>算法</strong></h4><ol>
<li>使用<strong>极大似然估计法</strong>估计相应的先验概率:$P\left(Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)}{N}, \quad k=1,2, \cdots, K$和条件概率$P\left(X^{(j)}=a_{n} | Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(x_{i}^{(n)}=a_{j i} y_{i}=c_{k}\right)}{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)}$</li>
<li>计算条件独立性假设下的实例各个取值的可能性,$P\left(Y=c_{k}\right) \prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right), \quad k=1,2, \cdots, K$</li>
<li>选取其中的最大值作为输出.</li>
</ol>
<h4 id="特殊情况"><a href="#特殊情况" class="headerlink" title="特殊情况"></a>特殊情况</h4><ol>
<li>用极大似然估计可能会出现所要估计的概率值为0的情况,在累乘后会影响后验概率的计算结果,使分类产生偏差.可以采用<strong>贝叶斯估计</strong>,在随机变量各个取值的频数上赋予一个正数.$P_{\lambda}\left(X^{(1)}=a_{j q} | Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(x_{i}^{(l)}=a_{\beta}, y_{i}=c_{k}\right)+\lambda}{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)+S_{j} \lambda}$，$S_j$为j属性可能取值数量,当$λ=0$时就是极大似然估计.常取$λ=1$,称为<strong>拉普拉斯平滑</strong>.</li>
<li>如果是连续值的情况,可以假设连续变量服从高斯分布,然后用训练数据估计参数.$P\left(X_{i}=x_{i} | Y=y_{i}\right)=\frac{1}{\sqrt{2 \pi} \sigma_{i j}^{2}} e^{\frac{\left(x_{i}-\mu_{j}\right)^{2}}{2 \sigma_{i}^{2}}}$</li>
</ol>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>决策树是一种基本的分类与回归方法.它可以认为是<strong>if-then规则</strong>的集合,也可以认为是定义在特征空间与类空间上的<strong>条件概率分布</strong>.主要优点是模型具有可读性,分类速度快.其主要围绕着两个问题：</p>
<ol>
<li>如何从数据表中找出最佳节点和最佳分枝？</li>
<li>如何让决策树停止生长，防止过拟合？</li>
</ol>
<h4 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h4><p>分类决策树由<strong>结点</strong>和<strong>有向边</strong>组成.结点分为<strong>内部结点</strong>(表示一个特征或属性)和<strong>叶结点</strong>(表示一个类).决策树的路径具有<strong>互斥且完备</strong>的性质.</p>
<h4 id="策略-2"><a href="#策略-2" class="headerlink" title="策略"></a>策略</h4><p>决策树学习本质上是从训练数据集中归纳出一组分类规则.我们需要的是一个与训练数据<strong>矛盾较小</strong>,同时具有很好的<strong>泛化能力</strong>的决策树.从所有可能的决策树中选取最优决策树是NP完全问题,所以现实中常采用<strong>启发式方法</strong>近似求解.</p>
<h4 id="算法-3"><a href="#算法-3" class="headerlink" title="算法"></a>算法</h4><p>决策树学习算法包含<strong>特征选择</strong>,<strong>决策树的生成</strong>与<strong>决策树的剪枝过程</strong>.生成只考虑局部最优,剪枝则考虑全局最优。</p>
<h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><p>如果利用一个特征进行分类的结果与随机分类的结果没有很大差别,则称这个特征是<strong>没有分类能力</strong>的.扔掉这样的特征对决策树学习的精度影响不大.</p>
<ol>
<li><strong>信息熵</strong>：熵是衡量<strong>随机变量不确定性</strong>的度量.熵越大,随机变量的不确定性就越大.信息熵是信息量的期望，$\left.H(X)=-\sum_{x \in X} P(x) \log P(x)\right)$</li>
<li><strong>条件熵</strong>：条件熵表示在已知随机变量X的条件下随机变量Y的不确定性.$H(Y | X)=\sum_{i=1}^{n} p_{i} H\left(Y | X=x_{i}\right)$</li>
<li><strong>信息增益</strong>：表示得知特征X的信息而使得类Y的信息的<strong>不确定性减少</strong>的程度.定义为集合D的经验熵与特征A在给定条件下D的经验条件熵之差$g(D,A)=H(D)-H(D|A)$,也就是训练数据集中类与特征的<strong>互信息</strong>.</li>
<li><strong>信息增益算法</strong>:计算数据集D的经验熵$H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|_{\mathrm{log}_{2}}\left|C_{k}\right|}{|D|}$,计算特征A对数据集D的经验条件熵$H(D | A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right)=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \sum_{k=1}^{K} \frac{\left|D_{\mu}\right|}{\left|D_{i}\right|} \log _{2} \frac{\left|D_{k}\right|}{\left|D_{i}\right|}$,计算信息增益,选取信息增益最大的特征.</li>
<li><strong>信息增益比</strong>:信息增益值的大小是相对于训练数据集而言的,并无绝对意义.使用信息增益比,$g_{R}(D, A)=\frac{g(D, A)}{H(D)}$可以对这一问题进行校正.</li>
</ol>
<h4 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a><strong>决策树的生成</strong></h4><ol>
<li><strong>ID3算法</strong>:核心是在决策树各个结点上应用<strong>信息增益准则</strong>选择信息增益最大且大于阈值的特征,递归地构建决策树.ID3相当于用极大似然法进行概率模型的选择.由于算法只有树的生成,所以容易产生过拟合.</li>
<li><strong>C4.5算法</strong>:C4.5算法与ID3算法相似,改用<strong>信息增益比</strong>来选择特征.</li>
</ol>
<h4 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a><strong>决策树的剪枝</strong></h4><ol>
<li>在学习时过多考虑如何提高对训练数据的正确分类,从而构建出过于复杂的决策树,产生<strong>过拟合</strong>现象.解决方法是对已生成的决策树进行简化,称为剪枝.</li>
<li>设树的叶结点个数为$|T|$,每个叶结点有$N_t$个样本点,其中$k$类样本点有$N_{tk}$个,剪枝往往通过极小化决策树整体的损失函数$C_{\alpha}(T)=\sum_{i=1}^{\pi} N_{i} H_{i}(T)+\alpha|T|$来实现,其中经验熵$H_{t}(T)=-\sum_{k} \frac{N_{a}}{N_{t}} \log \frac{N_{u}}{N_{t}}$.剪枝通过加入$a|T|$项来考虑模型复杂度,实际上就是用正则化的极大似然估计进行模型选择.</li>
<li><strong>剪枝算法</strong>:剪去某一子结点,如果生成的新的整体树的<strong>损失函数值</strong>小于原树,则进行剪枝,直到不能继续为止.具体可以由动态规划实现.</li>
</ol>
<h4 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a><strong>CART算法</strong></h4><ol>
<li><p>CART既可以用于<strong>分类也</strong>可以用于<strong>回归</strong>.它假设决策树是<strong>二叉树</strong>,内部结点特征的取值为”是”和”否”.递归地构建二叉树,对回归树用<strong>平方误差</strong>最小化准则,对分类数用<strong>基尼指数</strong>最小化准则.</p>
</li>
<li><p><strong>回归树的生成</strong>:在训练数据集所在的输入空间中,递归地将每个区域划分为两个子区域.选择第j个变量和它取的值s作为切分变量和切分点,并定义两个区域$R_{1}(j, s)=\left\{x | x^{(j)} \leqslant s\right\} \quad$和$\quad R_{2}(j, s)=\left\{x | x^{(l)}&gt;s\right\}$,遍历变量j,对固定的j扫描切分点s,求解$\min _{j, z}\left[\min _{c_1} \sum_{x \in R_{1}(j, x)}\left(y_{i}-c_{1}\right)^{2}+\min _{c_{2}} \sum_{x \in R_{2}(j, x)}\left(y_{i}-c_{2}\right)^{2}\right]$.用选定的对(j,s)划分区域并决定相应的输出值$\hat{c}_{m}=\frac{1}{N_{m}} \sum_{x_{i} \in R_{m}(j, x)} y_{i}, x \in R_{m}, \quad m=1,2$,直到满足停止条件.</p>
</li>
<li><p><strong>基尼指数</strong>:假设有K个类,样本属于第k类的概率为$p_k$,则概率分布的基尼指数为:$\operatorname{Gini}(p)=\sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=1-\sum_{k=1}^{K} p_{k}^{2}$,表示不确定性.在特征A的条件下集合D的基尼指数定义为$\operatorname{Gini}(D, A)=\frac{\left|D_{1}\right|}{|D|} \operatorname{Gini}\left(D_{1}\right)+\frac{\left|D_{2}\right|}{|D|} \operatorname{Gini}\left(D_{2}\right)$,表示分割后集合D的不确定性.基尼指数越大,样本集合的<strong>不确定性</strong>也就越大.</p>
</li>
<li><p><strong>分类树的生成</strong></p>
<ol>
<li>从根结点开始,设结点的训练数据集为D,对每个特征A和其可能取的每个值a,计算A=a时的基尼指数,</li>
<li>选择<strong>基尼指数最小</strong>的特征及其对应的切分点作为<strong>最优特征</strong>与<strong>最优切分点</strong>,生成两个子结点</li>
<li>递归进行以上操作,直至满足<strong>停止条件</strong>.停止条件一般是结点中的样本个数小于阈值,或样本集的基尼指数小于阈值,或没有更多特征.</li>
</ol>
</li>
<li><p><strong>CART剪枝</strong></p>
<p>$T_t$表示以t为根结点的子树,$|T_t|$是$T_t$的叶结点个数.可以证明当$\alpha=\frac{C(t)-C\left(T_{t}\right)}{\left|T_{t}\right|-1}$时,$T_t$与$t$有相同的损失函数值,且$t$的结点少,因此$t$比$T_t$更可取,对$T_t$进行剪枝.<strong>自下而上</strong>地对各内部结点t计算$g(t)=\frac{C(t)-C\left(T_{t}\right)}{\left|T_{t}\right|-1}$,并令$a=min(g(t))$,<strong>自上而下</strong>地访问内部节点t,如果有$g(t)=a$,进行剪枝,并对t以<strong>多数表决法</strong>决定其类,得到子树T,如此循环地生成一串<strong>子树序列</strong>,直到新生成的T是由根结点单独构成的树为止.利用<strong>交叉验证法</strong>在子树序列中选取最优子树.</p>
<p>如果是<strong>连续值</strong>的情况,一般用<strong>二分法</strong>作为结点来划分.</p>
</li>
</ol>
<h3 id="logistic回归和最大熵模型"><a href="#logistic回归和最大熵模型" class="headerlink" title="logistic回归和最大熵模型"></a>logistic回归和最大熵模型</h3><h4 id="逻辑斯谛分布"><a href="#逻辑斯谛分布" class="headerlink" title="逻辑斯谛分布"></a><strong>逻辑斯谛分布</strong></h4><p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/logistic.png" alt="avatar"></p>
<p>分布函数$f(x)$以点$(μ,1/2)$为中心对称,$γ$的值越小,曲线在中心附近增长得越快.</p>
<h4 id="逻辑斯谛回归模型"><a href="#逻辑斯谛回归模型" class="headerlink" title="逻辑斯谛回归模型"></a><strong>逻辑斯谛回归模型</strong></h4><p>对于给定的输入x,根据$P(Y=1 | x)=\frac{\exp (w \cdot x+b)}{1+\exp (w \cdot x+b)}$ 和 $P(Y=0 | x)=\frac{1}{1+\exp (w \cdot x+b)}$计算出两个条件概率值的大小,将x分到概率值较大的那一类.将偏置b加入到权值向量w中,并在x的最后添加常数项1,得到$P(Y=1 | x)=\frac{\exp (w \cdot x)}{1+\exp (w \cdot x)}$ 和 $P(Y=0 | x)=\frac{1}{1+\exp (w \cdot x)}$。</p>
<h4 id="对数几率"><a href="#对数几率" class="headerlink" title="对数几率"></a>对数几率</h4><p>如果某事件发生的概率是p,则该事件发生的<strong>几率</strong>(此处几率指该事件发生概率与不发生概率之比)是$\frac{p}{1-p}$,<strong>对数几率</strong>是$log(\frac{p}{1-p})$,那么$\log \frac{P(Y=1 | x)}{1-P(Y=1 | x)}=w \cdot x$，也就是说在逻辑斯谛回归模型中,输出Y=1的对数几率是输入x的<strong>线性函数</strong>,线性函数值越接近正无穷,概率值就越接近1,反之则越接近0.</p>
<h4 id="似然估计"><a href="#似然估计" class="headerlink" title="似然估计"></a><strong>似然估计</strong></h4><p>给定x的情况下参数θ是真实参数的可能性.</p>
<h4 id="模型参数估计"><a href="#模型参数估计" class="headerlink" title="模型参数估计"></a><strong>模型参数估计</strong></h4><p>对于给定的二分类训练数据集,对数似然函数为</p>
<script type="math/tex; mode=display">
\begin{aligned} L(w) &=\sum_{i=1}^{N}\left[y_{i} \log \pi\left(x_{i}\right)+\left(1-y_{i}\right)\log\left(1-\pi\left(x_{i}\right)\right)\right]\\ &=\sum_{i=1}^{N}\left[y_{i} \log \frac{\pi\left(x_{i}\right)}{1-\pi\left(x_{i}\right)}+\log \left(1-\pi\left(x_{i}\right)\right)\right]\\&=\sum_{i=1}^{N}\left[y_{i}\left(w \cdot x_{i}\right)-\log \left(1+\exp \left(w \cdot x_{i}\right)\right]\right.\end{aligned}</script><p>也就是<strong>损失函数</strong>.其中$P(Y=1|x)=π(x)$,对$L(w)$求极大值,就可以得到$w$的估计值.问题变成了以对数似然函数为目标函数的最优化问题.</p>
<h4 id="多项逻辑斯谛回归"><a href="#多项逻辑斯谛回归" class="headerlink" title="多项逻辑斯谛回归"></a><strong>多项逻辑斯谛回归</strong></h4><p>当问题是多分类问题时,可以作如下推广:设Y有K类可能取值,$P(Y=k | x)=\frac{\exp \left(w_{k} \cdot x\right)}{1+\sum_{k=1}^{K-1} \exp \left(w_{k} \cdot x\right)}, \quad k=1,2, \cdots, K-1 \quad P(Y=K | x)=\frac{1}{1+\sum_{k=1}^{K-1} \exp \left(w_{k} \cdot x\right)}$,实际上就是<strong>one-vs-all</strong>的思想,将其他所有类当作一个类,问题转换为二分类问题.</p>
<p>使用最大似然法衡量模型输出的概率与真实概率的差别，假设样本一共有N个，那么这组样本发生的总概率可以表示为：</p>
<script type="math/tex; mode=display">
P(\boldsymbol{W})=\prod_{n=1}^{N}\left(\frac{e^{\boldsymbol{w}_{y_{n}}^{T} \boldsymbol{x}_{n}}}{\sum_{k^{\prime}}^{C} e^{\boldsymbol{w}_{k^{\prime}}^{T} \boldsymbol{x}_{n}}}\right)</script><p>对函数取对数再乘以-1，推导得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
F(\boldsymbol{W})=-\ln (P(\boldsymbol{W})) &=\sum_{n=1}^{N} \ln \left(\frac{\sum_{k^{\prime}}^{C} e^{\boldsymbol{w}_{k^{\prime}}^{T} \boldsymbol{x}_{n}}}{e^{\boldsymbol{w}_{y_{n}}^{T} \boldsymbol{x}_{n}}}\right) \\
&=\sum_{n=1}^{N} \ln \left(\frac{e^{\boldsymbol{w}_{1}^{T} \boldsymbol{x}}+e^{\boldsymbol{w}_{2}^{T} \boldsymbol{x}}+\ldots+e^{\boldsymbol{w}_{y_{n}}^{T} \boldsymbol{x}_{n}}+\ldots+e^{\boldsymbol{w}_{c}^{T} \boldsymbol{x}}}{e^{\boldsymbol{w}_{y_{n}}^{T} \boldsymbol{x}_{n}}}\right) \\
&=\sum_{n=1}^{N} \ln \left(1+\sum_{k \neq y_{n}} e^{\boldsymbol{w}_{k} \boldsymbol{x}_{n}-\boldsymbol{w}_{y_{n}} \boldsymbol{x}_{n}}\right)
\end{aligned}</script><h4 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a><strong>最大熵原理</strong></h4><p>学习概率模型时,在所有可能的概率模型中,<strong>熵最大</strong>的模型是最好的模型.直观地,最大熵原理认为模型首先要满足已有的事实,即<strong>约束条件</strong>.在没有更多信息的情况下,那些不确定的部分都是”<strong>等可能的</strong>“.</p>
<h4 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a><strong>最大熵模型</strong></h4><p>给定训练数据集,可以确定联合分布P(X,Y)的经验分布$\tilde{P}(X=x, Y=y)=\frac{v(X=x, Y=y)}{N}$和边缘分布P(X)的经验分布$\tilde{P}(X=x)=\frac{v(X=x)}{N}$,其中v表示频数,N表示样本容量.用<strong>特征函数$f(x,y)$</strong>=1描述x与y满足某一事实,可以得到特征函数关于P(X,Y)的经验分布的期望值和关于模型P(Y|X)与P(X)的经验分布的期望值,假设两者相等,就得到了<strong>约束条件</strong>$\sum_{x, y} \tilde{P}(x) P(y | x) f(x, y)=\sum_{x, y} \tilde{P}(x, y) f(x, y)$.定义在条件概率分布P(Y|X)上的条件熵为$H(P)=-\sum_{x, y} \tilde{P}(x) P(y | x) \log P(y | x)$,则<strong>条件熵最大</strong>的模型称为最大熵模型.</p>
<h4 id="最大熵模型的学习"><a href="#最大熵模型的学习" class="headerlink" title="最大熵模型的学习"></a><strong>最大熵模型的学习</strong></h4><p>就是求解最大熵模型的过程.等价于<strong>约束最优化问题</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
&\max _{P_{e c}} H(P)=-\sum_{x, y} \tilde{P}(x) P(y | x) \log P(y | x)\\
&\text { s.t. } \quad E_{p}\left(f_{i}\right)=E_{p}\left(f_{i}\right), \quad i=1,2, \cdots, n\\
     &\sum_{y} P(y | x)=1
\end{aligned}</script><p>,将求最大值问题改为等价的求最小值问题</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\min _{R \in C}-H(P)=\sum_{x, y} \tilde{P}(x) P(y | x) \log P(y | x)\\
&\text { s.t. } \quad E_{P}\left(f_{i}\right)-E_{\beta}\left(f_{i}\right)=0, \quad i=1,2, \cdots, n\\
&\sum_{y} P(y | x)=1
\end{aligned}</script><p>引入<strong>拉格朗日乘子</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
L(P, w) & \equiv-H(P)+w_{0}\left(1-\sum_{y} P(y | x)\right)+\sum_{i=1}^{n} w_{i}\left(E_{p}\left(f_{i}\right)-E_{P}\left(f_{i}\right)\right) \\
&=\sum_{x, y} \tilde{P}(x) P(y | x) \log P(y | x)+w_{0}\left(1-\sum_{y} P(y | x)\right) \\
&+\sum_{i=1}^{n} w_{i}\left(\sum_{x, y} \tilde{P}(x, y) f_{i}(x, y)-\sum_{x, y} \tilde{P}(x) P(y | x) f_{i}(x, y)\right)
\end{aligned}</script><p>将原始问题$\min _{p \in C} \max _{w} L(P, w)$转换为无约束最优化的<strong>对偶问题</strong>$\max _{w} \min _{P \in \mathbf{C}} L(P, w)$.首先求解内部的<strong>极小化问题</strong>,即求$L(P,W)$对$P(y|x)$的偏导数.</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial L(P, w)}{\partial P(y | x)} &=\sum_{x, y} \tilde{P}(x)(\log P(y | x)+1)-\sum_{y} w_{0}-\sum_{x, y}\left(\tilde{P}(x) \sum_{i=1}^{n} w_{i} f_{i}(x, y)\right) \\
&=\sum_{x, y} \tilde{P}(x)\left(\log P(y | x)+1-w_{0}-\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)
\end{aligned}</script><p>,并令偏导数等于0,解得$Z_{w}(x)=\sum_{y} \exp \left(\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)$.可以证明对偶函数等价于对数似然函数,那么对偶函数极大化等价于最大熵模型的<strong>极大似然估计</strong>$L(w)=\sum_{x, y} \tilde{P}(x, y) \sum_{i=1}^{n} w_{i} f_{i}(x, y)-\sum_{x} \tilde{P}(x) \log Z_{w}(x)$.之后可以用最优化算法求解得到w.</p>
<h4 id="逻辑回归与最大熵模型的共同点"><a href="#逻辑回归与最大熵模型的共同点" class="headerlink" title="逻辑回归与最大熵模型的共同点"></a>逻辑回归与最大熵模型的共同点</h4><p>最大熵模型与逻辑斯谛回归模型有类似的形式,它们又称为<strong>对数线性模型</strong>.模型学习就是在给定的训练数据条件下对模型进行极大似然估计或正则化的极大似然估计.</p>
<h4 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h4><p>似然函数是<strong>光滑的凸函数</strong>,因此多种最优化方法都适用.</p>
<ol>
<li><strong>改进的迭代尺度法(IIS)</strong>:假设当前的参数向量是w,如果能找到一种方法<strong>w-&gt;w+δ</strong>使对数似然函数值变大,就可以<strong>重复</strong>使用这一方法,直到找到最大值.</li>
<li>逻辑斯谛回归常应用梯度下降法,牛顿法或拟牛顿法.</li>
</ol>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><h4 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h4><p>支持向量机(SVM)是一种<strong>二类分类模型</strong>.它的基本模型是定义在特征空间上的<strong>间隔最大</strong>的线性分类器.支持向量机还包括<strong>核技巧</strong>,使它成为实质上的非线性分类器.<strong>分离超平面</strong>$w^\star x+b^\star =0$,<strong>分类决策函数</strong>$f(s)=sign(w^\star x + b^\star)$.</p>
<h4 id="策略-3"><a href="#策略-3" class="headerlink" title="策略"></a>策略</h4><p><strong>间隔最大化</strong>,可形式化为一个求解<strong>凸二次规划</strong>的问题,也等价于正则化的<strong>合页损失函数</strong>的最小化问题.</p>
<h4 id="数据可分、近似可分、不可分"><a href="#数据可分、近似可分、不可分" class="headerlink" title="数据可分、近似可分、不可分"></a>数据可分、近似可分、不可分</h4><p>当训练数据<strong>线性可分</strong>时,通过硬间隔最大化,学习出<strong>线性可分支持向量机</strong>.当训练数据<strong>近似线性可分</strong>时,通过软间隔最大化,学习出<strong>线性支持向量机</strong>.当训练数据<strong>线性不可分</strong>时,通过使用核技巧及软间隔最大化,学习<strong>非线性支持向量机</strong>.</p>
<h4 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h4><p>当输入空间为欧式空间或离散集合,特征空间为希尔伯特空间时,核函数表示将输入从输入空间<strong>映射</strong>到特征空间得到的特征向量之间的<strong>内积</strong>.通过核函数学习非线性支持向量机等价于在高维的特征空间中学习线性支持向量机.这样的方法称为核技巧.</p>
<h4 id="输入空间和特征空间"><a href="#输入空间和特征空间" class="headerlink" title="输入空间和特征空间"></a>输入空间和特征空间</h4><p>考虑一个二类分类问题,假设输入空间与特征空间为两个不同的空间,输入空间为<strong>欧氏空间或离散集合</strong>,特征空间为<strong>欧氏空间或希尔伯特空间</strong>.支持向量机都将输入映射为特征向量,所以支持向量机的学习是在<strong>特征空间</strong>进行的.</p>
<h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><p>支持向量机的最优化问题一般通过对偶问题化为<strong>凸二次规划问题</strong>求解,具体步骤是将等式约束条件代入优化目标,通过求偏导求得优化目标在不等式约束条件下的极值.</p>
<h4 id="线性可分支持向量机"><a href="#线性可分支持向量机" class="headerlink" title="线性可分支持向量机"></a><strong>线性可分支持向量机</strong></h4><p>当训练数据集线性可分时,存在无穷个分离超平面可将两类数据正确分开.利用<strong>间隔最大化</strong>得到<strong>唯一</strong>最优分离超平面$w^\star x +b = 0$和相应的分类决策函数$f(s)=sign(w^\star x + b^\star)$.称为线性可分支持向量机.</p>
<h5 id="函数间隔"><a href="#函数间隔" class="headerlink" title="函数间隔"></a>函数间隔</h5><p>一般来说,一个点距离分离超平面的<strong>远近</strong>可以表示分类预测的<strong>确信程度</strong>.在超平面$w^\star x +b = 0$确定的情况下,$|wx+b|$能够相对地表示点x距离超平面的远近,而$wx+b$与$y$的符号是否一致能够表示分类是否正确.所以可用$\hat{\gamma}_{i}=y_{i}\left(w \cdot x_{i}+b\right)$来表示分类的正确性及确信度,这就是<strong>函数间隔</strong>.注意到即使超平面不变,函数间隔仍会受w和b的绝对大小影响.</p>
<h5 id="几何间隔"><a href="#几何间隔" class="headerlink" title="几何间隔"></a><strong>几何间隔</strong></h5><p>一般地,当样本点被超平面正确分类时,点x与超平面的距离是$\gamma_{i}=y_{i}\left(\frac{w}{|w|} \cdot x_{i}+\frac{b}{|w|}\right)$其中$||w||$是$w$的$l2$范数.这就是<strong>几何间隔</strong>的定义.定义超平面关于训练数据集T的几何间隔为超平面关于T中所有样本点的几何间隔之<strong>最小值</strong>$\gamma=\min _{i,…,N} \gamma_{1}$.可知$\gamma=\frac{\hat{\gamma}}{|\boldsymbol{w}|}$当$||w||=1$时几何间隔和函数间隔<strong>相等</strong>.</p>
<h5 id="硬间隔最大化"><a href="#硬间隔最大化" class="headerlink" title="硬间隔最大化"></a><strong>硬间隔最大化</strong></h5><p>对线性可分的训练集而言,这里的间隔最大化又称为<strong>硬间隔最大化</strong>.直观解释是对训练集找到几何间隔最大的超平面意味着以<strong>充分大的确信度</strong>对训练数据进行分类.求最大间隔分离超平面即约束最优化问题:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\max _{w, b} \quad \gamma\\
&\text { s.t. } \quad y_{i}\left(\frac{w}{\|w\|} \cdot x_{i}+\frac{b}{\|w\|}\right) \geqslant \gamma, \quad i=1,2, \cdots, N
\end{aligned}</script><p>,将几何间隔用函数间隔表示:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\max _{w, b} \frac{\hat{\gamma}}{\|w\|}\\
&\text { s.t. } \quad y_{i}\left(w \cdot x_{i}+b\right) \geqslant \hat{p}, \quad i=1,2, \cdots, N
\end{aligned}</script><p>,并且注意到函数间隔的取值并不影响最优化问题的解,不妨令函数间隔=1,并让最大化$\frac{1}{||w||}$等价为最小化$\frac{||w||^2}{2}$,问题变为<strong>凸二次规划问题</strong></p>
<script type="math/tex; mode=display">
\min _{w, b} \frac{1}{2}\|w\|^{2} \\
s.t. \quad y_{i}\left(w \cdot x_{i}+b\right)-1 \geqslant 0, \quad i=1,2, \cdots, N</script><h5 id="支持向量和间隔边界"><a href="#支持向量和间隔边界" class="headerlink" title="支持向量和间隔边界"></a><strong>支持向量和间隔边界</strong></h5><p>与分离超平面距离<strong>最近的样本点</strong>的实例称为<strong>支持向量</strong>.支持向量是使最优化问题中的约束条件等号成立的点.因此对$y=+1$的正例点和$y=-1$的负例点,支持向量分别在超平面H1:$wx+b=+1$和H2:$wx+b=-1$.H1和H2平行,两者之间形成一条长带,长带的宽度!称$\frac{2}{||w||}$为<strong>间隔</strong>,H1和H2称为<strong>间隔边界</strong>.在决定分离超平面时只有支持向量起作用,所以支持向量机是由很少的”重要的”训练样本确定的.由对偶问题同样可以得到支持向量一定在间隔边界上.</p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/support_vector.png" alt="avatar"></p>
<h5 id="对偶算法"><a href="#对偶算法" class="headerlink" title="对偶算法"></a><strong>对偶算法</strong></h5><p>引进拉格朗日乘子,定义拉格朗日函数$L(w, b, \alpha)=\frac{1}{2}|w|^{2}-\sum_{i=1}^{N} \alpha_{i} y_{i}\left(w \cdot x_{i}+b\right)+\sum_{i=1}^{N} \alpha_{i}$,根据拉格朗日对偶性,原始问题的对偶问题是极大极小问题:$\max _{\alpha} \min _{w, b} L(w, b, \alpha)$.先求对w,b的<strong>极小值</strong>.将$L(w,b,a)$分别对w,b求偏导数并令其等于0,得</p>
<script type="math/tex; mode=display">
\begin{array}{l}
w=\sum_{i=1}^{N} \alpha_{i} y_{i} x_{i} \\
\sum_{i=1}^{N} \alpha_{i} y_{i}=0
\end{array}</script><p>,代入拉格朗日函数得</p>
<script type="math/tex; mode=display">
\begin{aligned}
L(w, b, \alpha) &=\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum_{i=1}^{N} \alpha_{i} y_{i}\left(\left(\sum_{j=1}^{N} \alpha_{j} y_{j} x_{j}\right) \cdot x_{i}+b\right)+\sum_{i=1}^{N} \alpha_{i} \\
&=-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)+\sum_{i=1}^{N} \alpha_{i}
\end{aligned}</script><p>这就是极小值.接下来对极小值求对a的极大,即是<strong>对偶问题</strong></p>
<script type="math/tex; mode=display">
\begin{array}{l}
\max _{a}-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)+\sum_{i=1}^{N} \alpha_{i} \\
\text { s.t. } \sum_{i=1}^{N} \alpha_{i} y_{i}=0 \\
\quad \alpha_{i} \geqslant 0, \quad i=1,2, \cdots, N
\end{array}</script><p>.将求极大转换为求极小</p>
<script type="math/tex; mode=display">
\begin{array}{cl}
\min _{\alpha} & \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum_{i=1}^{N} \alpha_{i} \\
\text { s.t. } & \sum_{i=1}^{N} \alpha_{i} y_{i}=0 \\
& \alpha_{i} \geqslant 0, \quad i=1,2, \cdots, N
\end{array}</script><p>.由<strong>KKT条件</strong>成立得到</p>
<script type="math/tex; mode=display">
\begin{aligned}
&w^{*}=\sum_{i=1}^{N} \alpha_{i}^{*} y_{i} x_{i}\\
&b^{*}=y_{j}-\sum_{i=1}^{N} \alpha_{i}^{*} y_{i}\left(x_{i} \cdot x_{j}\right)
\end{aligned}</script><p>,其中$j$为使$a_j^<em>&gt;0$的下标之一.所以问题就变为求对偶问题的解$a^</em>$,再求得原始问题的解$w^<em>,b^</em>$,从而得分离超平面及分类决策函数可以看出$w^<em>$和$b^</em>$都只依赖训练数据中$a_i^<em>&gt;0$的样本点Z$(x_i,y_i)$,这些实例点$x_i$被称为<em>*支持向量</em></em>.</p>
<h4 id="线性支持向量机"><a href="#线性支持向量机" class="headerlink" title="线性支持向量机"></a><strong>线性支持向量机</strong></h4><p>如果训练数据是<strong>线性不可分</strong>的(近似线性可分),那么上述方法中的不等式约束并不能都成立,需要修改硬间隔最大化,使其成为<strong>软间隔最大化</strong>.</p>
<h5 id="松弛变量"><a href="#松弛变量" class="headerlink" title="松弛变量"></a>松弛变量</h5><p>线性不可分意味着某些<strong>特异点</strong>不能满足函数间隔大于等于1的约束条件,可以对每个样本点引进一个<strong>松弛变量</strong>,使函数间隔加上松弛变量大于等于1,约束条件变为$y_{i}\left(w \cdot x_{i}+b\right) \geqslant 1-\xi_{i}$,同时对每个松弛变量,支付一个代价,目标函数变为$\frac{1}{2}|w|^{2}+C \sum_{i=1}^{N} \xi_{i}$,其中$C&gt;0$称为<strong>惩罚参数</strong>,C值越大对误分类的惩罚也越大.新目标函数包含了两层含义:使<strong>间隔尽量大</strong>,同时使误分类点的<strong>个数尽量小</strong>.</p>
<h5 id="软间隔最大化"><a href="#软间隔最大化" class="headerlink" title="软间隔最大化"></a>软间隔最大化</h5><p>学习问题变成如下<strong>凸二次规划</strong>问题:</p>
<script type="math/tex; mode=display">
\min _{w, b, k} \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{N} \xi_{i} \\
s.t. \quad y_{i}\left(w \cdot x_{i}+b\right) \geqslant 1-\xi_{i}, \quad i=1,2, \cdots, N \\
\xi_{i} \geqslant 0, \quad i=1,2, \cdots, N</script><p>,可以证明w的解是唯一的,但b的解存在一个<strong>区间</strong>.线性支持向量机包含线性可分支持向量机,因此<strong>适用性更广</strong>.</p>
<h5 id="对偶算法-1"><a href="#对偶算法-1" class="headerlink" title="对偶算法"></a>对偶算法</h5><p>原始问题的对偶问题是,构造<strong>拉格朗日函数</strong> $L(w, b, \xi, \alpha, \mu) \equiv \frac{1}{2}|w|^{2}+C \sum_{i=1}^{N} \xi_{i}-\sum_{i=1}^{N} \alpha_{i}\left(y_{i}\left(w \cdot x_{i}+b\right)-1+\xi_{i}\right)-\sum_{i=1}^{N} \mu_{i} \xi_{i}$ ，先求对w,b,ξ的<strong>极小值</strong>,分别求偏导并令导数为0,得</p>
<script type="math/tex; mode=display">
\begin{aligned}
&w=\sum_{i=1} \alpha_{i} y_{i} x_{i}\\
&\sum_{i=1}^{N} \alpha_{i} y_{i}=0\\
&C-\alpha_{i}-\mu_{i}=0
\end{aligned}</script><p>,代入原函数,再对极小值求a的<strong>极大值</strong>,得到</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\max _{a}-\frac{1}{2} \sum_{i=1}^{N} \sum_{i=1}^{N} \alpha_{i} \alpha, y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)+\sum_{i=1}^{N} \alpha_{i}\\
&\text { s.t. } \quad \sum_{i=1}^{N} \alpha_{i} y_{i}=0\\
&\begin{array}{l}
C-\alpha_{i}-\mu_{i}=0 \\
\alpha_{i} \geqslant 0 \\
\mu_{i} \geqslant 0, \quad i=1,2, \cdots, N
\end{array}
\end{aligned}</script><p>,利用后三条约束<strong>消去μ</strong>,再将求极大转换为<strong>求极小</strong>,得到<strong>对偶问题</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
&\min _{\alpha} \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum_{i=1}^{N} \alpha_{i}\\
&\text { s.t. } \quad \sum_{i=1}^{N} \alpha_{i} y_{i}=0\\
&0 \leqslant \alpha_{i} \leqslant C, \quad i=1,2, \cdots, N
\end{aligned}</script><p>由<strong>KKT条件</strong>成立可以得到</p>
<script type="math/tex; mode=display">
\begin{array}{c}
w^{*}=\sum_{i=1}^{N} \alpha_{i}^{*} y_{i} x_{i} \\
b^{*}=y_{j}-\sum_{i=1}^{N} y_{i} \alpha_{i}^{*}\left(x_{i} \cdot x_{j}\right)
\end{array}</script><p>$j$是满足$0&lt;\alpha_j^<em><C$的下标之一.问题就变为选择惩罚参数$C>0$,求得对偶问题(<strong>凸二次规划问题</strong>)的**最优解$\alpha^</C$的下标之一.问题就变为选择惩罚参数$C></em>$<strong>,代入计算$w^<em>$和$b^</em>$,求得分离超平面和分类决策函数.因为$b$的解并不唯一,所以实际计算$b^*$时可以取所有样本点上的</strong>平均值**.</p>
<h5 id="支持向量"><a href="#支持向量" class="headerlink" title="支持向量"></a>支持向量</h5><p>在<strong>线性不可分</strong>的情况下,将对应与$\alpha_i^<em>&gt;0$的样本点$(x_i,y_i)$的实例点$x_i$称为<em>*支持向量</em></em>.软间隔的支持向量或者在间隔边界上,或者在间隔边界与分类超平面之间,或者再分离超平面误分一侧.</p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/support_soft.png" alt="avatar"></p>
<h5 id="合页损失"><a href="#合页损失" class="headerlink" title="合页损失"></a>合页损失</h5><p>可以认为是0-1损失函数的上界,而线性支持向量机可以认为是优化合页损失函数构成的目标函数.</p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/0_1loss.png" alt="avatar"></p>
<h4 id="非线性支持向量机"><a href="#非线性支持向量机" class="headerlink" title="非线性支持向量机"></a><strong>非线性支持向量机</strong></h4><p>如果分类问题是<strong>非线性</strong>的,就要使用<strong>非线性支持向量机</strong>.主要特点是使用<strong>核技巧</strong>.</p>
<h5 id="非线性分类问题"><a href="#非线性分类问题" class="headerlink" title="非线性分类问题"></a><strong>非线性分类问题</strong></h5><p>用线性分类方法求解非线性分类问题分为两步:首先使用一个变换将原空间的数据映射到新空间,然后在新空间里用线性分类学习方法从训练数据中学习分类模型.</p>
<h5 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a><strong>核函数</strong></h5><p>设X是<strong>输入空间</strong>(欧式空间的子集或离散集合),H为<strong>特征空间</strong>(希尔伯特空间),一般是<strong>高维</strong>甚至无穷维的.如果存在一个从X到H的映射$\phi(x): \mathcal{X} \rightarrow \mathcal{H}$使得对所有x,z属于X,函数K(x,z)满足条件$K(x, z)=\phi(x) \cdot \phi(z)$,点乘代表<strong>内积</strong>,则称K(x,z)为<strong>核函数</strong>.</p>
<h5 id="核技巧-1"><a href="#核技巧-1" class="headerlink" title="核技巧"></a><strong>核技巧</strong></h5><p>基本思想是通过一个<strong>非线性变换</strong>将输入空间对应于一个<strong>特征空间</strong>,使得在输入空间中的<strong>超曲面模型</strong>对应于特征空间中的<strong>超平面模型</strong>(支持向量机).在学习和预测中只定义核函数$K(x,z)$,而<strong>不显式</strong>地定义映射函数.对于给定的核$K(x,z)$,特征空间和映射函数的取法并<strong>不唯一</strong>.注意到在线性支持向量机的对偶问题中,目标函数和决策函数都只涉及输入实例与实例之间的<strong>内积</strong>,$x_i,x_j$可以用核函数$K(x_i,x_j)=\phi (x_i)\phi (x_j)$来<strong>代替</strong>.当映射函数是非线性函数时,学习到的含有核函数的支持向量机是非线性分类模型.在实际应用中,往往依赖领域知识<strong>直接选择</strong>核函数.</p>
<h5 id="正定核"><a href="#正定核" class="headerlink" title="正定核"></a><strong>正定核</strong></h5><p>通常所说的核函数是指<strong>正定核函数</strong>.只要满足正定核的充要条件,那么给定的函数K(x,z)就是正定核函数.设K是定义在X<em>X上的<strong>对称函数</strong>,如果任意xi属于X,K(x,z)对应的<strong>Gram矩阵</strong>$K=\left[K\left(x_{i}, x_{j}\right)\right]_{mxm}$是<em>*半正定矩阵</em></em>,则称$K(x,z)$是正定核.这一定义在构造核函数时很有用,但要验证一个具体函数是否为正定核函数并不容易,所以在实际问题中往往应用已有的核函数.</p>
<h5 id="算法-4"><a href="#算法-4" class="headerlink" title="算法"></a><strong>算法</strong></h5><p>选取适当的核函数K(x,z)和适当的参数C,将线性支持向量机对偶形式中的内积换成核函数,构造并求解最优化问题</p>
<script type="math/tex; mode=display">
\min _{a} \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j} K\left(x_{i}, x_{j}\right)-\sum_{i=1}^{N} \alpha_{i} \\
s.t. \quad \sum_{i=1}^{N} \alpha_{i} y_{i}=0 \\
0 \leqslant \alpha_{i} \leqslant C, \quad i=1,2, \cdots, N</script><p>,选择最优解$a^<em>$的一个正分量$0&lt;a_j^</em>&lt;C$计算$b^{<em>}=y_{j}-\sum_{i=1}^{N} \alpha_{i}^{</em>} y_{i} K\left(x_{i} \cdot x_{j}\right)$,构造决策函数$f(x)=\operatorname{sign}\left(\sum_{i=1}^{N} \alpha_{i}^{<em>} y_{i} K\left(x \cdot x_{i}\right)+b^{</em>}\right)$</p>
<h5 id="常用核函数"><a href="#常用核函数" class="headerlink" title="常用核函数"></a><strong>常用核函数</strong></h5><ol>
<li><strong>多项式核函数(polynomial kernel function)</strong> :$K(x, z)=(x \cdot z+1)^{p}$,对应的支持向量机是一个p次多项式分类器,分类决策函数为:$f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{i}} a_{i}^{<em>} y_{i}\left(x_{i} \cdot x+1\right)^{p}+b^{</em>}\right)$</li>
<li><strong>高斯核函数(Gaussian krenel function)</strong> :$K(x, z)=\exp \left(-\frac{|x-z|^{2}}{2 \sigma^{2}}\right)$ ,对应的支持向量机是高斯径向基函数(RBF)分类器.分类决策函数为$f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{t}} a_{i}^{<em>} y_{i} \exp \left(-\frac{|x-z|^{2}}{2 \sigma^{2}}\right)+b^{</em>}\right)$</li>
<li><strong>字符串核函数(string kernel function)</strong>: 核函数不仅可以定义在欧氏空间上,还可以定义在<strong>离散数据的集合</strong>上.字符串核函数给出了字符串中长度等于n的所有子串组成的特征向量的余弦相似度.</li>
</ol>
<h5 id="序列最小最优化-SMO-算法"><a href="#序列最小最优化-SMO-算法" class="headerlink" title="序列最小最优化(SMO)算法"></a><strong>序列最小最优化(SMO)算法</strong></h5><p>SMO是一种<em>快速求解凸二次规划问题</em></p>
<script type="math/tex; mode=display">
\begin{aligned}
&\min _{\alpha} \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j} K\left(x_{i}, x_{j}\right)-\sum_{i=1}^{N} \alpha_{i}\\
&\text { s.t. } \quad \sum_{i=1}^{N} \alpha_{i} y_{i}=0\\
&0 \leqslant \alpha_{i} \leqslant C, \quad i=1,2, \cdots, N
\end{aligned}</script><p>的算法.基本思路是:如果所有变量都满足此优化问题的KKT条件,那么解就得到了.否则,选择<strong>两个变量</strong>,固定其他变量,针对这两个变量构建一个二次规划问题.不断地将原问题分解为<strong>子问题</strong>并对子问题求解,就可以求解原问题.注意子问题两个变量中只有一个是<strong>自由变量</strong>,另一个由<strong>等式约束</strong>确定.</p>
<h5 id="两个变量二次规划的求解方法"><a href="#两个变量二次规划的求解方法" class="headerlink" title="两个变量二次规划的求解方法"></a><strong>两个变量二次规划的求解方法</strong></h5><p>假设选择的两个变量是a1,a2,其他变量是固定的,于是得到子问题</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\begin{aligned}
\min _{\alpha, \alpha_{i}} W\left(\alpha_{1}, \alpha_{2}\right)=& \frac{1}{2} K_{11} \alpha_{1}^{2}+\frac{1}{2} K_{22} \alpha_{2}^{2}+y_{1} y_{2} K_{12} \alpha_{1} \alpha_{2} \\
&-\left(\alpha_{1}+\alpha_{2}\right)+y_{1} \alpha_{1} \sum_{i=1}^{N} y_{i} \alpha_{i} K_{n}+y_{2} \alpha_{2} \sum_{i=1}^{N} y_{i} \alpha_{i} K_{i}
\end{aligned}\\
&\text { s.t. } \quad \alpha_{1} y_{1}+\alpha_{2} y_{2}=-\sum_{i=3}^{N} y_{i} \alpha_{i}=\zeta\\
&0 \leqslant \alpha_{i} \leqslant C, \quad i=1,2
\end{aligned}</script><p>,$\epsilon$是常数,目标函数式省略了不含$a_1,a_2$的常数项.考虑不等式约束和等式约束,要求的是目标函数在一条平行于对角线的线段上的最优值</p>
<p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/1.png" alt="avatar"></p>
<p>问题变为<strong>单变量</strong>的最优化问题.假设初始可行解为aold,最优解为anew,考虑沿着约束方向未经剪辑的最优解anew,unc(即未考虑不等式约束).对该问题求偏导数,并令导数为0,代入原式,令$E_{i}=g\left(x_{i}\right)-y_{i}=\left(\sum_{j=1}^{N} \alpha, y_{j} K\left(x_{j}, x_{i}\right)+b\right)-y_{i}, \quad i=1,2$,得到$\alpha_{2}^{\text {new, } \text { unc }}=\alpha_{2}^{\text {old }}+\frac{y_{2}\left(E_{1}-E_{2}\right)}{\eta}$,经剪辑后a2的解是</p>
<script type="math/tex; mode=display">
\alpha_{2}^{\text {new }}=\left\{\begin{array}{ll}H, & \alpha_{2}^{\text {new }, \text { unc }}>H \\ \alpha_{2}^{\text {new }, \text { unc }}, & L \leqslant \alpha_{2}^{\text {new}, \text { unc}} \leqslant H \\ L, & \alpha_{2}^{\text {new }, \text { unc }}<L\end{array}\right.</script><p>L与H是$a_2^{new}$所在的对角线段端点的界.并解得$\alpha_{1}^{\mathrm{new}}=\alpha_{1}^{\mathrm{old}}+y_{1} y_{2}\left(\alpha_{2}^{\mathrm{old}}-\alpha_{2}^{\mathrm{new}}\right)$</p>
<h5 id="变量的选择方法"><a href="#变量的选择方法" class="headerlink" title="变量的选择方法"></a><strong>变量的选择方法</strong></h5><p>在每个子问题中选择两个变量优化,其中至少一个变量是违反KKT条件的.第一个变量的选取标准是<strong>违反KKT条件最严重</strong>的样本点,第二个变量的选取标准是希望能使该变量有<strong>足够大的变化</strong>,一般可以选取使对应的$|E1-E2|$最大的点.在每次选取完点后,<strong>更新</strong>阈值$b$和差值$Ei$.</p>
<h3 id="提升方法"><a href="#提升方法" class="headerlink" title="提升方法"></a>提升方法</h3><h4 id="提升方法-1"><a href="#提升方法-1" class="headerlink" title="提升方法"></a>提升方法</h4><p>boosting是<strong>一种常用的统计学习方法,是集成学习的一种.它通过改变训练样本的权重(概率分布),学习</strong>多个<strong>弱分类器(基本分类器),并将这些分类器</strong>线性组合**来构成一个强分类器提高分类的性能.</p>
<h4 id="加法模型和前向分步算法"><a href="#加法模型和前向分步算法" class="headerlink" title="加法模型和前向分步算法"></a>加法模型和前向分步算法</h4><p>加法模型$f(x)= \sum_{m=1}^M{\beta_mb(x;\gamma_m)}$,其中，$b(x;\gamma_m)$为基函数，$\gamma_m$为基函数参数，$\beta_m$为基函数的系数。在给定训练数据及损失函数$L(y,f(x))$的条件下，学习加法模型$f(x)$成为经验风险极小化即损失函数极小化问题：</p>
<script type="math/tex; mode=display">
min_{\beta_m,\gamma_m}\sum_{m=1}^{M}{\beta_m b(x_i;\gamma_m)}</script><p>通常这是一个复杂的优化问题。</p>
<p>前向分步算法求解这一优化问题的想法是：因为学习的是加法模型，如果能够从前向后，每一步只学习一个基函数及其系数：$\left(\beta_{m}, \gamma_{m}\right)=\arg \min _{\beta, y} \sum_{i=1}^{N} L\left(y_{i}, f_{m-1}\left(x_{i}\right)+\beta b\left(x_{i} ; \gamma\right)\right)$，得到参数βm和γm,更新$f_{m}(x)=f_{m-1}(x)+\beta_{m} b\left(x ; \gamma_{m}\right)$,逐步逼近优化目标函数式，那么就可以简化优化的复杂度，最终得到加法模型。</p>
<h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a><strong>AdaBoost</strong></h4><h5 id="思想："><a href="#思想：" class="headerlink" title="思想："></a>思想：</h5><p>AdaBoost提高那些被前一轮弱分类器错误分类样本的权值,而降低那些被正确分类样本的权值.然后采取<strong>加权多数表决</strong>的方法组合弱分类器.</p>
<h5 id="算法-5"><a href="#算法-5" class="headerlink" title="算法"></a><strong>算法</strong></h5><p>首先假设训练数据集具有均匀的权值分布D1,使用具有<strong>权值分布</strong>Dm的训练数据集学习得到<strong>基本分类器</strong>Gm(x),计算<strong>分类误差率</strong>$e_{m}=P\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)=\sum_{i=1}^{N} w_{m i} I\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)$和Gm(x)的<strong>系数</strong>$\alpha_{m}=\frac{1}{2} \log \frac{1-e_{m}}{e_{m}}$,更新训练数据集的权值分布$D_{m+1}=\left(w_{m+1,1}, \cdots, w_{m+1, i}, \cdots, w_{m+1, N}\right)$，其中</p>
<script type="math/tex; mode=display">
w_{m+1, i}=\left\{\begin{array}{ll}
\frac{w_{mi}}{Z_{m}} \mathrm{e}^{-\alpha_{m}}, & G_{m}\left(x_{i}\right)=y_{i} \\
\frac{w_{m i}}{Z_{m}} \mathrm{e}^{\alpha_{m}}, & G_{m}\left(x_{i}\right) \neq y_{i}
\end{array}\right.</script><p>$Z_m$是使Dm+1成为概率分布的<strong>规范化因子</strong>$Z_{m}=\sum_{i=1}^{N} w_{m i} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right)$.重复上述操作M次后得到M个弱分类器,构建线性组合得到<strong>最终分类器</strong>$G(x)=\operatorname{sign}(f(x))=\operatorname{sign}\left(\sum_{m=1}^{M} \alpha_{m} G_{m}(x)\right)$</p>
<h4 id="提升树"><a href="#提升树" class="headerlink" title="提升树"></a><strong>提升树</strong></h4><p>提升树是模型为加法模型,算法为前向分布算法,基函数为<strong>决策树</strong>的提升方法.第m步的模型是$f_{m}(x)=f_{m-1}(x)+T\left(x ; \Theta_{m}\right)$,通过经验风险极小化确定下一棵决策树的参数$\hat{\Theta}_{m}=\arg \min _{\theta_{m}} \sum_{i=1}^{N} L\left(y_{i}, f_{m-1}\left(x_{i}\right)+T\left(x_{i} ; \Theta_{m}\right)\right)$.不同问题的提升树学习算法主要区别在于使用的<strong>损失函数</strong>不同.</p>
<h5 id="二类分类问题"><a href="#二类分类问题" class="headerlink" title="二类分类问题"></a><strong>二类分类问题</strong></h5><p>只需将AdaBoost算法中的基本分类器限制为二类分类数即可.</p>
<h5 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a><strong>回归问题</strong></h5><p>如果将输入空间划分为J个互不相交的区域,并且在每个区域上确定输出的常量$C_j$,那么树可表示为$T(x ; \Theta)=\sum_{j=1}^{J} c_{j} I\left(x \in R_{j}\right)$,其中$\Theta=\left\{\left(R_{1}, c_{1}\right),\left(R_{2}, c_{2}\right), \cdots,\left(R_{J}, c_{J}\right)\right\}$提升树采用<strong>前向分步算法</strong>:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&f_{0}(x)=0\\
&\begin{array}{l}
f_{m}(x)=f_{m-1}(x)+T\left(x ; \Theta_{m}\right), m=1,2, \cdots, M \\
f_{M}(x)=\sum_{m=1}^{M} T\left(x ; \Theta_{m}\right)
\end{array}
\end{aligned}</script><p>.当采用平方误差损失函数时,损失变为</p>
<script type="math/tex; mode=display">
\begin{array}{l}
L\left(y, f_{m-1}(x)+T\left(x ; \Theta_{m}\right)\right) \\
\quad=\left[y-f_{m-1}(x)-T\left(x ; \Theta_{m}\right)\right]^{2} \\
\quad=\left[r-T\left(x ; \Theta_{m}\right)\right]^{2}
\end{array}</script><p>,其中r是当前模型拟合数据的<strong>残差</strong>.每一步都只需<strong>拟合残差</strong>学习一个回归树即可.</p>
<h5 id="存在的缺点"><a href="#存在的缺点" class="headerlink" title="存在的缺点"></a>存在的缺点</h5><p>当损失函数式平方误差损失函数或者交叉熵损失函数的时候，残差即为对应的梯度，这个时候损失函数沿着梯度的方向下降最快。当损失函数式其他损失函数的时候，残差和损失函数的导数并不相等，函数收敛的速度就会没有沿着梯度的方向收敛的快。</p>
<h4 id="梯度提升树-GBDT"><a href="#梯度提升树-GBDT" class="headerlink" title="梯度提升树(GBDT)"></a>梯度提升树(GBDT)</h4><p>利用最速下降法的近似方法来实现每一步的优化,关键在于用损失函数的<strong>负梯度</strong>在当前模型的值$-\left[\frac{\partial L\left(y, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{-1}(x)}$作为回归问题中提升树算法中的残差的<strong>近似值</strong>,每一步以此来估计回归树叶结点区域以拟合残差的近似值,并利用线性搜索估计叶结点区域的值使损失函数最小化,然后更新回归树即可.</p>
<h4 id="Xgboost"><a href="#Xgboost" class="headerlink" title="Xgboost"></a>Xgboost</h4><p>相比传统GBDT有以下优点:</p>
<ol>
<li>在优化时用到了二阶导数信息.</li>
<li>在代价函数里加入了正则项.</li>
<li>每次迭代后都将叶子结点的权重乘上一个系数,削弱每棵树的影响.</li>
<li>列抽样.</li>
<li>在训练前对数据进行排序,保存为block结构,并行地对各个特征进行增益计算.</li>
</ol>
<h3 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h3><p>EM算法是一种<strong>迭代</strong>算法,用于含有<strong>隐变量</strong>的概率模型参数的极大似然估计.每次迭代由两步组成:E步,求<strong>期望</strong>(expectation),M步,求<strong>极大值</strong>(maximization),直至收敛为止.</p>
<h4 id="隐变量"><a href="#隐变量" class="headerlink" title="隐变量"></a><strong>隐变量</strong></h4><p>不能被直接观察到，但是对系统的状态和能观察到的输出存在影响的一种东西.</p>
<h4 id="算法-6"><a href="#算法-6" class="headerlink" title="算法"></a><strong>算法</strong></h4><ol>
<li>选择参数的初始值θ(0),开始迭代.注意EM算法对初值是<strong>敏感</strong>的.</li>
<li><strong>E步</strong>:θ(i)为第i次迭代参数θ的估计值,在第i+1次迭代的E步,计算$\begin{aligned} Q\left(\theta, \theta^{(i)}\right) &amp;=E_{z}\left[\log P(Y, Z | \theta) | Y, \theta^{(i)}\right] =\sum_{z} \log P(Y, Z | \theta) P\left(Z | Y, \theta^{(i)}\right) \end{aligned}$ ,$P(Z|Y,θ(i))$是在给定<strong>观测数据</strong>Y和当前参数估计θ(i)下<strong>隐变量数据</strong>Z的条件概率分布.</li>
<li><strong>M步</strong>:求使Q(θ,θ(i))极大化的θ,确定第i+1次迭代的参数的估计值$\theta^{(i+1)}=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)$</li>
<li>重复2和3直到<strong>收敛</strong>,一般是对较小的正数$\varepsilon1$和$\varepsilon2$满足$\left|\theta^{(i+1)}-\theta^{(i)}\right|&lt;\varepsilon_{1} \quad$ 或$\quad\left|Q\left(\theta^{(i+1)}, \theta^{(i)}\right)-Q\left(\theta^{(i)}, \theta^{(i)}\right)\right|&lt;\varepsilon_{2}$则停止迭代.</li>
</ol>
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>EM算法是通过不断求解<strong>下界</strong>的极大化逼近求解对数似然函数极大化的算法.可以用于生成模型的<strong>非监督学习</strong>.生成模型由联合概率分布P(X,Y)表示.X为观测数据,Y为未观测数据.</p>
<h3 id="隐马尔科夫模型-HMM"><a href="#隐马尔科夫模型-HMM" class="headerlink" title="隐马尔科夫模型(HMM)"></a>隐马尔科夫模型(HMM)</h3><p>隐马尔可夫模型是关于<strong>时序</strong>的概率模型,描述由一个隐藏的马尔可夫链随机生成不可观测的<strong>状态序列</strong>,再由各个状态生成一个观测而产生<strong>观测随机序列</strong>的过程.HMM是一种生成式模型，它的理论基础是朴素贝叶斯，本质上就类似于我们将朴素贝叶斯在单样本分类问题上的应用推广到序列样本分类问题上。</p>
<h4 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h4><p>设Q是所有可能的状态的集合$Q=\left\{q_{1}, q_{2}, \cdots, q_{N}\right\}$,V是所有可能的观测的集合$V=\left\{v_{1}, v_{2}, \cdots, v_{M}\right\}$,I是长度为T的状态序列$I=\left(i_{1}, i_{2}, \cdots, i_{T}\right)$, O是对应的观测序列$O=\left(o_{1}, o_{2}, \cdots, o_{T}\right)$,</p>
<ol>
<li>A是<strong>状态转移概率矩阵</strong>$A=\left[a_{i j}\right]_{N \times N}$,$a_{ij}$表示在时刻t处于状态$q_i$的条件下在时刻t+1转移到状态$q_j$的概率.</li>
<li>.B是<strong>观测概率矩阵</strong> $B=\left[b_{j}(k)\right]_{N \times M}$,$b_{ij}$是在时刻t处于状态$q_j$的条件下生成观测$v_k$的概率.</li>
<li>$\pi$是<strong>初始状态概率向量</strong>$\pi=\pi(x)$,$\pi_i$表示时刻t=1处于状态qi的概率.</li>
</ol>
<p>隐马尔可夫模型由初始状态概率向量$pi$,状态转移概率矩阵A以及观测概率矩阵B确定.$\pi$和A决定即隐藏的<strong>马尔可夫链</strong>,生成不可观测的<strong>状态序列</strong>.B决定如何从状态生成观测,与状态序列综合确定了<strong>观测序列</strong>.因此,隐马尔可夫模型可以用<strong>三元符号</strong>表示$\lambda = (A,B,\pi)$</p>
<h4 id="两个基本假设"><a href="#两个基本假设" class="headerlink" title="两个基本假设"></a>两个基本假设</h4><ol>
<li><strong>齐次马尔可夫性假设</strong>:假设隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一时刻的状态.</li>
<li><strong>观测独立性假设</strong>:假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态.</li>
</ol>
<h4 id="三个基本问题"><a href="#三个基本问题" class="headerlink" title="三个基本问题"></a>三个基本问题</h4><h5 id="1-概率计算问题"><a href="#1-概率计算问题" class="headerlink" title="1. 概率计算问题"></a><strong>1. 概率计算问题</strong></h5><p>给定模型$\lambda = (A,B,\pi)$和观测序列,$O=\left(o_{1}, o_{2}, \cdots, o_{T}\right)$计算在模型$\lambda$下观测序列O出现的概率$P(O|λ)$.</p>
<ol>
<li>直接计算：列举所有可能长度为T的状态序列,求各个状态序列I与观测序列O的联合概率,但计算量太大,实际操作不可行.</li>
<li><strong>前向算法</strong>：定义到时刻t部分观测序列为$o_1$~$o_t$且状态为$q_i$的概率为<strong>前向概率</strong>,记作$\alpha_{t}(i)=P\left(o_{1}, o_{2}, \cdots, o_{t}, i_{t}=q_{i} | \lambda\right)$.初始化前向概率$\alpha_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right), \quad i=1,2, \cdots, N$，递推，对$t=1$ ~ $T-1$,$\alpha_{t+1}(i)=\left[\sum_{j=1}^{N} \alpha_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right), \quad i=1,2, \cdots, N$,得到$P(O | \lambda)=\sum_{i=1}^{N} \alpha_{T}(i)$减少计算量的原因在于每一次计算直接引用前一个时刻的计算结果,避免重复计算.</li>
<li><strong>后向算法</strong>:定义在时刻t状态为$q_i$的条件下,从t+1到T的部分观测序列为$o_{i+1}$~$o_T$的概率为<strong>后向概率</strong>,记作$\beta_{t}(i)=P\left(o_{t+1}, o_{t+2}, \cdots, o_{r} | i_{t}=q_{i}, \lambda\right)$.初始化后向概率$\beta_{r}(i)=1, \quad i=1,2, \cdots, N$,递推,对$t=T-1$~$1$$\beta_{t}(i)=\sum_{j=1}^{N} a_{i j} b_{j}\left(o_{i+1}\right) \beta_{i+1}(j), \quad i=1,2, \cdots, N$,得到$P(O | \lambda)=\sum_{i=1}^{N} \pi_{i} b_{i}\left(o_{1}\right) \beta_{1}(i)$</li>
</ol>
<h5 id="2-学习算法"><a href="#2-学习算法" class="headerlink" title="2. 学习算法"></a><strong>2. 学习算法</strong></h5><p>已知观测序列$O=(o_1,o_2, \cdots,o_r)$,估计模型$\lambda = (A,B,\pi)$,的参数,使得在该模型下观测序列概率$p(O|\lambda)$最大.根据训练数据是否包括观察序列对应的状态序列分别由监督学习与非监督学习实现.</p>
<ol>
<li><p>监督学习：估计转移概率$\hat{a}_{i j}=\frac{A_{i j}}{\sum_{j=1}^{N} A_{i j}}, \quad i=1,2, \cdots, N ; \quad j=1,2, \cdots, N$ 和观测概率$\hat{b}_{j}(k)=\frac{B_{j k}}{\sum_{k=1}^{M} B_{j k}}, \quad j=1,2, \cdots, N, k=1,2, \cdots, M$.初始状态概率$\pi_i$的估计为S个样本中初始状态为$q_i$的频率.</p>
</li>
<li><p><strong>非监督学习(Baum-Welch算法)</strong>:将观测序列数据看作观测数据O,状态序列数据看作不可观测的<strong>隐数据</strong>I.首先确定完全数据的对数似然函数$log p(O,I|\lambda)$,求Q函数</p>
<script type="math/tex; mode=display">
\begin{aligned}
Q(\lambda, \bar{\lambda})=& \sum_{t} \log \pi_{i_1} P(O, I | \bar{\lambda}) \\
&+\sum_{I}\left(\sum_{i=1}^{I-1} \log a_{i_t,i_{t+1}}\right) P(O, I | \bar{\lambda}) \\
&+\sum_{I}\left(\sum_{i=1}^{T} \log b_{i_t}\left(o_{t}\right)\right) P(O, I | \bar{\lambda})
\end{aligned}</script><p>,用拉格朗日乘子法极大化Q函数求模型参数$\pi_{i}=\frac{P\left(O, i_{1}=i | \bar{\lambda}\right)}{P(O | \bar{\lambda})}$,$a_{i j}=\frac{\sum_{i=1}^{T-1} P\left(O, i_{t}=i, i_{t+1}=j | \bar{\lambda}\right)}{\sum_{t=1}^{T-1} P\left(O, i_{t}=i | \bar{\lambda}\right)}$,$b_{j}(k)=\frac{\sum_{i=1}^{T} P\left(O, i_{t}=j | \bar{\lambda}\right) I\left(o_{i}=v_{k}\right)}{\sum_{i=1}^{T} P\left(O, i_{t}=j | \bar{\lambda}\right)}$,</p>
</li>
</ol>
<h5 id="3-预测问题"><a href="#3-预测问题" class="headerlink" title="3. 预测问题"></a><strong>3. 预测问题</strong></h5><p>也称为解码问题.已知模型$\lambda = (A,B,\pi)$和观测序列$O=(O_1,O_2,\cdots,O_T)$,求对给定观测序列条件概率$P(I|O)$最大的状态序列$I=(i_1,i_2,\cdots,i_T)$</p>
<ol>
<li><p><strong>近似算法</strong>: 在每个时刻t选择在该时刻最有可能出现的状态$i_t^<em>$,从而得到一个状态序列作为预测的结果.优点是<em>*计算简单</em></em>,缺点是不能保证状态序列整体是最有可能的状态序列</p>
</li>
<li><p><strong>维特比算法</strong>:用<strong>动态规划</strong>求概率最大路径,这一条路径对应着一个状态序列.从t=1开始,递推地计算在时刻t状态为i的各条部分路径的最大概率,直至得到时刻t=T状态为i的各条路径的最大概率.时刻t=T的最大概率即为<strong>最优路径</strong>的概率$P^\star$,最优路径的<strong>终结点</strong>$i_t^\star$也同时得到,之后从终结点开始由后向前逐步求得<strong>结点</strong>,得到最优路径.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viterbi</span><span class="params">(obs, states, Pi, A, B)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param obs:观测序列</span></span><br><span class="line"><span class="string">    :param states:隐状态</span></span><br><span class="line"><span class="string">    :param Pi:初始概率（隐状态）</span></span><br><span class="line"><span class="string">    :param A:转移概率（隐状态）</span></span><br><span class="line"><span class="string">    :param B: 发射概率 （隐状态表现为显状态的概率）</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 路径概率表 V[时间][隐状态] = 概率</span></span><br><span class="line">    V = [&#123;&#125;]</span><br><span class="line">    <span class="comment"># 一个中间变量，代表当前状态是哪个隐状态</span></span><br><span class="line">    path = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化初始状态 (t == 0)</span></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> states:</span><br><span class="line">        V[<span class="number">0</span>][y] = Pi[y] * B[y][obs[<span class="number">0</span>]]</span><br><span class="line">        path[y] = [y]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对 t &gt; 0 跑一遍维特比算法</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">1</span>, len(obs)):</span><br><span class="line">        V.append(&#123;&#125;)</span><br><span class="line">        newpath = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> states:</span><br><span class="line">            <span class="comment"># 概率 隐状态 =    前状态是y0的概率 * y0转移到y的概率 * y表现为当前状态的概率</span></span><br><span class="line">            (prob, state) = max([(V[t - <span class="number">1</span>][y0] * A[y0][y] * B[y][obs[t]], y0) <span class="keyword">for</span> y0 <span class="keyword">in</span> states])</span><br><span class="line">            <span class="comment"># 记录最大概率</span></span><br><span class="line">            V[t][y] = prob</span><br><span class="line">            <span class="comment"># 记录路径</span></span><br><span class="line">            newpath[y] = path[state] + [y]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 不需要保留旧路径</span></span><br><span class="line">        path = newpath</span><br><span class="line"></span><br><span class="line">    print_dptable(V)</span><br><span class="line">    (prob, state) = max([(V[len(obs) - <span class="number">1</span>][y], y) <span class="keyword">for</span> y <span class="keyword">in</span> states])</span><br><span class="line">    <span class="keyword">return</span> (prob, path[state])</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 打印路径概率表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_dptable</span><span class="params">(V)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"    "</span>,</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(V)): <span class="keyword">print</span> <span class="string">"%7d"</span> % i,</span><br><span class="line">    <span class="keyword">print</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> V[<span class="number">0</span>].keys():</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"%.5s: "</span> % y,</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(len(V)):</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"%.7s"</span> % (<span class="string">"%f"</span> % V[t][y]),</span><br><span class="line">        <span class="keyword">print</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="最大熵马尔科夫模型-MEMM"><a href="#最大熵马尔科夫模型-MEMM" class="headerlink" title="最大熵马尔科夫模型(MEMM)"></a>最大熵马尔科夫模型(MEMM)</h3><p>最大熵马尔科夫模型利用判别式模型的特点，直接对每一个时刻的状态建立一个分类器，然后将所有的分类器的概率值连乘起来$P\left(y_{1}^{n} | x_{1}^{n}\right)=\prod_{t=1}^{n} P\left(y_{t} | y_{t-1}, x_{t}\right)$。为了实现是对整个序列进行的分类，在每个时刻t时，它的特征不仅来自当前观测值$x_t$，而且还来自前一状态值$y_{t-1}$,通过最大熵分类器建模$P\left(y_{t}=y^{<em>} | y_{t-1}=y^{\prime}, x_{t}\right)=\frac{1}{Z\left(x_{t}, y^{\prime}\right)} \exp \left(\sum_{a} \lambda_{a} f_{a}\left(x_{t}, y^{\prime}, y^{</em>}\right)\right)$,其中，$Z\left(x_{t}, y \prime\right)=\sum_{y} \exp \left(\sum_{a} \lambda_{a} f_{a}\left(x_{t}, y \prime, y\right)\right)$，</p>
<h4 id="标注偏置问题"><a href="#标注偏置问题" class="headerlink" title="标注偏置问题"></a>标注偏置问题</h4><p>使用维特比算法进行解码时，$v_{t}(j)=\max _{i} v_{t-1}(i) * P\left(y_{j} | y_{i}, x_{t}\right) 1 \leq j \leq n, 1&lt;t&lt;T$。最大熵模型在每一个时刻，针对不同的前一状态y′进行归一化操作，这是一种局部的归一化操作，会存在标签偏置问题。</p>
<h5 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h5><p><img src="/2020/01/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%A7%E6%80%BB%E7%BB%93/label_bias.png" alt="avatar"></p>
<p>状态转换(1→2),(2→3),(4→5),(5→3)的概率值都是1，而无论观测值是什么，换言之有$P(2|1,i)=P(2|1,o)=1$</p>
<p>你可能会很惊讶$P(2∣1,i)=1,P(2∣1,o)=1$怎么可能会成立呢？你可以套用上面的公式试一试，由于状态”1”的只能转换为”2”，所以计算归一化项时， 其实只有一个枚举值，就是状态”2”，所以无论你分子为多少，分母都和它一样，所以概率值就是1。在这种情况下，其实观测值并没有任何作用，这就是标签偏置。</p>
<h5 id="后果："><a href="#后果：" class="headerlink" title="后果："></a><strong>后果：</strong></h5><p>它会造成什么后果呢？<br>他会导致模型进行预测时只依赖数据统计出来的概率值，没有利用到样本的特征。<br>假设训练集现在有3个rib和1个rob，当我们在测试阶段，遇到词rob，它会被解码成什么状态序列呢？答案是(0→1→2→3)！你可以套公式试一试，因为$P(1∣0,r)&gt;P(4∣0,r)$,$P(2∣1,o)=P(5∣4,0)=1,P(3∣2,b)&gt;P(3∣5,b)$。</p>
<h5 id="原因"><a href="#原因" class="headerlink" title="原因"></a><strong>原因</strong></h5><p>那么问题出在哪里呢？因为MEMM中在每一时刻t，都在前一时刻某状态y′下做了局部的归一化操作，如何解决这种标签偏置问题呢？<br>在CRF中并不是对每个时刻都进行一次分类，而是直接对整个序列进行分类，做一个全局的归一化操作。</p>
<h3 id="条件随机场CRF"><a href="#条件随机场CRF" class="headerlink" title="条件随机场CRF"></a>条件随机场CRF</h3><h4 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h4><p>结点表示随机变量，边表示随机变量之间的概率依赖关系。</p>
<h5 id="马尔科夫性"><a href="#马尔科夫性" class="headerlink" title="马尔科夫性"></a>马尔科夫性</h5><ol>
<li>成对马尔可夫性</li>
<li>局部马尔科夫性</li>
<li>全局马尔科夫性</li>
</ol>
<h5 id="概率无向图模型的因式分解"><a href="#概率无向图模型的因式分解" class="headerlink" title="概率无向图模型的因式分解"></a>概率无向图模型的因式分解</h5><h6 id="团与最大团"><a href="#团与最大团" class="headerlink" title="团与最大团"></a>团与最大团</h6><p>无向图G中任何两个结点均有边连接的结点子集称为<strong>团</strong>。若C是无向图G的一个团，并且不能再加进任何一个G的结点使其成为一个更大的团，称此C为<strong>最大团</strong>。</p>
<p>给定概率无向图模型，设其无向图为G，C为G上的最大团，$Y_C$表示C对应的随机变量。那么概率无向图模型的联合概率分布$P(Y)$可写作图中所有最大团C上的函数$\phi_C(Y_C)$的乘积的形式。</p>
<p><strong>Hammersley-Clifford定理</strong><br>概率无向图模型的联合概率分布$P(Y)$可以表示为如下形式：</p>
<script type="math/tex; mode=display">
P(Y)=\frac{1}{Z}\prod_C{\phi_C(Y_C)}\\
Z=\sum_Y\prod_C{\phi_C(Y_C)}</script><h5 id="条件随机场CRF-1"><a href="#条件随机场CRF-1" class="headerlink" title="条件随机场CRF"></a>条件随机场CRF</h5><p>条件随机场基于概率无向图模型，利用最大团理论，对随机变量的联合分布$P(Y)$进行建模。</p>
<p>在序列标注任务中的条件随机场，往往是指<strong>线性链条件随机场</strong></p>
<h6 id="条件随机场的参数化形式"><a href="#条件随机场的参数化形式" class="headerlink" title="条件随机场的参数化形式"></a>条件随机场的参数化形式</h6><script type="math/tex; mode=display">
P(y|x)=\frac{1}{Z(x)} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, x, i\right)+\sum_{i, j} \mu_{l} s_{l}\left(y_{i}, x, i\right)\right) 
\\
Z(x)=\sum_{y} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, x, i\right)+\sum_{i, j} \mu_{l} s_{l}\left(y_{i}, x, i\right)\right)</script><h6 id="条件随机场的简化形式"><a href="#条件随机场的简化形式" class="headerlink" title="条件随机场的简化形式"></a>条件随机场的简化形式</h6><script type="math/tex; mode=display">
\begin{aligned}
P(y | x) &=\frac{1}{Z(x)} \exp \sum_{k=1}^{K} w_{k} f_{k}(y, x) \\
Z(x) &=\sum_{y} \exp \sum_{k=1}^{K} w_{k} f_{k}(y, x)
\end{aligned}</script><h6 id="条件随机场的矩阵形式"><a href="#条件随机场的矩阵形式" class="headerlink" title="条件随机场的矩阵形式"></a>条件随机场的矩阵形式</h6><script type="math/tex; mode=display">
P_{w}(y | x)=\frac{1}{Z_{w}(x)} \prod_{i=1}^{n+1} M_{i}\left(y_{i-1}, y_{i} | x\right)\\
Z_{w}(x)=\left(M_{1}(x) M_{2}(x) \cdots M_{n+1}(x)\right)_{\text {start, stop }}</script><h3 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h3><p>K-Means是<strong>无监督</strong>的<strong>聚类</strong>算法.思想是对于给定的样本集,按照样本之间的距离大小将样本集划分为K个簇,让簇内的点尽量紧密地连在一起,而让簇间的距离尽量的大.</p>
<h4 id="传统算法"><a href="#传统算法" class="headerlink" title="传统算法"></a>传统算法</h4><ol>
<li>用先验知识或交叉验证选择一个合适的<strong>k</strong>值.</li>
<li>随机选择k个样本作为初始的<strong>质心</strong>.注意初始化质心的选择对最后的聚类结果和运行时间都有很大的影响.</li>
<li>计算每个样本点和各个质心的距离,将样本点标记为<strong>距离最小</strong>的质心所对应的簇.</li>
<li>重新计算每个<strong>簇</strong>的质心,取该簇中每个点位置的平均值.</li>
<li>重复2,3,4步直到k个质心都没有发生变化为止.</li>
</ol>
<h4 id="K-Means-1"><a href="#K-Means-1" class="headerlink" title="K-Means++"></a>K-Means++</h4><p>用于优化随机初始化质心的方法</p>
<ol>
<li>从输入样本点中随机选择一个点作为第一个质心.</li>
<li>计算每一个样本点到已选择的质心中<strong>最近质心</strong>的距离D(x).</li>
<li>选择一个新的样本点作为新的质心,选择原则是D(x)越大的点被选中的概率越大.</li>
<li>重复2和3直到选出k个质心.</li>
</ol>
<h4 id="Elkan-K-Means"><a href="#Elkan-K-Means" class="headerlink" title="Elkan K-Means"></a><strong>Elkan K-Means</strong></h4><p>利用两边之和大于第三边以及两边之差小于第三边来减少距离的计算.不适用于特征稀疏的情况.</p>
<h4 id="Mini-Batch-K-Means"><a href="#Mini-Batch-K-Means" class="headerlink" title="Mini Batch K-Means"></a><strong>Mini Batch K-Means</strong></h4><p>样本量很大时,只用其中的一部分来做传统的K-Means.一般多用几次该算法,从不同的随即采样中选择最优的聚类簇.</p>
<h3 id="Apriori"><a href="#Apriori" class="headerlink" title="Apriori"></a>Apriori</h3><p>Apriori是常用的挖掘出<strong>数据关联规则</strong>的算法,用于找出数据值中<strong>频繁</strong>出现的数据集合.一般使用支持度或者支持度与置信度的组合作为<strong>评估标准</strong>.</p>
<ol>
<li>支持度：几个关联的数据在数据集中出现的次数占总数据集的比重Support$(X, Y)=P(X Y)=\frac{\text {number}(X Y)}{\text {num}(\text {AllSamples})}$</li>
<li><strong>置信度</strong>：一个数据出现后.另一个数据出现的概率Confidence$(X \Leftarrow Y)=P(X | Y)=P(X Y) / P(Y)$</li>
</ol>
<p>Apriori算法的目标是找到最大的<strong>K项频繁集</strong>.假设使用支持度来作为评估标准,首先搜索出<strong>候选1项集</strong>及对应的支持度,<strong>剪枝</strong>去掉低于支持度的1项集,得到<strong>频繁1项集</strong>.然后对剩下的频繁1项集进行<strong>连接</strong>,得到候选的频繁2项集……以此类推,不断迭代,直到无法找到频繁k+1项集为止,对应的频繁k项集的集合即为输出结果.</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://blog.csdn.net/qq_20989105/article/details/81218696" target="_blank" rel="noopener">HMM隐马尔可夫模型与viterbi维特比算法</a></li>
</ol>

    </div>

    
    
    <div>
  
    <div style="text-align:center;color:#bfbfbf;font-size:16px;">
      <span>-------- 本文结束 </span>
      <i class="fa fa-coffee"></i>
      <span> 感谢阅读 --------</span>
    </div>
  
</div>
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    鼓励一下
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat.png" alt="Li Zhen 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/ali.png" alt="Li Zhen 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
              <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag"><i class="fa fa-tag"></i> 统计学习方法</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/08/31/scrapy/" rel="prev" title="scrapy">
      <i class="fa fa-chevron-left"></i> scrapy
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/03/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/" rel="next" title="深度学习总结">
      深度学习总结 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习大总结"><span class="nav-number">1.</span> <span class="nav-text">机器学习大总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#知识点"><span class="nav-number">1.1.</span> <span class="nav-text">知识点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#进程和线程"><span class="nav-number">1.1.1.</span> <span class="nav-text">进程和线程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#判别式模型和生成式模型"><span class="nav-number">1.1.2.</span> <span class="nav-text">判别式模型和生成式模型:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#概率质量函数-概率密度函数-累积分布函数"><span class="nav-number">1.1.3.</span> <span class="nav-text">概率质量函数,概率密度函数,累积分布函数:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#极大似然估计"><span class="nav-number">1.1.4.</span> <span class="nav-text">极大似然估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最小二乘法"><span class="nav-number">1.1.5.</span> <span class="nav-text">最小二乘法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#梯度下降法"><span class="nav-number">1.1.6.</span> <span class="nav-text">梯度下降法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#牛顿法"><span class="nav-number">1.1.7.</span> <span class="nav-text">牛顿法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拟牛顿法"><span class="nav-number">1.1.8.</span> <span class="nav-text">拟牛顿法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#先验概率和后验概率"><span class="nav-number">1.1.9.</span> <span class="nav-text">先验概率和后验概率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#偏差-方差-噪声"><span class="nav-number">1.1.10.</span> <span class="nav-text">偏差,方差,噪声</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#对偶原理"><span class="nav-number">1.1.11.</span> <span class="nav-text">对偶原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#KKT条件"><span class="nav-number">1.1.12.</span> <span class="nav-text">KKT条件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#降维方法"><span class="nav-number">1.1.13.</span> <span class="nav-text">降维方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#集成方法"><span class="nav-number">1.1.14.</span> <span class="nav-text">集成方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#性能度量"><span class="nav-number">1.1.15.</span> <span class="nav-text">性能度量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数和风险函数"><span class="nav-number">1.1.16.</span> <span class="nav-text">损失函数和风险函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#经验风险最小化和结构风险最小化"><span class="nav-number">1.1.17.</span> <span class="nav-text">经验风险最小化和结构风险最小化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#过拟合"><span class="nav-number">1.1.18.</span> <span class="nav-text">过拟合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#正则化"><span class="nav-number">1.1.19.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#交叉验证"><span class="nav-number">1.1.20.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sklearn"><span class="nav-number">1.1.21.</span> <span class="nav-text">sklearn</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#感知机"><span class="nav-number">1.2.</span> <span class="nav-text">感知机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型"><span class="nav-number">1.2.1.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#感知机的几何解释"><span class="nav-number">1.2.2.</span> <span class="nav-text">感知机的几何解释</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#策略"><span class="nav-number">1.2.3.</span> <span class="nav-text">策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法"><span class="nav-number">1.2.4.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#对偶形式"><span class="nav-number">1.2.5.</span> <span class="nav-text">对偶形式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k近邻法"><span class="nav-number">1.3.</span> <span class="nav-text">k近邻法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#三个基本要素"><span class="nav-number">1.3.1.</span> <span class="nav-text">三个基本要素:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型-1"><span class="nav-number">1.3.2.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#策略-1"><span class="nav-number">1.3.3.</span> <span class="nav-text">策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法-1"><span class="nav-number">1.3.4.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#搜索"><span class="nav-number">1.3.5.</span> <span class="nav-text">搜索</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#朴素贝叶斯"><span class="nav-number">1.4.</span> <span class="nav-text">朴素贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型-2"><span class="nav-number">1.4.1.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法-2"><span class="nav-number">1.4.2.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#特殊情况"><span class="nav-number">1.4.3.</span> <span class="nav-text">特殊情况</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树"><span class="nav-number">1.5.</span> <span class="nav-text">决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型-3"><span class="nav-number">1.5.1.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#策略-2"><span class="nav-number">1.5.2.</span> <span class="nav-text">策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法-3"><span class="nav-number">1.5.3.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#特征选择"><span class="nav-number">1.5.4.</span> <span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#决策树的生成"><span class="nav-number">1.5.5.</span> <span class="nav-text">决策树的生成</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#决策树的剪枝"><span class="nav-number">1.5.6.</span> <span class="nav-text">决策树的剪枝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CART算法"><span class="nav-number">1.5.7.</span> <span class="nav-text">CART算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#logistic回归和最大熵模型"><span class="nav-number">1.6.</span> <span class="nav-text">logistic回归和最大熵模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#逻辑斯谛分布"><span class="nav-number">1.6.1.</span> <span class="nav-text">逻辑斯谛分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#逻辑斯谛回归模型"><span class="nav-number">1.6.2.</span> <span class="nav-text">逻辑斯谛回归模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#对数几率"><span class="nav-number">1.6.3.</span> <span class="nav-text">对数几率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#似然估计"><span class="nav-number">1.6.4.</span> <span class="nav-text">似然估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型参数估计"><span class="nav-number">1.6.5.</span> <span class="nav-text">模型参数估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多项逻辑斯谛回归"><span class="nav-number">1.6.6.</span> <span class="nav-text">多项逻辑斯谛回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大熵原理"><span class="nav-number">1.6.7.</span> <span class="nav-text">最大熵原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大熵模型"><span class="nav-number">1.6.8.</span> <span class="nav-text">最大熵模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大熵模型的学习"><span class="nav-number">1.6.9.</span> <span class="nav-text">最大熵模型的学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#逻辑回归与最大熵模型的共同点"><span class="nav-number">1.6.10.</span> <span class="nav-text">逻辑回归与最大熵模型的共同点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#优化算法"><span class="nav-number">1.6.11.</span> <span class="nav-text">优化算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#支持向量机"><span class="nav-number">1.7.</span> <span class="nav-text">支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型-4"><span class="nav-number">1.7.1.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#策略-3"><span class="nav-number">1.7.2.</span> <span class="nav-text">策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据可分、近似可分、不可分"><span class="nav-number">1.7.3.</span> <span class="nav-text">数据可分、近似可分、不可分</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#核技巧"><span class="nav-number">1.7.4.</span> <span class="nav-text">核技巧</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#输入空间和特征空间"><span class="nav-number">1.7.5.</span> <span class="nav-text">输入空间和特征空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#优化"><span class="nav-number">1.7.6.</span> <span class="nav-text">优化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#线性可分支持向量机"><span class="nav-number">1.7.7.</span> <span class="nav-text">线性可分支持向量机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#线性支持向量机"><span class="nav-number">1.7.8.</span> <span class="nav-text">线性支持向量机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#非线性支持向量机"><span class="nav-number">1.7.9.</span> <span class="nav-text">非线性支持向量机</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#提升方法"><span class="nav-number">1.8.</span> <span class="nav-text">提升方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#提升方法-1"><span class="nav-number">1.8.1.</span> <span class="nav-text">提升方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#加法模型和前向分步算法"><span class="nav-number">1.8.2.</span> <span class="nav-text">加法模型和前向分步算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaBoost"><span class="nav-number">1.8.3.</span> <span class="nav-text">AdaBoost</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#提升树"><span class="nav-number">1.8.4.</span> <span class="nav-text">提升树</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#梯度提升树-GBDT"><span class="nav-number">1.8.5.</span> <span class="nav-text">梯度提升树(GBDT)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Xgboost"><span class="nav-number">1.8.6.</span> <span class="nav-text">Xgboost</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#EM算法"><span class="nav-number">1.9.</span> <span class="nav-text">EM算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#隐变量"><span class="nav-number">1.9.1.</span> <span class="nav-text">隐变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法-6"><span class="nav-number">1.9.2.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#应用"><span class="nav-number">1.9.3.</span> <span class="nav-text">应用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#隐马尔科夫模型-HMM"><span class="nav-number">1.10.</span> <span class="nav-text">隐马尔科夫模型(HMM)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型表示"><span class="nav-number">1.10.1.</span> <span class="nav-text">模型表示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#两个基本假设"><span class="nav-number">1.10.2.</span> <span class="nav-text">两个基本假设</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#三个基本问题"><span class="nav-number">1.10.3.</span> <span class="nav-text">三个基本问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最大熵马尔科夫模型-MEMM"><span class="nav-number">1.11.</span> <span class="nav-text">最大熵马尔科夫模型(MEMM)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#标注偏置问题"><span class="nav-number">1.11.1.</span> <span class="nav-text">标注偏置问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#条件随机场CRF"><span class="nav-number">1.12.</span> <span class="nav-text">条件随机场CRF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#概率图模型"><span class="nav-number">1.12.1.</span> <span class="nav-text">概率图模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-Means"><span class="nav-number">1.13.</span> <span class="nav-text">K-Means</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#传统算法"><span class="nav-number">1.13.1.</span> <span class="nav-text">传统算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K-Means-1"><span class="nav-number">1.13.2.</span> <span class="nav-text">K-Means++</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Elkan-K-Means"><span class="nav-number">1.13.3.</span> <span class="nav-text">Elkan K-Means</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mini-Batch-K-Means"><span class="nav-number">1.13.4.</span> <span class="nav-text">Mini Batch K-Means</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Apriori"><span class="nav-number">1.14.</span> <span class="nav-text">Apriori</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参考"><span class="nav-number">1.15.</span> <span class="nav-text">参考</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <a href='/'>
    <img class="site-author-image" itemprop="image" alt="Li Zhen"
      src="/images/snoppy.jpeg">
  </a>
  <p class="site-author-name" itemprop="name">Li Zhen</p>
  <div class="site-description" itemprop="description">但行好事，莫问前程！</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jeffery0628" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jeffery0628" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jeffery.lee.0628@gmail.com" title="邮箱 → mailto:jeffery.lee.0628@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>邮箱</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heartbeat"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li Zhen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">399k</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="site-uv">
      我的第 <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 位朋友，
    </span>
    <span class="site-pv">
      历经 <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次回眸才与你相遇
    </span>
</div>






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"bu0jcrISneKfTwssc7P792xE-gzGzoHsz","app_key":"3y7nYJuTGp6zIHSfRBQlMQnB","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  

  <canvas id="evanyou"></canvas>
  <style>
    #evanyou {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
    }
  </style>
  <script src="/js/evan-you.js"></script>




  <canvas id="evanyou"></canvas>
  <style>
    #evanyou {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
    }
  </style>
  <script src="/js/evan-you.js"></script>



  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>


 

<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
<script>
  function timer() {
    var ages = moment.preciseDiff(moment(),moment(20180101,"YYYYMMDD"));
    ages = ages.replace(/years?/, "年");
    ages = ages.replace(/months?/, "月");
    ages = ages.replace(/days?/, "天");
    ages = ages.replace(/hours?/, "小时");
    ages = ages.replace(/minutes?/, "分");
    ages = ages.replace(/seconds?/, "秒");
    ages = ages.replace(/\d+/g, '<span style="color:#1890ff">$&</span>');
    div.innerHTML = `我已在此等候你 ${ages}`;
  }
  var div = document.createElement("div");
  //插入到copyright之后
  var copyright = document.querySelector(".copyright");
  document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
  timer();
  setInterval("timer()",1000)
</script>


<script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>

<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'wocKAhd8E1IRPHNgYbfFVsKf-gzGzoHsz',
      appKey     : '0SDY7WADR3m02c4hBcUv3T0B',
      placeholder: "留下你的小脚印吧！",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '8' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
